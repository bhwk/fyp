<!-- prettier-ignore -->

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ray.data.dataset &#8212; Ray 3.0.0.dev0</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="https://docs.ray.io/en/master/_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="https://docs.ray.io/en/master/_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="https://docs.ray.io/en/master/_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="https://docs.ray.io/en/master/_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="https://docs.ray.io/en/master/_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="https://docs.ray.io/en/master/_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="https://docs.ray.io/en/master/_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/css/termynal.css?v=2fc3cb5e" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/css/csat.css?v=c8f39c76" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/css/assistant.css?v=d345c55e" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/css/custom.css?v=2df59da5" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/docsearch.css?v=45fb5152" />
    <link rel="stylesheet" type="text/css" href="https://docs.ray.io/en/master/_static/pydata-docsearch-custom.css?v=7fb92720" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="https://docs.ray.io/en/master/_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="https://docs.ray.io/en/master/_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="https://docs.ray.io/en/master/_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script src="https://docs.ray.io/en/master/_static/documentation_options.js?v=d1493c90"></script>
    <script src="https://docs.ray.io/en/master/_static/doctools.js?v=9a2dae69"></script>
    <script src="https://docs.ray.io/en/master/_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="https://docs.ray.io/en/master/_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="https://docs.ray.io/en/master/_static/copybutton.js?v=9a29e97e"></script>
    <script defer="defer" src="https://docs.ray.io/en/master/_static/js/termynal.js?v=67cfcf08"></script>
    <script defer="defer" src="https://docs.ray.io/en/master/_static/js/custom.js?v=9e3b357f"></script>
    <script src="https://docs.ray.io/en/master/_static/js/csat.js?v=8e649b1c"></script>
    <script defer="defer" src="https://docs.ray.io/en/master/_static/js/assistant.js?v=73fdc522"></script>
    <script defer="defer" src="https://docs.ray.io/en/master/_static/docsearch.js?v=77274085"></script>
    <script defer="defer" src="https://docs.ray.io/en/master/_static/docsearch_config.js?v=d25523ed"></script>
    <script src="https://docs.ray.io/en/master/_static/design-tabs.js?v=36754332"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/ray/data/dataset';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.14.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://docs.ray.io/en/master/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'master';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = false;
        </script>
    <link rel="canonical" href="https://docs.ray.io/en/latest/_modules/ray/data/dataset.html" />
    <link rel="icon" href="https://docs.ray.io/en/master/_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" /><!-- Extra header to include at the top of each template.
Kept separately so that it can easily be included in any templates
that need to be overridden for individual pages; e.g. included
both in the usual template (layout.html) as well as (index.html). -->

<link rel="preconnect" href="https://fonts.googleapis.com" />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link
  href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;900&family=Roboto:wght@400;500;700&display=swap"
  rel="stylesheet"
/>
<link
  rel="stylesheet"
  title="light"
  href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
  disabled="disabled"
/>
<link
  rel="stylesheet"
  title="dark"
  href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css"
  disabled="disabled"
/>
<link
  href="https://cdn.jsdelivr.net/npm/remixicon@4.1.0/fonts/remixicon.css"
  rel="stylesheet"
/>

<!-- Used for text embedded in html on the index page  -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

<!-- Parser used to call hljs on responses from Ray Assistant -->
<script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

<!-- Sanitizer for Ray Assistant AI -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/dompurify/2.3.3/purify.min.js"></script>

<!-- Fathom - beautiful, simple website analytics -->
<script src="https://deer.ray.io/script.js" data-site="WYYANYOS" defer></script>
<!-- / Fathom -->

<!-- Google Tag Manager -->
<script>
  (function (w, d, s, l, i) {
    w[l] = w[l] || [];
    w[l].push({
      'gtm.start': new Date().getTime(),
      event: 'gtm.js',
    });
    var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s),
      dl = l != 'dataLayer' ? '&l=' + l : '';
    j.async = true;
    j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
    f.parentNode.insertBefore(j, f);
  })(window, document, 'script', 'dataLayer', 'GTM-P8H6KQG');
</script>
<!-- End Google Tag Manager -->
<!-- Data to be shared with JS on every page -->
<script>
  window.data = {
      copyIconSrc: "../../../_static/copy-button.svg"
  };
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  <script async type="text/javascript" src="https://docs.ray.io/_/static/javascript/readthedocs-addons.js"></script><meta name="readthedocs-project-slug" content="anyscale-ray" /><meta name="readthedocs-version-slug" content="master" /><meta name="readthedocs-resolver-filename" content="/_modules/ray/data/dataset.html" /><meta name="readthedocs-http-status" content="200" /></head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="dataset.html#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="https://docs.ray.io/en/master/search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../../index.html">
  <svg
   id="svg"
   version="1.1"
   viewBox="0, 0, 400,200.13540961408262"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg">
  <g id="g1">
    <path id="ray-text" d="m 102.875,36.782 c 0.16,0.041 0.423,0.041 0.583,0 0.161,-0.042 0.029,-0.077 -0.291,-0.077 -0.321,0 -0.452,0.035 -0.292,0.077 m 89.958,63.206 v 30.345 h 3.584 3.583 v -9.487 -9.487 l 9.958,-0.059 c 10.822,-0.064 10.056,-0.121 10.664,0.804 0.113,0.172 0.394,0.597 0.625,0.945 0.231,0.348 0.42,0.693 0.42,0.766 0,0.073 0.15,0.269 0.333,0.435 0.183,0.166 0.333,0.358 0.333,0.427 0,0.069 0.366,0.676 0.814,1.349 0.925,1.393 2.687,4.088 2.936,4.493 0.092,0.149 0.312,0.486 0.489,0.751 1.348,2.013 2.261,3.416 2.261,3.474 0,0.038 0.338,0.561 0.75,1.164 0.413,0.602 0.755,1.151 0.761,1.219 0.006,0.067 0.267,0.46 0.58,0.873 0.313,0.412 0.692,0.975 0.843,1.25 0.622,1.138 0.378,1.083 4.846,1.083 h 4.062 l -0.254,-0.458 c -0.139,-0.252 -0.677,-1.058 -1.196,-1.792 -1.001,-1.416 -1.194,-1.694 -5.308,-7.666 -1.452,-2.109 -2.684,-3.871 -2.737,-3.917 -0.053,-0.046 -0.172,-0.213 -0.263,-0.372 -0.326,-0.563 -2.842,-4.226 -3.541,-5.154 -0.969,-1.287 -1.025,-1.162 0.832,-1.838 0.726,-0.263 2.976,-1.446 3.305,-1.737 0.145,-0.128 0.319,-0.232 0.388,-0.232 0.287,0 2.659,-2.095 3.515,-3.105 3.686,-4.345 5.22,-10.506 4.352,-17.484 -0.442,-3.559 -1.381,-5.956 -3.555,-9.078 -0.491,-0.706 -3.235,-3.333 -3.481,-3.333 -0.128,0 -0.232,-0.062 -0.232,-0.136 0,-0.075 -0.319,-0.313 -0.708,-0.53 -0.39,-0.216 -0.746,-0.439 -0.792,-0.496 -0.077,-0.096 -1.012,-0.546 -2.532,-1.218 -1.038,-0.459 -3.173,-1.141 -4.051,-1.293 -0.459,-0.08 -1.359,-0.273 -2,-0.429 -1.04,-0.253 -2.711,-0.292 -15.375,-0.353 l -14.209,-0.07 v 30.346 m 80.935,-28.446 c -0.448,1.031 -1.004,2.287 -1.235,2.791 -0.396,0.861 -0.579,1.27 -1.363,3.038 -0.403,0.911 -1.14,2.528 -1.903,4.177 -0.33,0.714 -0.6,1.373 -0.6,1.464 0,0.092 -0.107,0.333 -0.238,0.536 -0.13,0.203 -0.661,1.344 -1.179,2.535 -0.519,1.192 -1.085,2.467 -1.258,2.834 -0.464,0.979 -1.328,2.9 -2.324,5.166 -1.025,2.334 -1.477,3.34 -1.759,3.917 -0.113,0.229 -1.423,3.154 -2.913,6.5 -1.49,3.346 -2.951,6.608 -3.248,7.25 -1.302,2.818 -8.248,18.378 -8.248,18.475 0,0.06 1.714,0.108 3.808,0.108 h 3.809 l 1.04,-2.375 c 0.573,-1.306 1.191,-2.712 1.374,-3.125 0.183,-0.412 0.483,-1.087 0.665,-1.5 0.183,-0.412 0.467,-1.05 0.63,-1.416 0.164,-0.367 0.656,-1.492 1.093,-2.5 0.437,-1.009 0.93,-2.134 1.097,-2.5 0.166,-0.367 0.399,-0.911 0.517,-1.209 l 0.215,-0.541 h 16.448 16.447 l 0.369,0.791 c 0.203,0.436 0.464,1.017 0.581,1.292 0.209,0.494 1.042,2.363 1.485,3.333 0.21,0.46 2.5,5.679 2.998,6.834 0.118,0.275 0.406,0.912 0.638,1.416 0.232,0.504 0.465,1.048 0.516,1.209 0.085,0.267 0.426,0.291 4.003,0.291 h 3.91 l -0.137,-0.458 c -0.122,-0.41 -1.026,-2.462 -2.331,-5.292 -0.254,-0.55 -1.531,-3.4 -2.838,-6.333 -1.307,-2.933 -2.618,-5.858 -2.913,-6.5 -0.412,-0.894 -5.399,-12.071 -8.292,-18.583 -0.183,-0.413 -0.473,-1.05 -0.644,-1.417 -0.324,-0.694 -1.063,-2.353 -1.56,-3.5 -0.159,-0.367 -0.427,-0.967 -0.595,-1.333 -0.867,-1.885 -2.251,-4.97 -2.916,-6.5 -0.195,-0.45 -0.423,-0.958 -1.421,-3.167 -0.166,-0.367 -0.502,-1.117 -0.747,-1.667 -0.63,-1.413 -1.07,-2.395 -1.419,-3.166 -0.652,-1.443 -0.97,-2.18 -1.059,-2.459 -0.086,-0.266 -0.421,-0.291 -3.891,-0.291 h -3.798 l -0.814,1.875 M 306.5,69.745 c 0,0.096 0.45,0.894 1.132,2.005 0.281,0.458 0.75,1.283 1.042,1.833 0.293,0.55 0.625,1.113 0.738,1.25 0.114,0.138 0.649,1.029 1.189,1.982 0.54,0.952 1.147,2.002 1.348,2.333 0.201,0.331 0.669,1.127 1.04,1.769 0.372,0.641 0.874,1.504 1.117,1.916 0.452,0.769 0.799,1.371 1.408,2.446 0.19,0.337 0.586,0.993 0.878,1.458 0.293,0.466 0.625,1.034 0.738,1.263 0.113,0.229 0.393,0.717 0.622,1.083 0.229,0.367 0.735,1.218 1.124,1.891 0.389,0.673 0.857,1.477 1.041,1.787 0.183,0.31 0.775,1.334 1.316,2.276 0.541,0.942 1.066,1.817 1.167,1.944 0.101,0.127 0.446,0.704 0.767,1.282 0.32,0.579 0.948,1.675 1.393,2.436 0.446,0.762 0.963,1.647 1.149,1.968 0.186,0.32 0.476,0.808 0.644,1.083 0.168,0.275 0.497,0.837 0.73,1.25 0.234,0.412 0.563,0.975 0.731,1.25 0.168,0.275 0.456,0.763 0.64,1.083 0.183,0.321 0.607,1.046 0.94,1.612 l 0.606,1.028 v 10.18 10.18 h 3.583 3.584 v -10.55 c 0,-6.074 0.064,-10.617 0.151,-10.708 0.083,-0.087 0.32,-0.458 0.528,-0.825 0.869,-1.535 1.109,-1.954 1.881,-3.277 1.098,-1.882 1.383,-2.373 1.773,-3.056 0.183,-0.321 0.473,-0.827 0.644,-1.125 0.171,-0.298 0.587,-1.029 0.926,-1.625 0.338,-0.596 0.683,-1.196 0.765,-1.334 0.428,-0.714 1.259,-2.124 1.424,-2.416 0.186,-0.329 0.612,-1.07 1.22,-2.125 0.172,-0.298 0.634,-1.104 1.027,-1.792 0.393,-0.687 0.815,-1.368 0.938,-1.513 0.122,-0.145 0.223,-0.389 0.223,-0.542 0,-0.153 0.061,-0.278 0.137,-0.278 0.075,0 0.302,-0.319 0.503,-0.709 0.202,-0.389 0.551,-1.008 0.775,-1.375 0.225,-0.366 0.551,-0.929 0.724,-1.25 0.63,-1.167 2.234,-3.927 2.52,-4.336 0.161,-0.23 0.547,-0.889 0.858,-1.462 0.312,-0.574 0.732,-1.323 0.935,-1.664 0.203,-0.342 0.561,-0.959 0.796,-1.371 0.234,-0.413 0.585,-1.013 0.779,-1.333 0.325,-0.538 0.934,-1.61 1.374,-2.417 0.1,-0.183 0.267,-0.446 0.371,-0.583 0.103,-0.138 0.425,-0.7 0.715,-1.25 0.29,-0.55 0.647,-1.171 0.793,-1.379 l 0.265,-0.378 -3.801,0.045 -3.801,0.045 -0.3,0.5 c -0.165,0.275 -0.455,0.762 -0.644,1.083 -0.189,0.321 -0.565,0.921 -0.835,1.334 -0.27,0.412 -0.569,0.9 -0.664,1.083 -0.096,0.183 -0.395,0.671 -0.665,1.083 -0.27,0.413 -0.645,1.013 -0.834,1.334 -0.189,0.32 -0.49,0.808 -0.668,1.083 -0.178,0.275 -0.479,0.762 -0.669,1.083 -0.19,0.321 -0.712,1.184 -1.159,1.917 -0.448,0.733 -1.086,1.783 -1.417,2.333 -0.332,0.55 -0.824,1.338 -1.093,1.75 -0.27,0.413 -0.542,0.863 -0.605,1 -0.064,0.138 -0.427,0.738 -0.807,1.334 -0.38,0.596 -0.834,1.308 -1.009,1.583 -0.175,0.275 -0.402,0.65 -0.503,0.833 -0.102,0.184 -0.696,1.159 -1.321,2.167 -0.625,1.008 -1.316,2.133 -1.536,2.5 -0.219,0.367 -0.584,0.967 -0.81,1.333 -0.226,0.367 -0.461,0.777 -0.523,0.911 -0.061,0.134 -0.42,0.696 -0.797,1.25 -0.378,0.553 -0.737,1.118 -0.799,1.256 -0.061,0.138 -0.3,0.55 -0.531,0.917 -0.23,0.366 -0.507,0.837 -0.615,1.046 -0.292,0.563 -0.932,-0.03 -1.58,-1.463 -0.063,-0.138 -0.27,-0.473 -0.461,-0.747 -0.39,-0.556 -0.504,-0.738 -1.098,-1.753 -0.559,-0.954 -0.693,-1.171 -1.084,-1.754 -0.183,-0.274 -0.422,-0.647 -0.531,-0.83 -0.109,-0.183 -0.695,-1.12 -1.302,-2.083 -0.607,-0.962 -1.193,-1.897 -1.302,-2.077 -0.534,-0.884 -1.693,-2.723 -1.97,-3.124 -0.171,-0.249 -0.311,-0.495 -0.311,-0.549 0,-0.053 -0.141,-0.3 -0.312,-0.548 C 323.21,84.6 322,82.674 322,82.582 c 0,-0.053 -0.139,-0.299 -0.309,-0.547 -0.761,-1.11 -1.663,-2.54 -1.81,-2.868 -0.061,-0.138 -0.435,-0.724 -0.83,-1.303 -0.395,-0.578 -0.718,-1.088 -0.718,-1.133 0,-0.044 -0.3,-0.532 -0.666,-1.084 C 317.3,75.095 317,74.611 317,74.571 c 0,-0.039 -0.356,-0.628 -0.792,-1.308 -0.435,-0.681 -1.12,-1.768 -1.522,-2.417 l -0.731,-1.179 h -3.727 c -2.051,0 -3.728,0.035 -3.728,0.078 m -86.75,7.023 c 3.486,0.433 8.055,2.022 8.389,2.917 0.03,0.081 0.138,0.148 0.239,0.148 0.278,0 2.413,2.27 2.792,2.969 0.184,0.338 0.399,0.727 0.48,0.865 2.258,3.865 1.774,11.495 -0.942,14.836 -0.206,0.254 -0.375,0.504 -0.375,0.556 0,0.13 -1.451,1.504 -2.196,2.079 -1.372,1.059 -4.274,2.252 -6.804,2.797 -1.265,0.272 -2.482,0.311 -11.375,0.359 L 200,104.348 V 90.424 76.5 l 8.792,-0.001 c 7.089,0 9.211,0.052 10.958,0.269 m 58.745,1.979 c 0.003,0.09 0.235,0.653 0.516,1.25 0.281,0.598 0.662,1.424 0.846,1.836 0.185,0.413 0.48,1.05 0.656,1.417 0.177,0.367 0.321,0.719 0.321,0.783 -10e-4,0.101 0.437,1.075 1.82,4.05 0.17,0.367 1.189,2.654 2.263,5.084 1.075,2.429 2.18,4.904 2.456,5.5 0.276,0.596 0.76,1.683 1.075,2.416 0.581,1.349 0.792,1.826 1.478,3.334 0.209,0.458 0.542,1.208 0.74,1.666 0.198,0.459 0.498,1.115 0.666,1.459 l 0.307,0.625 h -13.32 c -8.524,0 -13.319,-0.059 -13.319,-0.163 0,-0.089 0.164,-0.52 0.365,-0.958 0.622,-1.356 1.332,-2.938 1.572,-3.504 0.126,-0.298 0.337,-0.786 0.469,-1.084 0.131,-0.298 0.814,-1.854 1.517,-3.458 0.704,-1.604 1.411,-3.217 1.573,-3.583 0.161,-0.367 0.406,-0.93 0.544,-1.25 0.137,-0.321 0.794,-1.821 1.459,-3.334 1.615,-3.672 1.781,-4.049 2.154,-4.875 0.175,-0.389 0.674,-1.533 1.108,-2.541 0.937,-2.177 1.685,-3.833 2.006,-4.443 0.128,-0.243 0.233,-0.576 0.233,-0.74 0,-0.333 0.484,0.168 0.495,0.513" />
    <path id="ray-logo" d="m 101.476,36.871 c -1.303,0.145 -3.55,0.666 -4.332,1.004 -2.044,0.884 -2.472,1.092 -3.144,1.529 -7.177,4.661 -9.961,13.497 -6.746,21.409 0.465,1.144 0.582,1.352 1.707,3.057 0.986,1.494 3.928,4.463 4.424,4.463 0.054,0 0.429,0.223 0.832,0.496 4.639,3.13 12.64,3.283 17.395,0.332 0.457,-0.284 22.892,21.99 22.486,22.327 -0.218,0.181 -0.803,1.491 -1.437,3.22 l -0.352,0.959 h -6.238 c -5.795,0 -6.238,-0.021 -6.238,-0.288 0,-0.977 -1.759,-4.418 -3.151,-6.165 -4.027,-5.051 -11.482,-7.68 -17.226,-6.075 -0.711,0.198 -1.405,0.361 -1.542,0.361 -0.745,0 -4.681,2.22 -5.914,3.336 -0.321,0.291 -0.792,0.706 -1.046,0.923 -0.855,0.728 -2.606,3.23 -3.29,4.701 -0.372,0.801 -0.749,1.587 -0.837,1.746 -0.088,0.159 -0.16,0.434 -0.16,0.611 0,0.888 0.287,0.85 -6.415,0.85 H 74.04 l -0.198,-0.542 c -0.108,-0.298 -0.347,-0.917 -0.531,-1.375 -0.183,-0.458 -0.358,-0.946 -0.389,-1.083 -0.087,-0.39 -1.399,-2.503 -2.064,-3.324 -2.725,-3.366 -5.769,-5.225 -10.441,-6.377 -3.309,-0.816 -10.96,0.695 -12.419,2.453 -0.113,0.136 -0.278,0.248 -0.367,0.248 -0.392,0 -4.298,3.657 -4.298,4.024 0,0.086 -0.131,0.297 -0.291,0.469 -2.793,2.998 -3.936,11.297 -2.141,15.549 0.844,1.999 1.072,2.472 1.583,3.291 0.314,0.504 0.634,0.942 0.711,0.972 0.076,0.031 0.138,0.154 0.138,0.274 0,0.246 2.689,3.043 3.334,3.468 0.229,0.151 0.716,0.486 1.083,0.744 6.843,4.811 18.162,3.018 23.001,-3.643 0.093,-0.128 0.412,-0.542 0.709,-0.922 0.297,-0.38 0.54,-0.747 0.54,-0.815 0,-0.069 0.224,-0.489 0.498,-0.935 0.275,-0.445 0.461,-0.81 0.414,-0.81 -0.046,0 0.104,-0.372 0.335,-0.827 0.231,-0.456 0.42,-0.94 0.42,-1.076 0,-0.136 0.087,-0.439 0.193,-0.672 l 0.194,-0.425 h 6.22 6.22 l 0.101,0.459 c 1.063,4.828 6.623,10.565 11.322,11.682 0.366,0.087 1.154,0.288 1.75,0.446 7.975,2.118 18.533,-4.211 20.101,-12.05 l 0.107,-0.537 h 6.217 6.217 l 0.352,0.959 c 0.642,1.751 1.22,3.04 1.447,3.228 0.178,0.148 -2.094,2.503 -10.941,11.344 l -11.165,11.158 -0.793,-0.404 c -1.29,-0.658 -1.561,-0.769 -2.959,-1.21 -5.239,-1.651 -12.178,-0.296 -16.032,3.131 -1.412,1.256 -2.907,2.908 -3.508,3.878 -4.539,7.323 -3.445,16.326 2.69,22.138 0.992,0.939 3.39,2.578 4.35,2.972 1.875,0.771 2.482,1.005 2.729,1.053 0.149,0.03 0.849,0.174 1.556,0.32 10.388,2.155 20.37,-6.164 20.38,-16.983 0.002,-3.118 -0.379,-4.767 -1.788,-7.728 l -0.505,-1.061 11.107,-11.106 11.107,-11.105 0.873,0.447 c 1.444,0.739 3.341,1.372 5.068,1.691 1.606,0.297 5.042,0.225 6.39,-0.134 0.595,-0.159 1.37,-0.358 1.72,-0.442 1.198,-0.288 4.129,-1.822 5.32,-2.786 9.711,-7.857 8.716,-22.425 -1.957,-28.665 -3.504,-2.048 -8.663,-2.872 -12.167,-1.942 -0.55,0.146 -1.262,0.327 -1.583,0.403 -0.614,0.144 -1.774,0.627 -2.958,1.232 l -0.709,0.362 -11.105,-11.105 -11.105,-11.106 0.289,-0.561 c 3.009,-5.83 2.687,-12.491 -0.861,-17.825 -0.257,-0.386 -0.543,-0.821 -0.634,-0.965 -1.398,-2.203 -6.344,-5.524 -9.084,-6.099 -3.096,-0.651 -4.424,-0.766 -6.357,-0.551 m 4.095,8.912 c 6.101,1.712 8.316,9.521 3.993,14.078 -6.028,6.355 -16.205,1.325 -14.858,-7.345 0.559,-3.597 3.168,-6.047 7.544,-7.084 0.546,-0.13 2.249,0.05 3.321,0.351 M 59.946,91.812 c 2.314,0.806 4.061,2.37 5.152,4.615 l 0.644,1.323 v 2.25 2.25 l -0.648,1.332 c -3.748,7.711 -14.726,6.286 -16.362,-2.124 -1.223,-6.284 5.142,-11.76 11.214,-9.646 M 105,91.512 c 7.468,1.695 9.27,11.549 2.87,15.694 -7.325,4.746 -16.184,-3.082 -12.434,-10.986 0.56,-1.179 2.473,-3.387 2.935,-3.387 0.102,0 0.312,-0.113 0.465,-0.252 1.043,-0.944 4.259,-1.502 6.164,-1.069 m 46.441,0.171 c 4.417,1.35 7.025,5.54 6.148,9.877 -0.306,1.514 -0.863,2.879 -1.336,3.271 -0.139,0.116 -0.253,0.306 -0.253,0.424 0,0.307 -1.541,1.65 -2.554,2.224 -7.406,4.199 -15.743,-3.631 -12.051,-11.318 0.752,-1.565 3.286,-3.994 4.167,-3.994 0.112,0 0.276,-0.069 0.363,-0.153 0.713,-0.687 3.754,-0.87 5.516,-0.331 m -44.774,46.358 c 8.432,4.162 5.806,16.556 -3.5,16.523 C 100.595,154.555 96,152.103 96,150.74 c 0,-0.11 -0.106,-0.287 -0.236,-0.395 -1.065,-0.884 -1.517,-5.232 -0.754,-7.262 1.796,-4.781 7.334,-7.176 11.657,-5.042" />
  </g>
</svg>

</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <div class="navbar-content docutils container">
<ul class="navbar-toplevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-overview/getting-started.html" title="Get Started"><span class="navbar-link-title">Get Started</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-overview/use-cases.html" title="Use Cases"><span class="navbar-link-title">Use Cases</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-overview/examples.html" title="Example Gallery"><span class="navbar-link-title">Example Gallery</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-more-libs/installation.html" title="Library"><span class="navbar-link-title">Library</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-core/walkthrough.html" title="Ray Core"><span class="navbar-link-title">Ray Core</span>Scale general Python applications</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../data/data.html" title="Ray Data"><span class="navbar-link-title">Ray Data</span>Scale data ingest and preprocessing</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../train/train.html" title="Ray Train"><span class="navbar-link-title">Ray Train</span>Scale machine learning training</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../tune.html" title="Ray Tune"><span class="navbar-link-title">Ray Tune</span>Scale hyperparameter tuning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../serve/index.html" title="Ray Serve"><span class="navbar-link-title">Ray Serve</span>Scale model serving</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../rllib/index.html" title="Ray RLlib"><span class="navbar-link-title">Ray RLlib</span>Scale reinforcement learning</a></p>
</div>
</li>
</ul>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../index.html" title="Docs"><span class="navbar-link-title">Docs</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Resources"><span class="navbar-link-title">Resources</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Discussion Forum"><span class="navbar-link-title">Discussion Forum</span>Get your Ray questions answered</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://github.com/ray-project/ray-educational-materials" title="Training"><span class="navbar-link-title">Training</span>Hands-on learning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog" title="Blog"><span class="navbar-link-title">Blog</span>Updates, best practices, user-stories</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/events" title="Events"><span class="navbar-link-title">Events</span>Webinars, meetups, office hours</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog/how-ray-and-anyscale-make-it-easy-to-do-massive-scale-machine-learning-on" title="Success Stories"><span class="navbar-link-title">Success Stories</span>Real-world workload examples</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-overview/ray-libraries.html" title="Ecosystem"><span class="navbar-link-title">Ecosystem</span>Libraries integrated with Ray</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.ray.io/community" title="Community"><span class="navbar-link-title">Community</span>Connect with us</a></p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>

</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          <div id="docsearch"></div>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="versionswitcherbutton" type="button" role="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-bs-toggle="dropdown" aria-haspopup="listbox" aria-controls="versionswitcherlist" aria-label="Version switcher list">
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="versionswitcherlist" class="version-switcher__menu dropdown-menu list-group-flush py-0" role="listbox" aria-labelledby="versionswitcherbutton">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
      
        <div class="navbar-item"><a id="try-anyscale-href" href="https://console.anyscale.com/?utm_source=ray_docs&utm_medium=docs&utm_campaign=navbar">
  <div id="try-anyscale-text">
    <span>Try Ray on Anyscale</span>
  </div>
</a></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile"><div id="docsearch"></div>
    </div>
  

  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <div class="navbar-content docutils container">
<ul class="navbar-toplevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-overview/getting-started.html" title="Get Started"><span class="navbar-link-title">Get Started</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-overview/use-cases.html" title="Use Cases"><span class="navbar-link-title">Use Cases</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-overview/examples.html" title="Example Gallery"><span class="navbar-link-title">Example Gallery</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-more-libs/installation.html" title="Library"><span class="navbar-link-title">Library</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-core/walkthrough.html" title="Ray Core"><span class="navbar-link-title">Ray Core</span>Scale general Python applications</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../data/data.html" title="Ray Data"><span class="navbar-link-title">Ray Data</span>Scale data ingest and preprocessing</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../train/train.html" title="Ray Train"><span class="navbar-link-title">Ray Train</span>Scale machine learning training</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../tune.html" title="Ray Tune"><span class="navbar-link-title">Ray Tune</span>Scale hyperparameter tuning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../serve/index.html" title="Ray Serve"><span class="navbar-link-title">Ray Serve</span>Scale model serving</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../rllib/index.html" title="Ray RLlib"><span class="navbar-link-title">Ray RLlib</span>Scale reinforcement learning</a></p>
</div>
</li>
</ul>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../index.html" title="Docs"><span class="navbar-link-title">Docs</span></a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Resources"><span class="navbar-link-title">Resources</span></a></p>
<i class="fa-solid fa-chevron-down"></i></div>
<div class="navbar-dropdown docutils container">
<ul class="navbar-sublevel">
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://discuss.ray.io" title="Discussion Forum"><span class="navbar-link-title">Discussion Forum</span>Get your Ray questions answered</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://github.com/ray-project/ray-educational-materials" title="Training"><span class="navbar-link-title">Training</span>Hands-on learning</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog" title="Blog"><span class="navbar-link-title">Blog</span>Updates, best practices, user-stories</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/events" title="Events"><span class="navbar-link-title">Events</span>Webinars, meetups, office hours</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.anyscale.com/blog/how-ray-and-anyscale-make-it-easy-to-do-massive-scale-machine-learning-on" title="Success Stories"><span class="navbar-link-title">Success Stories</span>Real-world workload examples</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference internal" href="../../../ray-overview/ray-libraries.html" title="Ecosystem"><span class="navbar-link-title">Ecosystem</span>Libraries integrated with Ray</a></p>
</div>
</li>
<li><div class="ref-container docutils container">
<p><a class="reference external" href="https://www.ray.io/community" title="Community"><span class="navbar-link-title">Community</span>Connect with us</a></p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>

</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="versionswitcherbutton" type="button" role="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-bs-toggle="dropdown" aria-haspopup="listbox" aria-controls="versionswitcherlist" aria-label="Version switcher list">
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="versionswitcherlist" class="version-switcher__menu dropdown-menu list-group-flush py-0" role="listbox" aria-labelledby="versionswitcherbutton">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
        
          <div class="navbar-item"><a id="try-anyscale-href" href="https://console.anyscale.com/?utm_source=ray_docs&utm_medium=docs&utm_campaign=navbar">
  <div id="try-anyscale-text">
    <span>Try Ray on Anyscale</span>
  </div>
</a></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav id="main-sidebar" class="bd-docs-nav bd-links" aria-label="Section Navigation">
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../ray-overview/index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-overview/getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-more-libs/installation.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../ray-overview/use-cases.html">Use Cases</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-air/getting-started.html">Ray for ML Infrastructure</a></li>

</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-overview/examples.html">Example Gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-overview/ray-libraries.html">Ecosystem</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../ray-core/walkthrough.html">Ray Core</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-core/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../ray-core/user-guide.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../ray-core/tasks.html">Tasks</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/tasks/nested-tasks.html">Nested Remote Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/tasks/generators.html">Dynamic generators</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../ray-more-libs/actors.html">Actors</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/actors/named-actors.html">Named Actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/actors/terminating-actors.html">Terminating Actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/actors/async_api.html">AsyncIO / Concurrency for Actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/actors/concurrency_group_api.html">Limiting Concurrency Per-Method with Concurrency Groups</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/actors/actor-utils.html">Utility Classes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/actors/out-of-band-communication.html">Out-of-band Communication</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/actors/task-orders.html">Actor Task Execution Order</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../ray-core/objects.html">Objects</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/objects/serialization.html">Serialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/objects/object-spilling.html">Object Spilling</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/handling-dependencies.html">Environment Dependencies</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../ray-core/scheduling/index.html">Scheduling</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/scheduling/resources.html">Resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/scheduling/accelerators.html">Accelerator Support</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/scheduling/placement-group.html">Placement Groups</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/scheduling/memory-management.html">Memory Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/scheduling/ray-oom-prevention.html">Out-Of-Memory Prevention</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../ray-core/fault-tolerance.html">Fault Tolerance</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/fault_tolerance/tasks.html">Task Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/fault_tolerance/actors.html">Actor Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/fault_tolerance/objects.html">Object Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/fault_tolerance/nodes.html">Node Fault Tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/fault_tolerance/gcs.html">GCS Fault Tolerance</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../ray-core/patterns/index.html">Design Patterns &amp; Anti-patterns</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/nested-tasks.html">Pattern: Using nested tasks to achieve nested parallelism</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/generators.html">Pattern: Using generators to reduce heap memory usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/limit-pending-tasks.html">Pattern: Using ray.wait to limit the number of pending tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/limit-running-tasks.html">Pattern: Using resources to limit the number of concurrently running tasks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/concurrent-operations-async-actor.html">Pattern: Using asyncio to run actor methods concurrently</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/actor-sync.html">Pattern: Using an actor to synchronize other tasks and actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/tree-of-actors.html">Pattern: Using a supervisor actor to manage a tree of actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/pipelining.html">Pattern: Using pipelining to increase throughput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/return-ray-put.html">Anti-pattern: Returning ray.put() ObjectRefs from a task harms performance and fault tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/ray-get-loop.html">Anti-pattern: Calling ray.get in a loop harms parallelism</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/unnecessary-ray-get.html">Anti-pattern: Calling ray.get unnecessarily harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/ray-get-submission-order.html">Anti-pattern: Processing results in submission order using ray.get increases runtime</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/ray-get-too-many-objects.html">Anti-pattern: Fetching too many objects at once with ray.get causes failure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/too-fine-grained-tasks.html">Anti-pattern: Over-parallelizing with too fine-grained tasks harms speedup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/redefine-task-actor-loop.html">Anti-pattern: Redefining the same remote function or class harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/pass-large-arg-by-value.html">Anti-pattern: Passing the same large argument by value repeatedly harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/closure-capture-large-objects.html">Anti-pattern: Closure capturing large objects harms performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/global-variables.html">Anti-pattern: Using global variables to share state between tasks and actors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/patterns/out-of-band-object-ref-serialization.html">Anti-pattern: Serialize ray.ObjectRef out of band</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../ray-core/advanced-topics.html">Advanced Topics</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/tips-for-first-time.html">Tips for first-time users</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/starting-ray.html">Starting Ray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/ray-generator.html">Ray Generators</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/namespaces.html">Using Namespaces</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/cross-language.html">Cross-Language Programming</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/using-ray-with-jupyter.html">Working with Jupyter Notebooks &amp; JupyterLab</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/ray-dag.html">Lazy Computation Graphs with the Ray DAG API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/miscellaneous.html">Miscellaneous Topics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/runtime_env_auth.html">Authenticating Remote URIs in runtime_env</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-core/user-spawn-processes.html">Lifetimes of a User-Spawn Process</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../ray-core/examples/overview.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/examples/automl_for_time_series.html">Simple AutoML for time series with Ray Core</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/examples/batch_prediction.html">Batch Prediction with Ray Core</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/examples/gentle_walkthrough.html">A Gentle Introduction to Ray Core by Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/examples/highly_parallel.html">Using Ray for Highly Parallelizable Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/examples/map_reduce.html">A Simple MapReduce Example with Ray Core</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/examples/monte_carlo_pi.html">Monte Carlo Estimation of π</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/examples/plot_hyperparameter.html">Simple Parallel Model Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/examples/plot_parameter_server.html">Parameter Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/examples/plot_pong_example.html">Learning to Play Pong</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/examples/web-crawler.html">Speed up your web crawler by parallelizing it with Ray</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../ray-core/api/index.html">Ray Core API</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/api/core.html">Core API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/api/scheduling.html">Scheduling API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/api/runtime-env.html">Runtime Env API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/api/utility.html">Utility</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/api/exceptions.html">Exceptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-core/api/cli.html">Ray Core CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-observability/reference/cli.html">State CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-observability/reference/api.html">State API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../data/data.html">Ray Data</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../data/overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../data/quickstart.html">Quickstart</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../data/user-guide.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../data/loading-data.html">Loading Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/inspecting-data.html">Inspecting Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/transforming-data.html">Transforming Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/iterating-over-data.html">Iterating over Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/shuffling-data.html">Shuffling Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/saving-data.html">Saving Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/working-with-images.html">Working with Images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/working-with-text.html">Working with Text</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/working-with-tensors.html">Working with Tensors / NumPy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/working-with-pytorch.html">Working with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/monitoring-your-workload.html">Monitoring Your Workload</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/execution-configurations.html">Execution Configurations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/batch_inference.html">End-to-end: Offline Batch Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/performance-tips.html">Advanced: Performance Tips and Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/custom-datasource-example.html">Advanced: Read and Write Custom File Types</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../data/examples.html">Examples</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../data/api/api.html">Ray Data API</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../data/api/input_output.html">Input/Output</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/api/dataset.html">Dataset API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/api/data_iterator.html">DataIterator API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/api/execution_options.html">ExecutionOptions API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/api/grouped_data.html">GroupedData API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/api/data_context.html">Global configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/api/utility.html">Utility</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/api/preprocessor.html">Preprocessor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../data/api/from_other_data_libs.html">API Guide for Users from Other Data Libraries</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../data/data-internals.html">Ray Data Internals</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../train/train.html">Ray Train</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../train/overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../train/getting-started-pytorch.html">PyTorch Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../train/getting-started-pytorch-lightning.html">PyTorch Lightning Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../train/getting-started-transformers.html">Hugging Face Transformers Guide</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../train/more-frameworks.html">More Frameworks</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../train/huggingface-accelerate.html">Hugging Face Accelerate Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/deepspeed.html">DeepSpeed Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/distributed-tensorflow-keras.html">TensorFlow and Keras Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/distributed-xgboost-lightgbm.html">XGBoost and LightGBM Guide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/horovod.html">Horovod Guide</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../train/user-guides.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../train/user-guides/data-loading-preprocessing.html">Data Loading and Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/user-guides/using-gpus.html">Configuring Scale and GPUs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/user-guides/persistent-storage.html">Configuring Persistent Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/user-guides/monitoring-logging.html">Monitoring and Logging Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/user-guides/checkpoints.html">Saving and Loading Checkpoints</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/user-guides/experiment-tracking.html">Experiment Tracking</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/user-guides/results.html">Inspecting Training Results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/user-guides/fault-tolerance.html">Handling Failures and Node Preemption</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/user-guides/reproducibility.html">Reproducibility</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../train/user-guides/hyperparameter-optimization.html">Hyperparameter Optimization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../train/examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../train/benchmarks.html">Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../train/api/api.html">Ray Train API</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tune.html">Ray Tune</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tune/getting-started.html">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tune/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../tune/tutorials/overview.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-run.html">Running Basic Experiments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-output.html">Logging and Outputs in Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-resources.html">Setting Trial Resources</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-search-spaces.html">Using Search Spaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-stopping.html">How to Define Stopping Criteria for a Ray Tune Experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-trial-checkpoints.html">How to Save and Load Trial Checkpoints</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-storage.html">How to Configure Persistent Storage in Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-fault-tolerance.html">How to Enable Fault Tolerance in Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-metrics.html">Using Callbacks and Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune_get_data_in_and_out.html">Getting Data in and out of Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/examples/tune_analyze_results.html">Analyzing Tune Experiment Results</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../tune/examples/pbt_guide.html">A Guide to Population Based Training with Tune</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/pbt_visualization/pbt_visualization.html">Visualizing and Understanding PBT</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-distributed.html">Deploying Tune in the Cloud</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-lifecycle.html">Tune Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/tutorials/tune-scalability.html">Scalability Benchmarks</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../tune/examples/index.html">Ray Tune Examples</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../tune/examples/ml-frameworks.html">Examples using Ray Tune with ML Frameworks</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/tune_mnist_keras.html">Keras Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/tune-pytorch-cifar.html">PyTorch Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/tune-pytorch-lightning.html">PyTorch Lightning Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/pbt_ppo_example.html">Ray RLlib Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/tune-xgboost.html">XGBoost Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/lightgbm_example.html">LightGBM Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/horovod_simple.html">Horovod Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/pbt_transformers.html">Hugging Face Transformers Example</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../tune/examples/experiment-tracking.html">Tune Experiment Tracking Examples</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/tune-wandb.html">Weights &amp; Biases Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/tune-mlflow.html">MLflow Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/tune-aim.html">Aim Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/tune-comet.html">Comet Example</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../tune/examples/hpo-frameworks.html">Tune Hyperparameter Optimization Framework Examples</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/ax_example.html">Ax Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/hyperopt_example.html">HyperOpt Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/bayesopt_example.html">Bayesopt Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/bohb_example.html">BOHB Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/nevergrad_example.html">Nevergrad Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tune/examples/optuna_example.html">Optuna Example</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/examples/other-examples.html">Other Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/examples/exercises.html">Exercises</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tune/faq.html">Ray Tune FAQ</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../tune/api/api.html">Ray Tune API</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/execution.html">Tune Execution (tune.Tuner)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/result_grid.html">Tune Experiment Results (tune.ResultGrid)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/trainable.html">Training in Tune (tune.Trainable, train.report)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/search_space.html">Tune Search Space API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/suggestion.html">Tune Search Algorithms (tune.search)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/schedulers.html">Tune Trial Schedulers (tune.schedulers)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/stoppers.html">Tune Stopping Mechanisms (tune.stopper)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/reporters.html">Tune Console Output (Reporters)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/syncing.html">Syncing in Tune (train.SyncConfig)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/logging.html">Tune Loggers (tune.logger)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/callbacks.html">Tune Callbacks (tune.Callback)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/env.html">Environment variables used by Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/integration.html">External library integrations for Ray Tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/internals.html">Tune Internals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tune/api/cli.html">Tune CLI (Experimental)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../serve/index.html">Ray Serve</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/getting_started.html">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/develop-and-deploy.html">Develop and Deploy an ML Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/model_composition.html">Deploy Compositions of Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/multi-app.html">Deploy Multiple Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/model-multiplexing.html">Model Multiplexing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/configure-serve-deployment.html">Configure Ray Serve deployments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/http-guide.html">Set Up FastAPI and HTTP</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../serve/production-guide/index.html">Production Guide</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/production-guide/config.html">Serve Config Files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/production-guide/kubernetes.html">Deploy on Kubernetes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/production-guide/docker.html">Custom Docker Images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/production-guide/fault-tolerance.html">Add End-to-End Fault Tolerance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/production-guide/handling-dependencies.html">Handle Dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/production-guide/best-practices.html">Best practices in production</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/monitoring.html">Monitor Your Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/resource-allocation.html">Resource Allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/autoscaling-guide.html">Ray Serve Autoscaling</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../serve/advanced-guides/index.html">Advanced Guides</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/advanced-guides/app-builder-guide.html">Pass Arguments to Applications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/advanced-guides/advanced-autoscaling.html">Advanced Ray Serve Autoscaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/advanced-guides/performance.html">Performance Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/advanced-guides/dyn-req-batch.html">Dynamic Request Batching</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/advanced-guides/inplace-updates.html">Updating Applications In-Place</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/advanced-guides/dev-workflow.html">Development Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/advanced-guides/grpc-guide.html">Set Up a gRPC Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/advanced-guides/managing-java-deployments.html">Experimental Java API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/advanced-guides/deploy-vm.html">Deploy on VM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../serve/advanced-guides/multi-app-container.html">Run Multiple Applications in Different Containers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/architecture.html">Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../serve/api/index.html">Ray Serve API</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../rllib/index.html">Ray RLlib</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../rllib/rllib-training.html">Getting Started with RLlib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rllib/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rllib/rllib-env.html">Environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rllib/rllib-algorithms.html">Algorithms</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../rllib/user-guides.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-31"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-advanced-api.html">Advanced Python APIs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-models.html">Models, Preprocessors, and Action Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-saving-and-loading-algos-and-policies.html">Saving and Loading your RL Algorithms and Policies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-concepts.html">How To Customize Policies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rllib/single-agent-episode.html">Episodes</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-replay-buffers.html">Replay Buffers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-offline.html">Working With Offline Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-catalogs.html">Catalog (Alpha)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-rlmodule.html">RL Modules (Alpha)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-learner.html">Learner (Alpha)</a></li>



<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-torch2x.html">Using RLlib with torch 2.x compile</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-fault-tolerance.html">Fault Tolerance And Elastic Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../rllib/rllib-dev.html">Install RLlib for Development</a></li>




</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../rllib/rllib-examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rllib/rllib-new-api-stack.html">RLlib’s new API stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../rllib/new-api-stack-migration-guide.html">New API stack migration guide</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../rllib/package_ref/index.html">Ray RLlib API</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-32"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../rllib/package_ref/algorithm.html">Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-33"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.copy.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.validate.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.validate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.freeze.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.freeze</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.callbacks.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.callbacks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.debugging.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.debugging</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.environment.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.evaluation.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.experimental.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.experimental</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.fault_tolerance.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.fault_tolerance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.framework.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.multi_agent.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.multi_agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.offline_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.python_environment.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.python_environment</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.reporting.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.reporting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.resources.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rl_module.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rl_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rollouts.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rollouts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.training.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_learner_class.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_learner_class</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_rl_module_spec.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_default_rl_module_spec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_evaluation_config_object.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_evaluation_config_object</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_rl_module_spec.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_rl_module_spec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_agent_setup.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_multi_agent_setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_rollout_fragment_length.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.get_rollout_fragment_length</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.validate_train_batch_size_vs_rollout_fragment_length.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.validate_train_batch_size_vs_rollout_fragment_length</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.html">ray.rllib.algorithms.algorithm.Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.setup.html">ray.rllib.algorithms.algorithm.Algorithm.setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.get_default_config.html">ray.rllib.algorithms.algorithm.Algorithm.get_default_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.compute_actions.html">ray.rllib.algorithms.algorithm.Algorithm.compute_actions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.compute_single_action.html">ray.rllib.algorithms.algorithm.Algorithm.compute_single_action</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.evaluate.html">ray.rllib.algorithms.algorithm.Algorithm.evaluate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.from_checkpoint.html">ray.rllib.algorithms.algorithm.Algorithm.from_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.from_state.html">ray.rllib.algorithms.algorithm.Algorithm.from_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.get_weights.html">ray.rllib.algorithms.algorithm.Algorithm.get_weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.set_weights.html">ray.rllib.algorithms.algorithm.Algorithm.set_weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.export_model.html">ray.rllib.algorithms.algorithm.Algorithm.export_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.export_policy_checkpoint.html">ray.rllib.algorithms.algorithm.Algorithm.export_policy_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.export_policy_model.html">ray.rllib.algorithms.algorithm.Algorithm.export_policy_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.restore.html">ray.rllib.algorithms.algorithm.Algorithm.restore</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.restore_workers.html">ray.rllib.algorithms.algorithm.Algorithm.restore_workers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.save.html">ray.rllib.algorithms.algorithm.Algorithm.save</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.save_checkpoint.html">ray.rllib.algorithms.algorithm.Algorithm.save_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.train.html">ray.rllib.algorithms.algorithm.Algorithm.train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.training_step.html">ray.rllib.algorithms.algorithm.Algorithm.training_step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.add_policy.html">ray.rllib.algorithms.algorithm.Algorithm.add_policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm.Algorithm.remove_policy.html">ray.rllib.algorithms.algorithm.Algorithm.remove_policy</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../rllib/package_ref/env.html">Environments</a><input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-34"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/env/base_env.html">BaseEnv API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/env/multi_agent_env.html">MultiAgentEnv API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/env/vector_env.html">VectorEnv API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/env/external_env.html">ExternalEnv API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/env/single_agent_episode.html">SingleAgentEpisode API</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../rllib/package_ref/policy.html">Policy API</a><input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-35"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.html">ray.rllib.policy.policy.Policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.html">ray.rllib.policy.torch_policy_v2.TorchPolicyV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.make_model.html">ray.rllib.policy.torch_policy_v2.TorchPolicyV2.make_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.make_model_and_action_dist.html">ray.rllib.policy.torch_policy_v2.TorchPolicyV2.make_model_and_action_dist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.make_model.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.make_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.compute_actions.html">ray.rllib.policy.policy.Policy.compute_actions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.compute_actions_from_input_dict.html">ray.rllib.policy.policy.Policy.compute_actions_from_input_dict</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.policy.Policy.compute_single_action.html">ray.rllib.policy.policy.Policy.compute_single_action</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.action_sampler_fn.html">ray.rllib.policy.torch_policy_v2.TorchPolicyV2.action_sampler_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.action_distribution_fn.html">ray.rllib.policy.torch_policy_v2.TorchPolicyV2.action_distribution_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.extra_action_out.html">ray.rllib.policy.torch_policy_v2.TorchPolicyV2.extra_action_out</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.action_sampler_fn.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.action_sampler_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.action_distribution_fn.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.action_distribution_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.extra_action_out_fn.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.extra_action_out_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.compute_gradients.html">ray.rllib.policy.Policy.compute_gradients</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.apply_gradients.html">ray.rllib.policy.Policy.apply_gradients</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.extra_compute_grad_fetches.html">ray.rllib.policy.torch_policy_v2.TorchPolicyV2.extra_compute_grad_fetches</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.extra_grad_process.html">ray.rllib.policy.torch_policy_v2.TorchPolicyV2.extra_grad_process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.grad_stats_fn.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.grad_stats_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.compute_gradients_fn.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.compute_gradients_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.apply_gradients_fn.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.apply_gradients_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.extra_learn_fetches_fn.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.extra_learn_fetches_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.learn_on_batch.html">ray.rllib.policy.Policy.learn_on_batch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.load_batch_into_buffer.html">ray.rllib.policy.Policy.load_batch_into_buffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.learn_on_loaded_batch.html">ray.rllib.policy.Policy.learn_on_loaded_batch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.learn_on_batch_from_replay_buffer.html">ray.rllib.policy.Policy.learn_on_batch_from_replay_buffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.get_num_samples_loaded_into_buffer.html">ray.rllib.policy.Policy.get_num_samples_loaded_into_buffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.loss.html">ray.rllib.policy.Policy.loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.compute_log_likelihoods.html">ray.rllib.policy.Policy.compute_log_likelihoods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.on_global_var_update.html">ray.rllib.policy.Policy.on_global_var_update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.postprocess_trajectory.html">ray.rllib.policy.Policy.postprocess_trajectory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.optimizer.html">ray.rllib.policy.torch_policy_v2.TorchPolicyV2.optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.get_tower_stats.html">ray.rllib.policy.torch_policy_v2.TorchPolicyV2.get_tower_stats</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.optimizer.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.stats_fn.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.stats_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.from_checkpoint.html">ray.rllib.policy.Policy.from_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.export_checkpoint.html">ray.rllib.policy.Policy.export_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.export_model.html">ray.rllib.policy.Policy.export_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.from_state.html">ray.rllib.policy.Policy.from_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.get_weights.html">ray.rllib.policy.Policy.get_weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.set_weights.html">ray.rllib.policy.Policy.set_weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.get_state.html">ray.rllib.policy.Policy.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.set_state.html">ray.rllib.policy.Policy.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.import_model_from_h5.html">ray.rllib.policy.Policy.import_model_from_h5</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.Policy.get_initial_state.html">ray.rllib.Policy.get_initial_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.Policy.num_state_tensors.html">ray.rllib.Policy.num_state_tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.Policy.is_recurrent.html">ray.rllib.Policy.is_recurrent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.apply.html">ray.rllib.policy.Policy.apply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.get_session.html">ray.rllib.policy.Policy.get_session</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.init_view_requirements.html">ray.rllib.policy.Policy.init_view_requirements</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.get_host.html">ray.rllib.policy.Policy.get_host</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.Policy.get_exploration_state.html">ray.rllib.policy.Policy.get_exploration_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.torch_policy_v2.TorchPolicyV2.get_batch_divisibility_req.html">ray.rllib.policy.torch_policy_v2.TorchPolicyV2.get_batch_divisibility_req</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.variables.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.get_batch_divisibility_req.html">ray.rllib.policy.eager_tf_policy_v2.EagerTFPolicyV2.get_batch_divisibility_req</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../rllib/package_ref/models.html">Model APIs</a><input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-36"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.modelv2.ModelV2.html">ray.rllib.models.modelv2.ModelV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.torch.torch_modelv2.TorchModelV2.html">ray.rllib.models.torch.torch_modelv2.TorchModelV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.tf.tf_modelv2.TFModelV2.html">ray.rllib.models.tf.tf_modelv2.TFModelV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.modelv2.ModelV2.forward.html">ray.rllib.models.modelv2.ModelV2.forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.modelv2.ModelV2.value_function.html">ray.rllib.models.modelv2.ModelV2.value_function</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.modelv2.ModelV2.last_output.html">ray.rllib.models.modelv2.ModelV2.last_output</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.modelv2.ModelV2.get_initial_state.html">ray.rllib.models.modelv2.ModelV2.get_initial_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.modelv2.ModelV2.is_time_major.html">ray.rllib.models.modelv2.ModelV2.is_time_major</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.modelv2.ModelV2.variables.html">ray.rllib.models.modelv2.ModelV2.variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.modelv2.ModelV2.trainable_variables.html">ray.rllib.models.modelv2.ModelV2.trainable_variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.distributions.Distribution.html">ray.rllib.models.distributions.Distribution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.modelv2.ModelV2.custom_loss.html">ray.rllib.models.modelv2.ModelV2.custom_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.models.modelv2.ModelV2.metrics.html">ray.rllib.models.modelv2.ModelV2.metrics</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../rllib/package_ref/catalogs.html">Catalog API</a><input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-37"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.models.catalog.Catalog.html">ray.rllib.core.models.catalog.Catalog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.models.catalog.Catalog.build_encoder.html">ray.rllib.core.models.catalog.Catalog.build_encoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.models.catalog.Catalog.get_action_dist_cls.html">ray.rllib.core.models.catalog.Catalog.get_action_dist_cls</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.models.catalog.Catalog.get_tokenizer_config.html">ray.rllib.core.models.catalog.Catalog.get_tokenizer_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.models.catalog.Catalog.latent_dims.html">ray.rllib.core.models.catalog.Catalog.latent_dims</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.models.catalog.Catalog._determine_components_hook.html">ray.rllib.core.models.catalog.Catalog._determine_components_hook</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.models.catalog.Catalog._get_encoder_config.html">ray.rllib.core.models.catalog.Catalog._get_encoder_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.models.catalog.Catalog._get_dist_cls_from_action_space.html">ray.rllib.core.models.catalog.Catalog._get_dist_cls_from_action_space</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../rllib/package_ref/rl_modules.html">RLModule API</a><input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-38"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.build.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.build</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleSpec.get_rl_module_config.html">ray.rllib.core.rl_module.rl_module.RLModuleSpec.get_rl_module_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleConfig.html">ray.rllib.core.rl_module.rl_module.RLModuleConfig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleConfig.to_dict.html">ray.rllib.core.rl_module.rl_module.RLModuleConfig.to_dict</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleConfig.from_dict.html">ray.rllib.core.rl_module.rl_module.RLModuleConfig.from_dict</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModuleConfig.get_catalog.html">ray.rllib.core.rl_module.rl_module.RLModuleConfig.get_catalog</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.build.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.build</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.get_multi_rl_module_config.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModuleSpec.get_multi_rl_module_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.html">ray.rllib.core.rl_module.rl_module.RLModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.as_multi_rl_module.html">ray.rllib.core.rl_module.rl_module.RLModule.as_multi_rl_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_train.html">ray.rllib.core.rl_module.rl_module.RLModule.forward_train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration.html">ray.rllib.core.rl_module.rl_module.RLModule.forward_exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.forward_inference.html">ray.rllib.core.rl_module.rl_module.RLModule.forward_inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule._forward_train.html">ray.rllib.core.rl_module.rl_module.RLModule._forward_train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule._forward_exploration.html">ray.rllib.core.rl_module.rl_module.RLModule._forward_exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule._forward_inference.html">ray.rllib.core.rl_module.rl_module.RLModule._forward_inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.input_specs_inference.html">ray.rllib.core.rl_module.rl_module.RLModule.input_specs_inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.input_specs_exploration.html">ray.rllib.core.rl_module.rl_module.RLModule.input_specs_exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.input_specs_train.html">ray.rllib.core.rl_module.rl_module.RLModule.input_specs_train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.output_specs_inference.html">ray.rllib.core.rl_module.rl_module.RLModule.output_specs_inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.output_specs_exploration.html">ray.rllib.core.rl_module.rl_module.RLModule.output_specs_exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.output_specs_train.html">ray.rllib.core.rl_module.rl_module.RLModule.output_specs_train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.get_state.html">ray.rllib.core.rl_module.rl_module.RLModule.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.set_state.html">ray.rllib.core.rl_module.rl_module.RLModule.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.save_to_path.html">ray.rllib.core.rl_module.rl_module.RLModule.save_to_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.restore_from_path.html">ray.rllib.core.rl_module.rl_module.RLModule.restore_from_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.rl_module.RLModule.from_checkpoint.html">ray.rllib.core.rl_module.rl_module.RLModule.from_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.setup.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.as_multi_rl_module.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.as_multi_rl_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.add_module.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.add_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.remove_module.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.remove_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.save_to_path.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.save_to_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.restore_from_path.html">ray.rllib.core.rl_module.multi_rl_module.MultiRLModule.restore_from_path</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../rllib/package_ref/learner.html">LearnerGroup API</a><input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-39"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.resources.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.resources</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rl_module.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.rl_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.training.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group.html">ray.rllib.algorithms.algorithm_config.AlgorithmConfig.build_learner_group</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.learner.learner_group.LearnerGroup.html">ray.rllib.core.learner.learner_group.LearnerGroup</a></li>
</ul>
</li>

<li class="toctree-l3 has-children"><a class="reference internal" href="../../../rllib/package_ref/evaluation.html">Sampling the Environment or offline data</a><input class="toctree-checkbox" id="toctree-checkbox-40" name="toctree-checkbox-40" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-40"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.html">ray.rllib.evaluation.rollout_worker.RolloutWorker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.add_policy.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.add_policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.remove_policy.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.remove_policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.get_policy.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.get_policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.set_is_policy_to_train.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.set_is_policy_to_train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.set_policy_mapping_fn.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.set_policy_mapping_fn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.for_policy.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.for_policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.foreach_policy.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.foreach_policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.foreach_policy_to_train.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.foreach_policy_to_train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.get_filters.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.get_filters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.get_global_vars.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.get_global_vars</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.set_global_vars.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.set_global_vars</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.get_host.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.get_host</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.get_metrics.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.get_metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.get_node_ip.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.get_node_ip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.get_weights.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.get_weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.set_weights.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.set_weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.get_state.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.set_state.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.lock.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.lock</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.unlock.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.unlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.sample.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.sample_with_count.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.sample_with_count</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.sample_and_learn.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.sample_and_learn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.learn_on_batch.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.learn_on_batch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.setup_torch_data_parallel.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.setup_torch_data_parallel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.compute_gradients.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.compute_gradients</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.apply_gradients.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.apply_gradients</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.foreach_env.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.foreach_env</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.foreach_env_with_context.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.foreach_env_with_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.stop.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.stop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.apply.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.apply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.sync_filters.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.sync_filters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.find_free_port.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.find_free_port</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.creation_args.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.creation_args</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.rollout_worker.RolloutWorker.assert_healthy.html">ray.rllib.evaluation.rollout_worker.RolloutWorker.assert_healthy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner.EnvRunner.html">ray.rllib.env.env_runner.EnvRunner</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.html">ray.rllib.env.env_runner_group.EnvRunnerGroup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.stop.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.stop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.reset.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.reset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.add_workers.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.add_workers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_worker.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_worker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_worker_with_id.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_worker_with_id</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_worker_async.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_worker_async</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.fetch_ready_async_reqs.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.fetch_ready_async_reqs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.num_in_flight_async_reqs.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.num_in_flight_async_reqs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.local_worker.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.local_worker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.remote_workers.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.remote_workers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.num_healthy_remote_workers.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.num_healthy_remote_workers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.num_healthy_workers.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.num_healthy_workers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.num_remote_worker_restarts.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.num_remote_worker_restarts</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.probe_unhealthy_workers.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.probe_unhealthy_workers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.add_policy.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.add_policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_env.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_env</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_env_with_context.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_env_with_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_policy.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_policy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_policy_to_train.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.foreach_policy_to_train</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.env.env_runner_group.EnvRunnerGroup.sync_weights.html">ray.rllib.env.env_runner_group.EnvRunnerGroup.sync_weights</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.offline.input_reader.InputReader.html">ray.rllib.offline.input_reader.InputReader</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.offline.input_reader.InputReader.next.html">ray.rllib.offline.input_reader.InputReader.next</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.sampler.SamplerInput.html">ray.rllib.evaluation.sampler.SamplerInput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.sampler.SamplerInput.get_data.html">ray.rllib.evaluation.sampler.SamplerInput.get_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.sampler.SamplerInput.get_extra_batches.html">ray.rllib.evaluation.sampler.SamplerInput.get_extra_batches</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.sampler.SamplerInput.get_metrics.html">ray.rllib.evaluation.sampler.SamplerInput.get_metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.evaluation.sampler.SyncSampler.html">ray.rllib.evaluation.sampler.SyncSampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.offline.json_reader.JsonReader.html">ray.rllib.offline.json_reader.JsonReader</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.offline.json_reader.JsonReader.read_all_files.html">ray.rllib.offline.json_reader.JsonReader.read_all_files</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.offline.mixed_input.MixedInput.html">ray.rllib.offline.mixed_input.MixedInput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.offline.d4rl_reader.D4RLReader.html">ray.rllib.offline.d4rl_reader.D4RLReader</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.offline.io_context.IOContext.html">ray.rllib.offline.io_context.IOContext</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.offline.io_context.IOContext.default_sampler_input.html">ray.rllib.offline.io_context.IOContext.default_sampler_input</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.policy_map.PolicyMap.html">ray.rllib.policy.policy_map.PolicyMap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.policy_map.PolicyMap.items.html">ray.rllib.policy.policy_map.PolicyMap.items</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.policy_map.PolicyMap.keys.html">ray.rllib.policy.policy_map.PolicyMap.keys</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.policy_map.PolicyMap.values.html">ray.rllib.policy.policy_map.PolicyMap.values</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.html">ray.rllib.policy.sample_batch.SampleBatch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.set_get_interceptor.html">ray.rllib.policy.sample_batch.SampleBatch.set_get_interceptor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.is_training.html">ray.rllib.policy.sample_batch.SampleBatch.is_training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.set_training.html">ray.rllib.policy.sample_batch.SampleBatch.set_training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.as_multi_agent.html">ray.rllib.policy.sample_batch.SampleBatch.as_multi_agent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.get.html">ray.rllib.policy.sample_batch.SampleBatch.get</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.to_device.html">ray.rllib.policy.sample_batch.SampleBatch.to_device</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.right_zero_pad.html">ray.rllib.policy.sample_batch.SampleBatch.right_zero_pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.slice.html">ray.rllib.policy.sample_batch.SampleBatch.slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.split_by_episode.html">ray.rllib.policy.sample_batch.SampleBatch.split_by_episode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.shuffle.html">ray.rllib.policy.sample_batch.SampleBatch.shuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.columns.html">ray.rllib.policy.sample_batch.SampleBatch.columns</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.rows.html">ray.rllib.policy.sample_batch.SampleBatch.rows</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.copy.html">ray.rllib.policy.sample_batch.SampleBatch.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.is_single_trajectory.html">ray.rllib.policy.sample_batch.SampleBatch.is_single_trajectory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.is_terminated_or_truncated.html">ray.rllib.policy.sample_batch.SampleBatch.is_terminated_or_truncated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.env_steps.html">ray.rllib.policy.sample_batch.SampleBatch.env_steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.SampleBatch.agent_steps.html">ray.rllib.policy.sample_batch.SampleBatch.agent_steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.MultiAgentBatch.html">ray.rllib.policy.sample_batch.MultiAgentBatch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.MultiAgentBatch.env_steps.html">ray.rllib.policy.sample_batch.MultiAgentBatch.env_steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.policy.sample_batch.MultiAgentBatch.agent_steps.html">ray.rllib.policy.sample_batch.MultiAgentBatch.agent_steps</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../rllib/package_ref/replay-buffers.html">Replay Buffer API</a><input class="toctree-checkbox" id="toctree-checkbox-41" name="toctree-checkbox-41" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-41"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.StorageUnit.html">ray.rllib.utils.replay_buffers.replay_buffer.StorageUnit</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.prioritized_replay_buffer.PrioritizedReplayBuffer.html">ray.rllib.utils.replay_buffers.prioritized_replay_buffer.PrioritizedReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.reservoir_replay_buffer.ReservoirReplayBuffer.html">ray.rllib.utils.replay_buffers.reservoir_replay_buffer.ReservoirReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.sample.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.add.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.add</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.get_state.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.set_state.html">ray.rllib.utils.replay_buffers.replay_buffer.ReplayBuffer.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.multi_agent_replay_buffer.MultiAgentReplayBuffer.html">ray.rllib.utils.replay_buffers.multi_agent_replay_buffer.MultiAgentReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer.html">ray.rllib.utils.replay_buffers.multi_agent_prioritized_replay_buffer.MultiAgentPrioritizedReplayBuffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.utils.update_priorities_in_replay_buffer.html">ray.rllib.utils.replay_buffers.utils.update_priorities_in_replay_buffer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.replay_buffers.utils.sample_min_n_steps_from_buffer.html">ray.rllib.utils.replay_buffers.utils.sample_min_n_steps_from_buffer</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../rllib/package_ref/utils.html">RLlib Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-42" name="toctree-checkbox-42" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-42"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.exploration.Exploration.html">ray.rllib.utils.exploration.exploration.Exploration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.random.Random.html">ray.rllib.utils.exploration.random.Random</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.stochastic_sampling.StochasticSampling.html">ray.rllib.utils.exploration.stochastic_sampling.StochasticSampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.epsilon_greedy.EpsilonGreedy.html">ray.rllib.utils.exploration.epsilon_greedy.EpsilonGreedy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.gaussian_noise.GaussianNoise.html">ray.rllib.utils.exploration.gaussian_noise.GaussianNoise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.ornstein_uhlenbeck_noise.OrnsteinUhlenbeckNoise.html">ray.rllib.utils.exploration.ornstein_uhlenbeck_noise.OrnsteinUhlenbeckNoise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.random_encoder.RE3.html">ray.rllib.utils.exploration.random_encoder.RE3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.curiosity.Curiosity.html">ray.rllib.utils.exploration.curiosity.Curiosity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.parameter_noise.ParameterNoise.html">ray.rllib.utils.exploration.parameter_noise.ParameterNoise</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.exploration.Exploration.get_exploration_action.html">ray.rllib.utils.exploration.exploration.Exploration.get_exploration_action</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.exploration.Exploration.before_compute_actions.html">ray.rllib.utils.exploration.exploration.Exploration.before_compute_actions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.exploration.Exploration.on_episode_start.html">ray.rllib.utils.exploration.exploration.Exploration.on_episode_start</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.exploration.Exploration.on_episode_end.html">ray.rllib.utils.exploration.exploration.Exploration.on_episode_end</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.exploration.Exploration.postprocess_trajectory.html">ray.rllib.utils.exploration.exploration.Exploration.postprocess_trajectory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.exploration.Exploration.get_state.html">ray.rllib.utils.exploration.exploration.Exploration.get_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.exploration.exploration.Exploration.set_state.html">ray.rllib.utils.exploration.exploration.Exploration.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.schedules.schedule.Schedule.html">ray.rllib.utils.schedules.schedule.Schedule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.schedules.constant_schedule.ConstantSchedule.html">ray.rllib.utils.schedules.constant_schedule.ConstantSchedule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.schedules.linear_schedule.LinearSchedule.html">ray.rllib.utils.schedules.linear_schedule.LinearSchedule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.schedules.piecewise_schedule.PiecewiseSchedule.html">ray.rllib.utils.schedules.piecewise_schedule.PiecewiseSchedule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule.html">ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.schedules.polynomial_schedule.PolynomialSchedule.html">ray.rllib.utils.schedules.polynomial_schedule.PolynomialSchedule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.schedules.schedule.Schedule.value.html">ray.rllib.utils.schedules.schedule.Schedule.value</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.schedules.schedule.Schedule.__call__.html">ray.rllib.utils.schedules.schedule.Schedule.__call__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.execution.train_ops.multi_gpu_train_one_step.html">ray.rllib.execution.train_ops.multi_gpu_train_one_step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.execution.train_ops.train_one_step.html">ray.rllib.execution.train_ops.train_one_step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.framework.try_import_torch.html">ray.rllib.utils.framework.try_import_torch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.framework.try_import_tf.html">ray.rllib.utils.framework.try_import_tf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.framework.try_import_tfp.html">ray.rllib.utils.framework.try_import_tfp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.explained_variance.html">ray.rllib.utils.tf_utils.explained_variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.flatten_inputs_to_1d_tensor.html">ray.rllib.utils.tf_utils.flatten_inputs_to_1d_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.get_gpu_devices.html">ray.rllib.utils.tf_utils.get_gpu_devices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.get_placeholder.html">ray.rllib.utils.tf_utils.get_placeholder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.huber_loss.html">ray.rllib.utils.tf_utils.huber_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.l2_loss.html">ray.rllib.utils.tf_utils.l2_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.make_tf_callable.html">ray.rllib.utils.tf_utils.make_tf_callable</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.minimize_and_clip.html">ray.rllib.utils.tf_utils.minimize_and_clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.one_hot.html">ray.rllib.utils.tf_utils.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.reduce_mean_ignore_inf.html">ray.rllib.utils.tf_utils.reduce_mean_ignore_inf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.scope_vars.html">ray.rllib.utils.tf_utils.scope_vars</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.warn_if_infinite_kl_divergence.html">ray.rllib.utils.tf_utils.warn_if_infinite_kl_divergence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tf_utils.zero_logps_from_actions.html">ray.rllib.utils.tf_utils.zero_logps_from_actions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.apply_grad_clipping.html">ray.rllib.utils.torch_utils.apply_grad_clipping</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.concat_multi_gpu_td_errors.html">ray.rllib.utils.torch_utils.concat_multi_gpu_td_errors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.convert_to_torch_tensor.html">ray.rllib.utils.torch_utils.convert_to_torch_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.explained_variance.html">ray.rllib.utils.torch_utils.explained_variance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.flatten_inputs_to_1d_tensor.html">ray.rllib.utils.torch_utils.flatten_inputs_to_1d_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.global_norm.html">ray.rllib.utils.torch_utils.global_norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.huber_loss.html">ray.rllib.utils.torch_utils.huber_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.l2_loss.html">ray.rllib.utils.torch_utils.l2_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.minimize_and_clip.html">ray.rllib.utils.torch_utils.minimize_and_clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.one_hot.html">ray.rllib.utils.torch_utils.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.reduce_mean_ignore_inf.html">ray.rllib.utils.torch_utils.reduce_mean_ignore_inf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.sequence_mask.html">ray.rllib.utils.torch_utils.sequence_mask</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.warn_if_infinite_kl_divergence.html">ray.rllib.utils.torch_utils.warn_if_infinite_kl_divergence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.set_torch_seed.html">ray.rllib.utils.torch_utils.set_torch_seed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.torch_utils.softmax_cross_entropy_with_logits.html">ray.rllib.utils.torch_utils.softmax_cross_entropy_with_logits</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.aligned_array.html">ray.rllib.utils.numpy.aligned_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.concat_aligned.html">ray.rllib.utils.numpy.concat_aligned</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.convert_to_numpy.html">ray.rllib.utils.numpy.convert_to_numpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.fc.html">ray.rllib.utils.numpy.fc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.flatten_inputs_to_1d_tensor.html">ray.rllib.utils.numpy.flatten_inputs_to_1d_tensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.make_action_immutable.html">ray.rllib.utils.numpy.make_action_immutable</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.huber_loss.html">ray.rllib.utils.numpy.huber_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.l2_loss.html">ray.rllib.utils.numpy.l2_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.lstm.html">ray.rllib.utils.numpy.lstm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.one_hot.html">ray.rllib.utils.numpy.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.relu.html">ray.rllib.utils.numpy.relu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.sigmoid.html">ray.rllib.utils.numpy.sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.numpy.softmax.html">ray.rllib.utils.numpy.softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.checkpoints.Checkpointable.html">ray.rllib.utils.checkpoints.Checkpointable</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.checkpoints.convert_to_msgpack_checkpoint.html">ray.rllib.utils.checkpoints.convert_to_msgpack_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.checkpoints.convert_to_msgpack_policy_checkpoint.html">ray.rllib.utils.checkpoints.convert_to_msgpack_policy_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.checkpoints.get_checkpoint_info.html">ray.rllib.utils.checkpoints.get_checkpoint_info</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.checkpoints.try_import_msgpack.html">ray.rllib.utils.checkpoints.try_import_msgpack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.policy.compute_log_likelihoods_from_input_dict.html">ray.rllib.utils.policy.compute_log_likelihoods_from_input_dict</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.policy.create_policy_for_framework.html">ray.rllib.utils.policy.create_policy_for_framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.policy.local_policy_inference.html">ray.rllib.utils.policy.local_policy_inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.policy.parse_policy_specs_from_checkpoint.html">ray.rllib.utils.policy.parse_policy_specs_from_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.utils.tensor_dtype.get_np_dtype.html">ray.rllib.utils.tensor_dtype.get_np_dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.common.CLIArguments.html">ray.rllib.common.CLIArguments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.common.FrameworkEnum.html">ray.rllib.common.FrameworkEnum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.common.SupportedFileType.html">ray.rllib.common.SupportedFileType</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.core.rl_module.validate_module_id.html">ray.rllib.core.rl_module.validate_module_id</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../rllib/package_ref/doc/ray.rllib.train.load_experiments_from_file.html">ray.rllib.train.load_experiments_from_file</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../rllib/package_ref/external-app.html">External Application API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../ray-more-libs/index.html">More Libraries</a><input class="toctree-checkbox" id="toctree-checkbox-43" name="toctree-checkbox-43" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-43"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../joblib.html">Distributed Scikit-learn / Joblib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-more-libs/multiprocessing.html">Distributed multiprocessing.Pool</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-more-libs/ray-collective.html">Ray Collective Communication Lib</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../ray-more-libs/dask-on-ray.html">Using Dask on Ray</a><input class="toctree-checkbox" id="toctree-checkbox-44" name="toctree-checkbox-44" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-44"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../ray-more-libs/doc/ray.util.dask.RayDaskCallback.html">ray.util.dask.RayDaskCallback</a><input class="toctree-checkbox" id="toctree-checkbox-45" name="toctree-checkbox-45" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-45"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-more-libs/doc/ray.util.dask.RayDaskCallback.ray_active.html">ray.util.dask.RayDaskCallback.ray_active</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_presubmit.html">ray.util.dask.callbacks.RayDaskCallback._ray_presubmit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit.html">ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_pretask.html">ray.util.dask.callbacks.RayDaskCallback._ray_pretask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_posttask.html">ray.util.dask.callbacks.RayDaskCallback._ray_posttask</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit_all.html">ray.util.dask.callbacks.RayDaskCallback._ray_postsubmit_all</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-more-libs/doc/ray.util.dask.callbacks.RayDaskCallback._ray_finish.html">ray.util.dask.callbacks.RayDaskCallback._ray_finish</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-more-libs/raydp.html">Using Spark on Ray (RayDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-more-libs/mars-on-ray.html">Using Mars on Ray</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-more-libs/modin/index.html">Using Pandas on Ray (Modin)</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../workflows/index.html">Ray Workflows (Alpha)</a><input class="toctree-checkbox" id="toctree-checkbox-46" name="toctree-checkbox-46" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-46"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../workflows/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../workflows/basics.html">Getting Started</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../workflows/management.html">Workflow Management</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../workflows/metadata.html">Workflow Metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../workflows/events.html">Events</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../workflows/comparison.html">API Comparisons</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../workflows/advanced.html">Advanced Topics</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../workflows/api/api.html">Ray Workflows API</a><input class="toctree-checkbox" id="toctree-checkbox-47" name="toctree-checkbox-47" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-47"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../workflows/api/execution.html">Workflow Execution API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../workflows/api/management.html">Workflow Management API</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../ray-more-libs/cluster/index.html">Ray Clusters</a><input class="toctree-checkbox" id="toctree-checkbox-48" name="toctree-checkbox-48" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-48"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../cluster/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../cluster/kubernetes/index.html">Deploying on Kubernetes</a><input class="toctree-checkbox" id="toctree-checkbox-49" name="toctree-checkbox-49" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-49"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../cluster/kubernetes/getting-started.html">Getting Started with KubeRay</a><input class="toctree-checkbox" id="toctree-checkbox-50" name="toctree-checkbox-50" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-50"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/getting-started/raycluster-quick-start.html">RayCluster Quickstart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/getting-started/rayjob-quick-start.html">RayJob Quickstart</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/getting-started/rayservice-quick-start.html">RayService Quickstart</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../cluster/kubernetes/user-guides.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-51" name="toctree-checkbox-51" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-51"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/rayservice.html">Deploy Ray Serve Apps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/rayservice-high-availability.html">RayService high availability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/observability.html">KubeRay Observability</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/upgrade-guide.html">KubeRay upgrade guide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/k8s-cluster-setup.html">Managed Kubernetes services</a></li>



<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/storage.html">Best Practices for Storage and Dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/config.html">RayCluster Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/configuring-autoscaling.html">KubeRay Autoscaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/kuberay-gcs-ft.html">GCS fault tolerance in KubeRay</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/gke-gcs-bucket.html">Configuring KubeRay to use Google Cloud Storage Buckets in GKE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/logging.html">Log Persistence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/gpu.html">Using GPUs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/tpu.html">Use TPUs with KubeRay</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/rayserve-dev-doc.html">Developing Ray Serve Python scripts on a RayCluster</a></li>









<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/pod-command.html">Specify container commands for Ray head/worker Pods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/pod-security.html">Pod Security</a></li>






<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/helm-chart-rbac.html">Helm Chart RBAC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/tls.html">TLS Authentication</a></li>






<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/k8s-autoscaler.html">(Advanced) Understanding the Ray Autoscaler in the Context of Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/user-guides/static-ray-cluster-without-kuberay.html">(Advanced) Deploying a static Ray cluster without KubeRay</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../cluster/kubernetes/examples.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-52" name="toctree-checkbox-52" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-52"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/ml-example.html">Ray Train XGBoostTrainer on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/gpu-training-example.html">Train PyTorch ResNet model with GPUs on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/mnist-training-example.html">Train a PyTorch model on Fashion MNIST with CPUs on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/stable-diffusion-rayservice.html">Serve a StableDiffusion text-to-image model on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/tpu-serve-stable-diffusion.html">Serve a Stable Diffusion model on GKE with TPUs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/mobilenet-rayservice.html">Serve a MobileNet image classifier on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/text-summarizer-rayservice.html">Serve a text summarizer on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/rayjob-batch-inference-example.html">RayJob Batch Inference Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/rayjob-kueue-priority-scheduling.html">Priority Scheduling with RayJob and Kueue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/rayjob-kueue-gang-scheduling.html">Gang Scheduling with RayJob and Kueue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/distributed-checkpointing-with-gcsfuse.html">Distributed checkpointing with KubeRay and GCSFuse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/modin-example.html">Use Modin with Ray on Kubernetes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/examples/vllm-rayservice.html">Serve a Large Language Model with vLLM on Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../cluster/kubernetes/k8s-ecosystem.html">KubeRay Ecosystem</a><input class="toctree-checkbox" id="toctree-checkbox-53" name="toctree-checkbox-53" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-53"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/k8s-ecosystem/ingress.html">Ingress</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/k8s-ecosystem/prometheus-grafana.html">Using Prometheus and Grafana</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/k8s-ecosystem/pyspy.html">Profiling with py-spy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/k8s-ecosystem/volcano.html">KubeRay integration with Volcano</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/k8s-ecosystem/kubeflow.html">Kubeflow: an interactive development solution</a></li>


<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/k8s-ecosystem/kueue.html">Gang scheduling and priority scheduling for RayJob with Kueue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/k8s-ecosystem/istio.html">mTLS and L7 observability with Istio</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../cluster/kubernetes/benchmarks.html">KubeRay Benchmarks</a><input class="toctree-checkbox" id="toctree-checkbox-54" name="toctree-checkbox-54" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-54"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/benchmarks/memory-scalability-benchmark.html">KubeRay memory and scalability benchmark</a></li>

</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../cluster/kubernetes/troubleshooting.html">KubeRay Troubleshooting</a><input class="toctree-checkbox" id="toctree-checkbox-55" name="toctree-checkbox-55" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-55"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/troubleshooting/troubleshooting.html">Troubleshooting guide</a></li>

<li class="toctree-l4"><a class="reference internal" href="../../../cluster/kubernetes/troubleshooting/rayservice-troubleshooting.html">RayService troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../cluster/kubernetes/references.html">API Reference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../cluster/vms/index.html">Deploying on VMs</a><input class="toctree-checkbox" id="toctree-checkbox-56" name="toctree-checkbox-56" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-56"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../cluster/vms/getting-started.html">Getting Started</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../cluster/vms/user-guides/index.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-57" name="toctree-checkbox-57" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-57"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/vms/user-guides/launching-clusters/index.html">Launching Ray Clusters on AWS, GCP, Azure, vSphere, On-Prem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/vms/user-guides/large-cluster-best-practices.html">Best practices for deploying large clusters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/vms/user-guides/configuring-autoscaling.html">Configuring Autoscaling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/vms/user-guides/logging.html">Log Persistence</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/vms/user-guides/community/index.html">Community Supported Cluster Managers</a></li>

</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../cluster/vms/examples/index.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-58" name="toctree-checkbox-58" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-58"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/vms/examples/ml-example.html">Ray Train XGBoostTrainer on VMs</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../cluster/vms/references/index.html">API References</a><input class="toctree-checkbox" id="toctree-checkbox-59" name="toctree-checkbox-59" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-59"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/vms/references/ray-cluster-cli.html">Cluster Launcher Commands</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/vms/references/ray-cluster-configuration.html">Cluster YAML Configuration Options</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../cluster/metrics.html">Collecting and monitoring metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../cluster/configure-manage-dashboard.html">Configuring and Managing Ray Dashboard</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../cluster/running-applications/index.html">Applications Guide</a><input class="toctree-checkbox" id="toctree-checkbox-60" name="toctree-checkbox-60" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-60"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../cluster/running-applications/job-submission/index.html">Ray Jobs Overview</a><input class="toctree-checkbox" id="toctree-checkbox-61" name="toctree-checkbox-61" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-61"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/running-applications/job-submission/quickstart.html">Quickstart using the Ray Jobs CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/running-applications/job-submission/sdk.html">Python SDK Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/running-applications/job-submission/jobs-package-ref.html">Python SDK API Reference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/running-applications/job-submission/cli.html">Ray Jobs CLI API Reference</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/running-applications/job-submission/rest.html">Ray Jobs REST API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../cluster/running-applications/job-submission/ray-client.html">Ray Client</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../cluster/running-applications/autoscaling/reference.html">Programmatic Cluster Scaling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../cluster/faq.html">FAQ</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../cluster/package-overview.html">Ray Cluster Management API</a><input class="toctree-checkbox" id="toctree-checkbox-62" name="toctree-checkbox-62" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-62"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../cluster/cli.html">Cluster Management CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../cluster/running-applications/job-submission/jobs-package-ref.html">Python SDK API Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../cluster/running-applications/job-submission/cli.html">Ray Jobs CLI API Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../cluster/running-applications/autoscaling/reference.html">Programmatic Cluster Scaling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../cluster/usage-stats.html">Usage Stats Collection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../ray-observability/index.html">Monitoring and Debugging</a><input class="toctree-checkbox" id="toctree-checkbox-63" name="toctree-checkbox-63" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-63"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-observability/getting-started.html">Ray Dashboard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-observability/ray-distributed-debugger.html">Ray Distributed Debugger</a></li>



<li class="toctree-l2"><a class="reference internal" href="../../../ray-observability/key-concepts.html">Key Concepts</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../ray-observability/user-guides/index.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-64" name="toctree-checkbox-64" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-64"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../ray-observability/user-guides/debug-apps/index.html">Debugging Applications</a><input class="toctree-checkbox" id="toctree-checkbox-65" name="toctree-checkbox-65" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-65"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-observability/user-guides/debug-apps/general-debugging.html">General Debugging</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-observability/user-guides/debug-apps/debug-memory.html">Debugging Memory Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-observability/user-guides/debug-apps/debug-hangs.html">Debugging Hangs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-observability/user-guides/debug-apps/debug-failures.html">Debugging Failures</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-observability/user-guides/debug-apps/optimize-performance.html">Optimizing Performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../ray-observability/user-guides/debug-apps/ray-debugging.html">Using the Ray Debugger</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-observability/user-guides/cli-sdk.html">Monitoring with the CLI or SDK</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-observability/user-guides/configure-logging.html">Configuring Logging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-observability/user-guides/profiling.html">Profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-observability/user-guides/add-app-metrics.html">Adding Application-Level Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-observability/user-guides/ray-tracing.html">Tracing</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../ray-observability/reference/index.html">Reference</a><input class="toctree-checkbox" id="toctree-checkbox-66" name="toctree-checkbox-66" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-66"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-observability/reference/api.html">State API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-observability/reference/cli.html">State CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-observability/reference/system-metrics.html">System Metrics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../ray-contribute/index.html">Developer Guides</a><input class="toctree-checkbox" id="toctree-checkbox-67" name="toctree-checkbox-67" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-67"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-contribute/stability.html">API Stability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-contribute/api-policy.html">API Policy</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../ray-contribute/getting-involved.html">Getting Involved / Contributing</a><input class="toctree-checkbox" id="toctree-checkbox-68" name="toctree-checkbox-68" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-68"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-contribute/development.html">Building Ray from Source</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-contribute/ci.html">CI Testing Workflow on PRs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-contribute/docs.html">Contributing to the Ray Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-contribute/writing-code-snippets.html">How to write code snippets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-contribute/fake-autoscaler.html">Testing Autoscaling Locally</a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../ray-contribute/testing-tips.html">Tips for testing Ray programs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-contribute/debugging.html">Debugging for Ray Developers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ray-contribute/profiling.html">Profiling for Ray Developers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-core/configure.html">Configuring Ray</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ray-contribute/whitepaper.html">Architecture Whitepapers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-references/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ray-security/index.html">Security</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">ray.data.dataset</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <h1>Source code for ray.data.dataset</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">html</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">Generic</span><span class="p">,</span>
    <span class="n">Iterable</span><span class="p">,</span>
    <span class="n">Iterator</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Literal</span><span class="p">,</span>
    <span class="n">Mapping</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">TypeVar</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">ray.cloudpickle</span> <span class="k">as</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">ray._private.thirdparty.tabulate.tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>
<span class="kn">from</span> <span class="nn">ray._private.usage</span> <span class="kn">import</span> <span class="n">usage_lib</span>
<span class="kn">from</span> <span class="nn">ray.air.util.tensor_extensions.arrow</span> <span class="kn">import</span> <span class="n">ArrowTensorTypeV2</span>
<span class="kn">from</span> <span class="nn">ray.air.util.tensor_extensions.utils</span> <span class="kn">import</span> <span class="n">_create_possibly_ragged_ndarray</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.aggregate</span> <span class="kn">import</span> <span class="n">Max</span><span class="p">,</span> <span class="n">Mean</span><span class="p">,</span> <span class="n">Min</span><span class="p">,</span> <span class="n">Std</span><span class="p">,</span> <span class="n">Sum</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.compute</span> <span class="kn">import</span> <span class="n">ComputeStrategy</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.datasource.bigquery_datasink</span> <span class="kn">import</span> <span class="n">BigQueryDatasink</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.datasource.csv_datasink</span> <span class="kn">import</span> <span class="n">CSVDatasink</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.datasource.image_datasink</span> <span class="kn">import</span> <span class="n">ImageDatasink</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.datasource.json_datasink</span> <span class="kn">import</span> <span class="n">JSONDatasink</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.datasource.mongo_datasink</span> <span class="kn">import</span> <span class="n">MongoDatasink</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.datasource.numpy_datasink</span> <span class="kn">import</span> <span class="n">NumpyDatasink</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.datasource.parquet_datasink</span> <span class="kn">import</span> <span class="n">ParquetDatasink</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.datasource.sql_datasink</span> <span class="kn">import</span> <span class="n">SQLDatasink</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.datasource.tfrecords_datasink</span> <span class="kn">import</span> <span class="n">TFRecordDatasink</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.datasource.webdataset_datasink</span> <span class="kn">import</span> <span class="n">WebDatasetDatasink</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.delegating_block_builder</span> <span class="kn">import</span> <span class="n">DelegatingBlockBuilder</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.equalize</span> <span class="kn">import</span> <span class="n">_equalize</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.execution.interfaces</span> <span class="kn">import</span> <span class="n">RefBundle</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.execution.interfaces.ref_bundle</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_ref_bundles_iterator_to_block_refs_list</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.iterator.iterator_impl</span> <span class="kn">import</span> <span class="n">DataIteratorImpl</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.iterator.stream_split_iterator</span> <span class="kn">import</span> <span class="n">StreamSplitDataIterator</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.all_to_all_operator</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">RandomizeBlocks</span><span class="p">,</span>
    <span class="n">RandomShuffle</span><span class="p">,</span>
    <span class="n">Repartition</span><span class="p">,</span>
    <span class="n">Sort</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.input_data_operator</span> <span class="kn">import</span> <span class="n">InputData</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.map_operator</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Filter</span><span class="p">,</span>
    <span class="n">FlatMap</span><span class="p">,</span>
    <span class="n">MapBatches</span><span class="p">,</span>
    <span class="n">MapRows</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.n_ary_operator</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Union</span> <span class="k">as</span> <span class="n">UnionLogicalOperator</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.n_ary_operator</span> <span class="kn">import</span> <span class="n">Zip</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.one_to_one_operator</span> <span class="kn">import</span> <span class="n">Limit</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.operators.write_operator</span> <span class="kn">import</span> <span class="n">Write</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.logical.optimizers</span> <span class="kn">import</span> <span class="n">LogicalPlan</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.pandas_block</span> <span class="kn">import</span> <span class="n">PandasBlockSchema</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.plan</span> <span class="kn">import</span> <span class="n">ExecutionPlan</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.planner.exchange.sort_task_spec</span> <span class="kn">import</span> <span class="n">SortKey</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.remote_fn</span> <span class="kn">import</span> <span class="n">cached_remote_fn</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.split</span> <span class="kn">import</span> <span class="n">_get_num_rows</span><span class="p">,</span> <span class="n">_split_at_indices</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.stats</span> <span class="kn">import</span> <span class="n">DatasetStats</span><span class="p">,</span> <span class="n">DatasetStatsSummary</span><span class="p">,</span> <span class="n">StatsManager</span>
<span class="kn">from</span> <span class="nn">ray.data._internal.util</span> <span class="kn">import</span> <span class="n">AllToAllAPI</span><span class="p">,</span> <span class="n">ConsumptionAPI</span><span class="p">,</span> <span class="n">get_compute_strategy</span>
<span class="kn">from</span> <span class="nn">ray.data.aggregate</span> <span class="kn">import</span> <span class="n">AggregateFn</span>
<span class="kn">from</span> <span class="nn">ray.data.block</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">VALID_BATCH_FORMATS</span><span class="p">,</span>
    <span class="n">Block</span><span class="p">,</span>
    <span class="n">BlockAccessor</span><span class="p">,</span>
    <span class="n">DataBatch</span><span class="p">,</span>
    <span class="n">T</span><span class="p">,</span>
    <span class="n">U</span><span class="p">,</span>
    <span class="n">UserDefinedFunction</span><span class="p">,</span>
    <span class="n">_apply_batch_format</span><span class="p">,</span>
    <span class="n">_apply_batch_size</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ray.data.context</span> <span class="kn">import</span> <span class="n">DataContext</span>
<span class="kn">from</span> <span class="nn">ray.data.datasource</span> <span class="kn">import</span> <span class="n">Connection</span><span class="p">,</span> <span class="n">Datasink</span><span class="p">,</span> <span class="n">FilenameProvider</span>
<span class="kn">from</span> <span class="nn">ray.data.iterator</span> <span class="kn">import</span> <span class="n">DataIterator</span>
<span class="kn">from</span> <span class="nn">ray.data.random_access_dataset</span> <span class="kn">import</span> <span class="n">RandomAccessDataset</span>
<span class="kn">from</span> <span class="nn">ray.types</span> <span class="kn">import</span> <span class="n">ObjectRef</span>
<span class="kn">from</span> <span class="nn">ray.util.annotations</span> <span class="kn">import</span> <span class="n">Deprecated</span><span class="p">,</span> <span class="n">DeveloperAPI</span><span class="p">,</span> <span class="n">PublicAPI</span>
<span class="kn">from</span> <span class="nn">ray.util.scheduling_strategies</span> <span class="kn">import</span> <span class="n">NodeAffinitySchedulingStrategy</span>
<span class="kn">from</span> <span class="nn">ray.widgets</span> <span class="kn">import</span> <span class="n">Template</span>
<span class="kn">from</span> <span class="nn">ray.widgets.util</span> <span class="kn">import</span> <span class="n">repr_with_fallback</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">dask</span>
    <span class="kn">import</span> <span class="nn">mars</span>
    <span class="kn">import</span> <span class="nn">modin</span>
    <span class="kn">import</span> <span class="nn">pandas</span>
    <span class="kn">import</span> <span class="nn">pyarrow</span>
    <span class="kn">import</span> <span class="nn">pyspark</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torch.utils.data</span>
    <span class="kn">from</span> <span class="nn">tensorflow_metadata.proto.v0</span> <span class="kn">import</span> <span class="n">schema_pb2</span>

    <span class="kn">from</span> <span class="nn">ray.data._internal.execution.interfaces</span> <span class="kn">import</span> <span class="n">Executor</span><span class="p">,</span> <span class="n">NodeIdStr</span>
    <span class="kn">from</span> <span class="nn">ray.data.grouped_data</span> <span class="kn">import</span> <span class="n">GroupedData</span>


<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">TensorflowFeatureTypeSpec</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span>
    <span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">]</span>
<span class="p">]</span>

<span class="n">TensorFlowTensorBatchType</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;tf.Tensor&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.Tensor&quot;</span><span class="p">]]</span>

<span class="n">CollatedData</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;CollatedData&quot;</span><span class="p">)</span>
<span class="n">TorchBatchType</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">],</span> <span class="n">CollatedData</span><span class="p">]</span>

<span class="n">BT_API_GROUP</span> <span class="o">=</span> <span class="s2">&quot;Basic Transformations&quot;</span>
<span class="n">SSR_API_GROUP</span> <span class="o">=</span> <span class="s2">&quot;Sorting, Shuffling and Repartitioning&quot;</span>
<span class="n">SMD_API_GROUP</span> <span class="o">=</span> <span class="s2">&quot;Splitting and Merging datasets&quot;</span>
<span class="n">GGA_API_GROUP</span> <span class="o">=</span> <span class="s2">&quot;Grouped and Global aggregations&quot;</span>
<span class="n">CD_API_GROUP</span> <span class="o">=</span> <span class="s2">&quot;Consuming Data&quot;</span>
<span class="n">IOC_API_GROUP</span> <span class="o">=</span> <span class="s2">&quot;I/O and Conversion&quot;</span>
<span class="n">IM_API_GROUP</span> <span class="o">=</span> <span class="s2">&quot;Inspecting Metadata&quot;</span>
<span class="n">E_API_GROUP</span> <span class="o">=</span> <span class="s2">&quot;Execution&quot;</span>


<div class="viewcode-block" id="Dataset">
<a class="viewcode-back" href="../../../data/api/dataset.html#ray.data.Dataset">[docs]</a>
<span class="nd">@PublicAPI</span>
<span class="k">class</span> <span class="nc">Dataset</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Dataset is a distributed data collection for data loading and processing.</span>

<span class="sd">    Datasets are distributed pipelines that produce ``ObjectRef[Block]`` outputs,</span>
<span class="sd">    where each block holds data in Arrow format, representing a shard of the overall</span>
<span class="sd">    data collection. The block also determines the unit of parallelism. For more</span>
<span class="sd">    details, see :ref:`Ray Data Internals &lt;dataset_concept&gt;`.</span>

<span class="sd">    Datasets can be created in multiple ways: from synthetic data via ``range_*()``</span>
<span class="sd">    APIs, from existing memory data via ``from_*()`` APIs (this creates a subclass</span>
<span class="sd">    of Dataset called ``MaterializedDataset``), or from external storage</span>
<span class="sd">    systems such as local disk, S3, HDFS etc. via the ``read_*()`` APIs. The</span>
<span class="sd">    (potentially processed) Dataset can be saved back to external storage systems</span>
<span class="sd">    via the ``write_*()`` APIs.</span>

<span class="sd">    Examples:</span>
<span class="sd">        .. testcode::</span>
<span class="sd">            :skipif: True</span>

<span class="sd">            import ray</span>
<span class="sd">            # Create dataset from synthetic data.</span>
<span class="sd">            ds = ray.data.range(1000)</span>
<span class="sd">            # Create dataset from in-memory data.</span>
<span class="sd">            ds = ray.data.from_items(</span>
<span class="sd">                [{&quot;col1&quot;: i, &quot;col2&quot;: i * 2} for i in range(1000)]</span>
<span class="sd">            )</span>
<span class="sd">            # Create dataset from external storage system.</span>
<span class="sd">            ds = ray.data.read_parquet(&quot;s3://bucket/path&quot;)</span>
<span class="sd">            # Save dataset back to external storage system.</span>
<span class="sd">            ds.write_csv(&quot;s3://bucket/output&quot;)</span>

<span class="sd">    Dataset has two kinds of operations: transformation, which takes in Dataset</span>
<span class="sd">    and outputs a new Dataset (e.g. :py:meth:`.map_batches()`); and consumption,</span>
<span class="sd">    which produces values (not a data stream) as output</span>
<span class="sd">    (e.g. :meth:`.iter_batches()`).</span>

<span class="sd">    Dataset transformations are lazy, with execution of the transformations being</span>
<span class="sd">    triggered by downstream consumption.</span>

<span class="sd">    Dataset supports parallel processing at scale: transformations such as</span>
<span class="sd">    :py:meth:`.map_batches()`, aggregations such as</span>
<span class="sd">    :py:meth:`.min()`/:py:meth:`.max()`/:py:meth:`.mean()`, grouping via</span>
<span class="sd">    :py:meth:`.groupby()`, shuffling operations such as :py:meth:`.sort()`,</span>
<span class="sd">    :py:meth:`.random_shuffle()`, and :py:meth:`.repartition()`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import ray</span>
<span class="sd">        &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">        &gt;&gt;&gt; # Transform batches (Dict[str, np.ndarray]) with map_batches().</span>
<span class="sd">        &gt;&gt;&gt; ds.map_batches(lambda batch: {&quot;id&quot;: batch[&quot;id&quot;] * 2})  # doctest: +ELLIPSIS</span>
<span class="sd">        MapBatches(&lt;lambda&gt;)</span>
<span class="sd">        +- Dataset(num_rows=1000, schema={id: int64})</span>
<span class="sd">        &gt;&gt;&gt; # Compute the maximum.</span>
<span class="sd">        &gt;&gt;&gt; ds.max(&quot;id&quot;)</span>
<span class="sd">        999</span>
<span class="sd">        &gt;&gt;&gt; # Shuffle this dataset randomly.</span>
<span class="sd">        &gt;&gt;&gt; ds.random_shuffle()  # doctest: +ELLIPSIS</span>
<span class="sd">        RandomShuffle</span>
<span class="sd">        +- Dataset(num_rows=1000, schema={id: int64})</span>
<span class="sd">        &gt;&gt;&gt; # Sort it back in order.</span>
<span class="sd">        &gt;&gt;&gt; ds.sort(&quot;id&quot;)  # doctest: +ELLIPSIS</span>
<span class="sd">        Sort</span>
<span class="sd">        +- Dataset(num_rows=1000, schema={id: int64})</span>

<span class="sd">    Both unexecuted and materialized Datasets can be passed between Ray tasks and</span>
<span class="sd">    actors without incurring a copy. Dataset supports conversion to/from several</span>
<span class="sd">    more featureful dataframe libraries (e.g., Spark, Dask, Modin, MARS), and are also</span>
<span class="sd">    compatible with distributed TensorFlow / PyTorch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">plan</span><span class="p">:</span> <span class="n">ExecutionPlan</span><span class="p">,</span>
        <span class="n">logical_plan</span><span class="p">:</span> <span class="n">LogicalPlan</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Construct a Dataset (internal API).</span>

<span class="sd">        The constructor is not part of the Dataset API. Use the ``ray.data.*``</span>
<span class="sd">        read methods to construct a dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">ExecutionPlan</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">plan</span><span class="p">)</span>
        <span class="n">usage_lib</span><span class="o">.</span><span class="n">record_library_usage</span><span class="p">(</span><span class="s2">&quot;dataset&quot;</span><span class="p">)</span>  <span class="c1"># Legacy telemetry name.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span> <span class="o">=</span> <span class="n">plan</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span> <span class="o">=</span> <span class="n">logical_plan</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">link_logical_plan</span><span class="p">(</span><span class="n">logical_plan</span><span class="p">)</span>

        <span class="c1"># Handle to currently running executor for this dataset.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Executor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_write_ds</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_uuid</span><span class="p">(</span><span class="n">StatsManager</span><span class="o">.</span><span class="n">get_dataset_id_from_stats_actor</span><span class="p">())</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span>
        <span class="n">ds</span><span class="p">:</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">,</span> <span class="n">_deep_copy</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">_as</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">type</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_as</span><span class="p">:</span>
            <span class="n">_as</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_deep_copy</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_as</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">deep_copy</span><span class="p">(),</span> <span class="n">ds</span><span class="o">.</span><span class="n">_logical_plan</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_as</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">ds</span><span class="o">.</span><span class="n">_logical_plan</span><span class="p">)</span>

<div class="viewcode-block" id="Dataset.map">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.map.html#ray.data.Dataset.map">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">BT_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_cpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_gpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply the given function to each row of this dataset.</span>

<span class="sd">        Use this method to transform your data. To learn more, see</span>
<span class="sd">        :ref:`Transforming rows &lt;transforming_rows&gt;`.</span>

<span class="sd">        You can use either a function or a callable class to perform the transformation.</span>
<span class="sd">        For functions, Ray Data uses stateless Ray tasks. For classes, Ray Data uses</span>
<span class="sd">        stateful Ray actors. For more information, see</span>
<span class="sd">        :ref:`Stateful Transforms &lt;stateful_transforms&gt;`.</span>

<span class="sd">        .. tip::</span>

<span class="sd">            If your transformation is vectorized like most NumPy or pandas operations,</span>
<span class="sd">            :meth:`~Dataset.map_batches` might be faster.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import os</span>
<span class="sd">                from typing import Any, Dict</span>
<span class="sd">                import ray</span>

<span class="sd">                def parse_filename(row: Dict[str, Any]) -&gt; Dict[str, Any]:</span>
<span class="sd">                    row[&quot;filename&quot;] = os.path.basename(row[&quot;path&quot;])</span>
<span class="sd">                    return row</span>

<span class="sd">                ds = (</span>
<span class="sd">                    ray.data.read_images(&quot;s3://anonymous@ray-example-data/image-datasets/simple&quot;, include_paths=True)</span>
<span class="sd">                    .map(parse_filename)</span>
<span class="sd">                )</span>
<span class="sd">                print(ds.schema())</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                Column    Type</span>
<span class="sd">                ------    ----</span>
<span class="sd">                image     numpy.ndarray(shape=(32, 32, 3), dtype=uint8)</span>
<span class="sd">                path      string</span>
<span class="sd">                filename  string</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: The function to apply to each row, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable.</span>
<span class="sd">            compute: This argument is deprecated. Use ``concurrency`` argument.</span>
<span class="sd">            fn_args: Positional arguments to pass to ``fn`` after the first argument.</span>
<span class="sd">                These arguments are top-level arguments to the underlying Ray task.</span>
<span class="sd">            fn_kwargs: Keyword arguments to pass to ``fn``. These arguments are</span>
<span class="sd">                top-level arguments to the underlying Ray task.</span>
<span class="sd">            fn_constructor_args: Positional arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                You can only provide this if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            fn_constructor_kwargs: Keyword arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                This can only be provided if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            num_cpus: The number of CPUs to reserve for each parallel map worker.</span>
<span class="sd">            num_gpus: The number of GPUs to reserve for each parallel map worker. For</span>
<span class="sd">                example, specify `num_gpus=1` to request 1 GPU for each parallel map</span>
<span class="sd">                worker.</span>
<span class="sd">            concurrency: The number of Ray workers to use concurrently. For a fixed-sized</span>
<span class="sd">                worker pool of size ``n``, specify ``concurrency=n``. For an autoscaling</span>
<span class="sd">                worker pool from ``m`` to ``n`` workers, specify ``concurrency=(m, n)``.</span>
<span class="sd">            ray_remote_args_fn: A function that returns a dictionary of remote args</span>
<span class="sd">                passed to each map worker. The purpose of this argument is to generate</span>
<span class="sd">                dynamic arguments for each actor/task, and will be called each time prior</span>
<span class="sd">                to initializing the worker. Args returned from this dict will always</span>
<span class="sd">                override the args in ``ray_remote_args``. Note: this is an advanced,</span>
<span class="sd">                experimental feature.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                Ray for each map worker.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.flat_map`</span>
<span class="sd">                Call this method to create new rows from existing ones. Unlike</span>
<span class="sd">                :meth:`~Dataset.map`, a function passed to</span>
<span class="sd">                :meth:`~Dataset.flat_map` can return multiple rows.</span>

<span class="sd">            :meth:`~Dataset.map_batches`</span>
<span class="sd">                Call this method to transform batches of data.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="n">compute</span> <span class="o">=</span> <span class="n">get_compute_strategy</span><span class="p">(</span>
            <span class="n">fn</span><span class="p">,</span>
            <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">num_cpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_cpus</span>

        <span class="k">if</span> <span class="n">num_gpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_gpus</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">map_op</span> <span class="o">=</span> <span class="n">MapRows</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
            <span class="n">fn</span><span class="p">,</span>
            <span class="n">fn_args</span><span class="o">=</span><span class="n">fn_args</span><span class="p">,</span>
            <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span>
            <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
            <span class="n">fn_constructor_kwargs</span><span class="o">=</span><span class="n">fn_constructor_kwargs</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">ray_remote_args_fn</span><span class="o">=</span><span class="n">ray_remote_args_fn</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">map_op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">_set_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the name of the dataset.</span>

<span class="sd">        Used as a prefix for metrics tags.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_dataset_name</span> <span class="o">=</span> <span class="n">name</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the dataset name&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_dataset_name</span>

<div class="viewcode-block" id="Dataset.map_batches">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.map_batches.html#ray.data.Dataset.map_batches">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">BT_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">map_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">DataBatch</span><span class="p">,</span> <span class="n">DataBatch</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">zero_copy_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fn_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_cpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_gpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply the given function to batches of data.</span>

<span class="sd">        This method is useful for preprocessing data and performing inference. To learn</span>
<span class="sd">        more, see :ref:`Transforming batches &lt;transforming_batches&gt;`.</span>

<span class="sd">        You can use either a function or a callable class to perform the transformation.</span>
<span class="sd">        For functions, Ray Data uses stateless Ray tasks. For classes, Ray Data uses</span>
<span class="sd">        stateful Ray actors. For more information, see</span>
<span class="sd">        :ref:`Stateful Transforms &lt;stateful_transforms&gt;`.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            To understand the format of the input to ``fn``, call :meth:`~Dataset.take_batch`</span>
<span class="sd">            on the dataset to get a batch in the same format as will be passed to ``fn``.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            If ``fn`` doesn&#39;t mutate its input, set ``zero_copy_batch=True`` to improve</span>
<span class="sd">            performance and decrease memory utilization.</span>

<span class="sd">        Examples:</span>

<span class="sd">            Call :meth:`~Dataset.map_batches` to transform your data.</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                from typing import Dict</span>
<span class="sd">                import numpy as np</span>
<span class="sd">                import ray</span>

<span class="sd">                def add_dog_years(batch: Dict[str, np.ndarray]) -&gt; Dict[str, np.ndarray]:</span>
<span class="sd">                    batch[&quot;age_in_dog_years&quot;] = 7 * batch[&quot;age&quot;]</span>
<span class="sd">                    return batch</span>

<span class="sd">                ds = (</span>
<span class="sd">                    ray.data.from_items([</span>
<span class="sd">                        {&quot;name&quot;: &quot;Luna&quot;, &quot;age&quot;: 4},</span>
<span class="sd">                        {&quot;name&quot;: &quot;Rory&quot;, &quot;age&quot;: 14},</span>
<span class="sd">                        {&quot;name&quot;: &quot;Scout&quot;, &quot;age&quot;: 9},</span>
<span class="sd">                    ])</span>
<span class="sd">                    .map_batches(add_dog_years)</span>
<span class="sd">                )</span>
<span class="sd">                ds.show()</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                {&#39;name&#39;: &#39;Luna&#39;, &#39;age&#39;: 4, &#39;age_in_dog_years&#39;: 28}</span>
<span class="sd">                {&#39;name&#39;: &#39;Rory&#39;, &#39;age&#39;: 14, &#39;age_in_dog_years&#39;: 98}</span>
<span class="sd">                {&#39;name&#39;: &#39;Scout&#39;, &#39;age&#39;: 9, &#39;age_in_dog_years&#39;: 63}</span>

<span class="sd">            If your function returns large objects, yield outputs in chunks.</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                from typing import Dict</span>
<span class="sd">                import ray</span>
<span class="sd">                import numpy as np</span>

<span class="sd">                def map_fn_with_large_output(batch: Dict[str, np.ndarray]) -&gt; Dict[str, np.ndarray]:</span>
<span class="sd">                    for i in range(3):</span>
<span class="sd">                        yield {&quot;large_output&quot;: np.ones((100, 1000))}</span>

<span class="sd">                ds = (</span>
<span class="sd">                    ray.data.from_items([1])</span>
<span class="sd">                    .map_batches(map_fn_with_large_output)</span>
<span class="sd">                )</span>

<span class="sd">            If you require stateful transfomation,</span>
<span class="sd">            use Python callable class. Here is an example showing how to use stateful transforms to create model inference workers, without having to reload the model on each call.</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                from typing import Dict</span>
<span class="sd">                import numpy as np</span>
<span class="sd">                import torch</span>
<span class="sd">                import ray</span>

<span class="sd">                class TorchPredictor:</span>

<span class="sd">                    def __init__(self):</span>
<span class="sd">                        self.model = torch.nn.Identity().cuda()</span>
<span class="sd">                        self.model.eval()</span>

<span class="sd">                    def __call__(self, batch: Dict[str, np.ndarray]) -&gt; Dict[str, np.ndarray]:</span>
<span class="sd">                        inputs = torch.as_tensor(batch[&quot;data&quot;], dtype=torch.float32).cuda()</span>
<span class="sd">                        with torch.inference_mode():</span>
<span class="sd">                            batch[&quot;output&quot;] = self.model(inputs).detach().cpu().numpy()</span>
<span class="sd">                        return batch</span>

<span class="sd">                ds = (</span>
<span class="sd">                    ray.data.from_numpy(np.ones((32, 100)))</span>
<span class="sd">                    .map_batches(</span>
<span class="sd">                        TorchPredictor,</span>
<span class="sd">                        # Two workers with one GPU each</span>
<span class="sd">                        concurrency=2,</span>
<span class="sd">                        # Batch size is required if you&#39;re using GPUs.</span>
<span class="sd">                        batch_size=4,</span>
<span class="sd">                        num_gpus=1</span>
<span class="sd">                    )</span>
<span class="sd">                )</span>

<span class="sd">            To learn more, see</span>
<span class="sd">            :ref:`End-to-end: Offline Batch Inference &lt;batch_inference_home&gt;`.</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: The function or generator to apply to a record batch, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable. Note ``fn`` must be</span>
<span class="sd">                pickle-able.</span>
<span class="sd">            batch_size: The desired number of rows in each batch, or ``None`` to use</span>
<span class="sd">                entire blocks as batches (blocks may contain different numbers of rows).</span>
<span class="sd">                The actual size of the batch provided to ``fn`` may be smaller than</span>
<span class="sd">                ``batch_size`` if ``batch_size`` doesn&#39;t evenly divide the block(s) sent</span>
<span class="sd">                to a given map task. Default batch_size is 1024 with &quot;default&quot;.</span>
<span class="sd">            compute: This argument is deprecated. Use ``concurrency`` argument.</span>
<span class="sd">            batch_format: If ``&quot;default&quot;`` or ``&quot;numpy&quot;``, batches are</span>
<span class="sd">                ``Dict[str, numpy.ndarray]``. If ``&quot;pandas&quot;``, batches are</span>
<span class="sd">                ``pandas.DataFrame``.</span>
<span class="sd">            zero_copy_batch: Whether ``fn`` should be provided zero-copy, read-only</span>
<span class="sd">                batches. If this is ``True`` and no copy is required for the</span>
<span class="sd">                ``batch_format`` conversion, the batch is a zero-copy, read-only</span>
<span class="sd">                view on data in Ray&#39;s object store, which can decrease memory</span>
<span class="sd">                utilization and improve performance. If this is ``False``, the batch</span>
<span class="sd">                is writable, which requires an extra copy to guarantee.</span>
<span class="sd">                If ``fn`` mutates its input, this needs to be ``False`` in order to</span>
<span class="sd">                avoid &quot;assignment destination is read-only&quot; or &quot;buffer source array is</span>
<span class="sd">                read-only&quot; errors. Default is ``False``.</span>
<span class="sd">            fn_args: Positional arguments to pass to ``fn`` after the first argument.</span>
<span class="sd">                These arguments are top-level arguments to the underlying Ray task.</span>
<span class="sd">            fn_kwargs: Keyword arguments to pass to ``fn``. These arguments are</span>
<span class="sd">                top-level arguments to the underlying Ray task.</span>
<span class="sd">            fn_constructor_args: Positional arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                You can only provide this if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            fn_constructor_kwargs: Keyword arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                This can only be provided if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            num_cpus: The number of CPUs to reserve for each parallel map worker.</span>
<span class="sd">            num_gpus: The number of GPUs to reserve for each parallel map worker. For</span>
<span class="sd">                example, specify `num_gpus=1` to request 1 GPU for each parallel map worker.</span>
<span class="sd">            concurrency: The number of Ray workers to use concurrently. For a fixed-sized</span>
<span class="sd">                worker pool of size ``n``, specify ``concurrency=n``. For an autoscaling</span>
<span class="sd">                worker pool from ``m`` to ``n`` workers, specify ``concurrency=(m, n)``.</span>
<span class="sd">            ray_remote_args_fn: A function that returns a dictionary of remote args</span>
<span class="sd">                passed to each map worker. The purpose of this argument is to generate</span>
<span class="sd">                dynamic arguments for each actor/task, and will be called each time prior</span>
<span class="sd">                to initializing the worker. Args returned from this dict will always</span>
<span class="sd">                override the args in ``ray_remote_args``. Note: this is an advanced,</span>
<span class="sd">                experimental feature.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray for each map worker.</span>

<span class="sd">        .. note::</span>

<span class="sd">            The size of the batches provided to ``fn`` might be smaller than the</span>
<span class="sd">            specified ``batch_size`` if ``batch_size`` doesn&#39;t evenly divide the</span>
<span class="sd">            block(s) sent to a given map task.</span>

<span class="sd">            If ``batch_size`` is set and each input block is smaller than the</span>
<span class="sd">            ``batch_size``, Ray Data will bundle up many blocks as the input for one</span>
<span class="sd">            task, until their total size is equal to or greater than the given</span>
<span class="sd">            ``batch_size``.</span>
<span class="sd">            If ``batch_size`` is not set, the bundling will not be performed. Each task</span>
<span class="sd">            will receive only one input block.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.iter_batches`</span>
<span class="sd">                Call this function to iterate over batches of data.</span>

<span class="sd">            :meth:`~Dataset.take_batch`</span>
<span class="sd">                Call this function to get a batch of data from the dataset</span>
<span class="sd">                in the same format as will be passed to the `fn` function of</span>
<span class="sd">                :meth:`~Dataset.map_batches`.</span>

<span class="sd">            :meth:`~Dataset.flat_map`</span>
<span class="sd">                Call this method to create new records from existing ones. Unlike</span>
<span class="sd">                :meth:`~Dataset.map`, a function passed to :meth:`~Dataset.flat_map`</span>
<span class="sd">                can return multiple records.</span>

<span class="sd">            :meth:`~Dataset.map`</span>
<span class="sd">                Call this method to transform one record at time.</span>

<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="n">use_gpus</span> <span class="o">=</span> <span class="n">num_gpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">num_gpus</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">use_gpus</span> <span class="ow">and</span> <span class="p">(</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">batch_size</span> <span class="o">==</span> <span class="s2">&quot;default&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;You must provide `batch_size` to `map_batches` when requesting GPUs. &quot;</span>
                <span class="s2">&quot;The optimal batch size depends on the model, data, and GPU used. &quot;</span>
                <span class="s2">&quot;We recommend using the largest batch size that doesn&#39;t result &quot;</span>
                <span class="s2">&quot;in your GPU device running out of memory. You can view the GPU memory &quot;</span>
                <span class="s2">&quot;usage via the Ray dashboard.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Batch size can&#39;t be negative or 0&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_batches_without_batch_size_validation</span><span class="p">(</span>
            <span class="n">fn</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="n">zero_copy_batch</span><span class="p">,</span>
            <span class="n">fn_args</span><span class="o">=</span><span class="n">fn_args</span><span class="p">,</span>
            <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span>
            <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
            <span class="n">fn_constructor_kwargs</span><span class="o">=</span><span class="n">fn_constructor_kwargs</span><span class="p">,</span>
            <span class="n">num_cpus</span><span class="o">=</span><span class="n">num_cpus</span><span class="p">,</span>
            <span class="n">num_gpus</span><span class="o">=</span><span class="n">num_gpus</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
            <span class="n">ray_remote_args_fn</span><span class="o">=</span><span class="n">ray_remote_args_fn</span><span class="p">,</span>
            <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">_map_batches_without_batch_size_validation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">DataBatch</span><span class="p">,</span> <span class="n">DataBatch</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">]],</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ComputeStrategy</span><span class="p">],</span>
        <span class="n">batch_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">zero_copy_batch</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">fn_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]],</span>
        <span class="n">fn_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
        <span class="n">fn_constructor_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]],</span>
        <span class="n">fn_constructor_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
        <span class="n">num_cpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
        <span class="n">num_gpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]],</span>
        <span class="n">ray_remote_args_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]],</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># NOTE: The `map_groups` implementation calls `map_batches` with</span>
        <span class="c1"># `batch_size=None`. The issue is that if you request GPUs with</span>
        <span class="c1"># `batch_size=None`, then `map_batches` raises a value error. So, to allow users</span>
        <span class="c1"># to call `map_groups` with  GPUs, we need a separate method that doesn&#39;t</span>
        <span class="c1"># perform batch size validation.</span>

        <span class="n">compute</span> <span class="o">=</span> <span class="n">get_compute_strategy</span><span class="p">(</span>
            <span class="n">fn</span><span class="p">,</span>
            <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">num_cpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_cpus</span>

        <span class="k">if</span> <span class="n">num_gpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_gpus</span>

        <span class="n">batch_format</span> <span class="o">=</span> <span class="n">_apply_batch_format</span><span class="p">(</span><span class="n">batch_format</span><span class="p">)</span>

        <span class="n">min_rows_per_bundled_input</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="s2">&quot;default&quot;</span><span class="p">:</span>
            <span class="c1"># Enable blocks bundling when batch_size is specified by caller.</span>
            <span class="n">min_rows_per_bundled_input</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">_apply_batch_size</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">batch_format</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">VALID_BATCH_FORMATS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The batch format must be one of </span><span class="si">{</span><span class="n">VALID_BATCH_FORMATS</span><span class="si">}</span><span class="s2">, got: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">batch_format</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">map_batches_op</span> <span class="o">=</span> <span class="n">MapBatches</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
            <span class="n">fn</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="n">zero_copy_batch</span><span class="p">,</span>
            <span class="n">min_rows_per_bundled_input</span><span class="o">=</span><span class="n">min_rows_per_bundled_input</span><span class="p">,</span>
            <span class="n">fn_args</span><span class="o">=</span><span class="n">fn_args</span><span class="p">,</span>
            <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span>
            <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
            <span class="n">fn_constructor_kwargs</span><span class="o">=</span><span class="n">fn_constructor_kwargs</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">ray_remote_args_fn</span><span class="o">=</span><span class="n">ray_remote_args_fn</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">map_batches_op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span>

<div class="viewcode-block" id="Dataset.add_column">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.add_column.html#ray.data.Dataset.add_column">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">BT_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">add_column</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">],</span> <span class="s2">&quot;pandas.Series&quot;</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add the given column to the dataset.</span>

<span class="sd">        A function generating the new column values given the batch in pandas</span>
<span class="sd">        format must be specified.</span>

<span class="sd">        Examples:</span>


<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.schema()</span>
<span class="sd">            Column  Type</span>
<span class="sd">            ------  ----</span>
<span class="sd">            id      int64</span>

<span class="sd">            Add a new column equal to ``id * 2``.</span>

<span class="sd">            &gt;&gt;&gt; ds.add_column(&quot;new_id&quot;, lambda df: df[&quot;id&quot;] * 2).schema()</span>
<span class="sd">            Column  Type</span>
<span class="sd">            ------  ----</span>
<span class="sd">            id      int64</span>
<span class="sd">            new_id  int64</span>

<span class="sd">            Overwrite the existing values with zeros.</span>

<span class="sd">            &gt;&gt;&gt; ds.add_column(&quot;id&quot;, lambda df: 0).take(3)</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 0}, {&#39;id&#39;: 0}]</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            col: Name of the column to add. If the name already exists, the</span>
<span class="sd">                column is overwritten.</span>
<span class="sd">            fn: Map function generating the column values given a batch of</span>
<span class="sd">                records in pandas format.</span>
<span class="sd">            compute: This argument is deprecated. Use ``concurrency`` argument.</span>
<span class="sd">            concurrency: The number of Ray workers to use concurrently. For a</span>
<span class="sd">                fixed-sized worker pool of size ``n``, specify ``concurrency=n``. For</span>
<span class="sd">                an autoscaling worker pool from ``m`` to ``n`` workers, specify</span>
<span class="sd">                ``concurrency=(m, n)``.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">add_column</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">:</span>
            <span class="n">batch</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">batch</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`fn` must be callable, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
            <span class="n">add_column</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span>  <span class="c1"># TODO(ekl) we should make this configurable.</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.drop_columns">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.drop_columns.html#ray.data.Dataset.drop_columns">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">BT_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">drop_columns</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cols</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Drop one or more columns from the dataset.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_parquet(&quot;s3://anonymous@ray-example-data/iris.parquet&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.schema()</span>
<span class="sd">            Column        Type</span>
<span class="sd">            ------        ----</span>
<span class="sd">            sepal.length  double</span>
<span class="sd">            sepal.width   double</span>
<span class="sd">            petal.length  double</span>
<span class="sd">            petal.width   double</span>
<span class="sd">            variety       string</span>
<span class="sd">            &gt;&gt;&gt; ds.drop_columns([&quot;variety&quot;]).schema()</span>
<span class="sd">            Column        Type</span>
<span class="sd">            ------        ----</span>
<span class="sd">            sepal.length  double</span>
<span class="sd">            sepal.width   double</span>
<span class="sd">            petal.length  double</span>
<span class="sd">            petal.width   double</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            cols: Names of the columns to drop. If any name does not exist,</span>
<span class="sd">                an exception is raised.</span>
<span class="sd">            compute: This argument is deprecated. Use ``concurrency`` argument.</span>
<span class="sd">            concurrency: The number of Ray workers to use concurrently. For a fixed-sized</span>
<span class="sd">                worker pool of size ``n``, specify ``concurrency=n``. For an autoscaling</span>
<span class="sd">                worker pool from ``m`` to ``n`` workers, specify ``concurrency=(m, n)``.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">def</span> <span class="nf">drop_columns</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">batch</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">cols</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
            <span class="n">drop_columns</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
            <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.select_columns">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.select_columns.html#ray.data.Dataset.select_columns">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">BT_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">select_columns</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cols</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Select one or more columns from the dataset.</span>

<span class="sd">        Specified columns must be in the dataset schema.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_parquet(&quot;s3://anonymous@ray-example-data/iris.parquet&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.schema()</span>
<span class="sd">            Column        Type</span>
<span class="sd">            ------        ----</span>
<span class="sd">            sepal.length  double</span>
<span class="sd">            sepal.width   double</span>
<span class="sd">            petal.length  double</span>
<span class="sd">            petal.width   double</span>
<span class="sd">            variety       string</span>
<span class="sd">            &gt;&gt;&gt; ds.select_columns([&quot;sepal.length&quot;, &quot;sepal.width&quot;]).schema()</span>
<span class="sd">            Column        Type</span>
<span class="sd">            ------        ----</span>
<span class="sd">            sepal.length  double</span>
<span class="sd">            sepal.width   double</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            cols: Names of the columns to select. If a name isn&#39;t in the</span>
<span class="sd">                dataset schema, an exception is raised.</span>
<span class="sd">            compute: This argument is deprecated. Use ``concurrency`` argument.</span>
<span class="sd">            concurrency: The number of Ray workers to use concurrently. For a fixed-sized</span>
<span class="sd">                worker pool of size ``n``, specify ``concurrency=n``. For an autoscaling</span>
<span class="sd">                worker pool from ``m`` to ``n`` workers, specify ``concurrency=(m, n)``.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">def</span> <span class="nf">select_columns</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">cols</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span>
            <span class="n">select_columns</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span>
            <span class="n">zero_copy_batch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
            <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.flat_map">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.flat_map.html#ray.data.Dataset.flat_map">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">BT_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">flat_map</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fn_constructor_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_cpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_gpus</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply the given function to each row and then flatten results.</span>

<span class="sd">        Use this method if your transformation returns multiple rows for each input</span>
<span class="sd">        row.</span>

<span class="sd">        You can use either a function or a callable class to perform the transformation.</span>
<span class="sd">        For functions, Ray Data uses stateless Ray tasks. For classes, Ray Data uses</span>
<span class="sd">        stateful Ray actors. For more information, see</span>
<span class="sd">        :ref:`Stateful Transforms &lt;stateful_transforms&gt;`.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            :meth:`~Dataset.map_batches` can also modify the number of rows. If your</span>
<span class="sd">            transformation is vectorized like most NumPy and pandas operations,</span>
<span class="sd">            it might be faster.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                from typing import Any, Dict, List</span>
<span class="sd">                import ray</span>

<span class="sd">                def duplicate_row(row: Dict[str, Any]) -&gt; List[Dict[str, Any]]:</span>
<span class="sd">                    return [row] * 2</span>

<span class="sd">                print(</span>
<span class="sd">                    ray.data.range(3)</span>
<span class="sd">                    .flat_map(duplicate_row)</span>
<span class="sd">                    .take_all()</span>
<span class="sd">                )</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                [{&#39;id&#39;: 0}, {&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 1}, {&#39;id&#39;: 2}, {&#39;id&#39;: 2}]</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: The function or generator to apply to each record, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable.</span>
<span class="sd">            compute: This argument is deprecated. Use ``concurrency`` argument.</span>
<span class="sd">            fn_args: Positional arguments to pass to ``fn`` after the first argument.</span>
<span class="sd">                These arguments are top-level arguments to the underlying Ray task.</span>
<span class="sd">            fn_kwargs: Keyword arguments to pass to ``fn``. These arguments are</span>
<span class="sd">                top-level arguments to the underlying Ray task.</span>
<span class="sd">            fn_constructor_args: Positional arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                You can only provide this if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            fn_constructor_kwargs: Keyword arguments to pass to ``fn``&#39;s constructor.</span>
<span class="sd">                This can only be provided if ``fn`` is a callable class. These arguments</span>
<span class="sd">                are top-level arguments in the underlying Ray actor construction task.</span>
<span class="sd">            num_cpus: The number of CPUs to reserve for each parallel map worker.</span>
<span class="sd">            num_gpus: The number of GPUs to reserve for each parallel map worker. For</span>
<span class="sd">                example, specify `num_gpus=1` to request 1 GPU for each parallel map</span>
<span class="sd">                worker.</span>
<span class="sd">            concurrency: The number of Ray workers to use concurrently. For a</span>
<span class="sd">                fixed-sized worker pool of size ``n``, specify ``concurrency=n``.</span>
<span class="sd">                For an autoscaling worker pool from ``m`` to ``n`` workers, specify</span>
<span class="sd">                ``concurrency=(m, n)``.</span>
<span class="sd">            ray_remote_args_fn: A function that returns a dictionary of remote args</span>
<span class="sd">                passed to each map worker. The purpose of this argument is to generate</span>
<span class="sd">                dynamic arguments for each actor/task, and will be called each time</span>
<span class="sd">                prior to initializing the worker. Args returned from this dict will</span>
<span class="sd">                always override the args in ``ray_remote_args``. Note: this is an</span>
<span class="sd">                advanced, experimental feature.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray for each map worker.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.map_batches`</span>
<span class="sd">                Call this method to transform batches of data.</span>

<span class="sd">            :meth:`~Dataset.map`</span>
<span class="sd">                Call this method to transform one row at time.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">compute</span> <span class="o">=</span> <span class="n">get_compute_strategy</span><span class="p">(</span>
            <span class="n">fn</span><span class="p">,</span>
            <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">num_cpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_cpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_cpus</span>

        <span class="k">if</span> <span class="n">num_gpus</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_gpus</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">FlatMap</span><span class="p">(</span>
            <span class="n">input_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
            <span class="n">fn_args</span><span class="o">=</span><span class="n">fn_args</span><span class="p">,</span>
            <span class="n">fn_kwargs</span><span class="o">=</span><span class="n">fn_kwargs</span><span class="p">,</span>
            <span class="n">fn_constructor_args</span><span class="o">=</span><span class="n">fn_constructor_args</span><span class="p">,</span>
            <span class="n">fn_constructor_kwargs</span><span class="o">=</span><span class="n">fn_constructor_kwargs</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">ray_remote_args_fn</span><span class="o">=</span><span class="n">ray_remote_args_fn</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.filter">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.filter.html#ray.data.Dataset.filter">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">BT_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">filter</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">UserDefinedFunction</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="nb">bool</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">compute</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ComputeStrategy</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Filter out rows that don&#39;t satisfy the given predicate.</span>

<span class="sd">        You can use either a function or a callable class to perform the transformation.</span>
<span class="sd">        For functions, Ray Data uses stateless Ray tasks. For classes, Ray Data uses</span>
<span class="sd">        stateful Ray actors. For more information, see</span>
<span class="sd">        :ref:`Stateful Transforms &lt;stateful_transforms&gt;`.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            If you can represent your predicate with NumPy or pandas operations,</span>
<span class="sd">            :meth:`Dataset.map_batches` might be faster. You can implement filter by</span>
<span class="sd">            dropping rows.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            If you&#39;re using parquet and the filter is a simple predicate, you might</span>
<span class="sd">            be able to speed it up by using filter pushdown, see</span>
<span class="sd">            :ref:`Parquet row pruning &lt;parquet_row_pruning&gt;`.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.filter(lambda row: row[&quot;id&quot;] % 2 == 0).take_all()</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 2}, {&#39;id&#39;: 4}, ...]</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: The predicate to apply to each row, or a class type</span>
<span class="sd">                that can be instantiated to create such a callable.</span>
<span class="sd">            compute: This argument is deprecated. Use ``concurrency`` argument.</span>
<span class="sd">            concurrency: The number of Ray workers to use concurrently. For a</span>
<span class="sd">                fixed-sized worker pool of size ``n``, specify ``concurrency=n``.</span>
<span class="sd">                For an autoscaling worker pool from ``m`` to ``n`` workers, specify</span>
<span class="sd">                ``concurrency=(m, n)``.</span>
<span class="sd">            ray_remote_args_fn: A function that returns a dictionary of remote args</span>
<span class="sd">                passed to each map worker. The purpose of this argument is to generate</span>
<span class="sd">                dynamic arguments for each actor/task, and will be called each time</span>
<span class="sd">                prior to initializing the worker. Args returned from this dict will</span>
<span class="sd">                always override the args in ``ray_remote_args``. Note: this is an</span>
<span class="sd">                advanced, experimental feature.</span>
<span class="sd">            ray_remote_args: Additional resource requirements to request from</span>
<span class="sd">                ray (e.g., num_gpus=1 to request GPUs for the map tasks).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">compute</span> <span class="o">=</span> <span class="n">get_compute_strategy</span><span class="p">(</span>
            <span class="n">fn</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">Filter</span><span class="p">(</span>
            <span class="n">input_op</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
            <span class="n">compute</span><span class="o">=</span><span class="n">compute</span><span class="p">,</span>
            <span class="n">ray_remote_args_fn</span><span class="o">=</span><span class="n">ray_remote_args_fn</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.repartition">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.repartition.html#ray.data.Dataset.repartition">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">SSR_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">repartition</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Repartition the :class:`Dataset` into exactly this number of :ref:`blocks &lt;dataset_concept&gt;`.</span>

<span class="sd">        This method can be useful to tune the performance of your pipeline. To learn</span>
<span class="sd">        more, see :ref:`Advanced: Performance Tips and Tuning &lt;data_performance_tips&gt;`.</span>

<span class="sd">        If you&#39;re writing data to files, you can also use this method to change the</span>
<span class="sd">        number of output files. To learn more, see</span>
<span class="sd">        :ref:`Changing the number of output files &lt;changing-number-output-files&gt;`.</span>

<span class="sd">        .. note::</span>

<span class="sd">            Repartition has two modes. If ``shuffle=False``, Ray Data performs the</span>
<span class="sd">            minimal data movement needed to equalize block sizes. Otherwise, Ray Data</span>
<span class="sd">            performs a full distributed shuffle.</span>

<span class="sd">            .. image:: /data/images/dataset-shuffle.svg</span>
<span class="sd">                :align: center</span>

<span class="sd">            ..</span>
<span class="sd">                https://docs.google.com/drawings/d/132jhE3KXZsf29ho1yUdPrCHB9uheHBWHJhDQMXqIVPA/edit</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100).repartition(10).materialize()</span>
<span class="sd">            &gt;&gt;&gt; ds.num_blocks()</span>
<span class="sd">            10</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            num_blocks: The number of blocks.</span>
<span class="sd">            shuffle: Whether to perform a distributed shuffle during the</span>
<span class="sd">                repartition. When shuffle is enabled, each output block</span>
<span class="sd">                contains a subset of data rows from each input block, which</span>
<span class="sd">                requires all-to-all data movement. When shuffle is disabled,</span>
<span class="sd">                output blocks are created from adjacent input blocks,</span>
<span class="sd">                minimizing data movement.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The repartitioned :class:`Dataset`.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">Repartition</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
            <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_blocks</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.random_shuffle">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.random_shuffle.html#ray.data.Dataset.random_shuffle">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">SSR_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">random_shuffle</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_blocks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">ray_remote_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Randomly shuffle the rows of this :class:`Dataset`.</span>

<span class="sd">        .. tip::</span>

<span class="sd">            This method can be slow. For better performance, try</span>
<span class="sd">            :ref:`Iterating over batches with shuffling &lt;iterating-over-batches-with-shuffling&gt;`.</span>
<span class="sd">            Also, see :ref:`Optimizing shuffles &lt;optimizing_shuffles&gt;`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.random_shuffle().take(3)  # doctest: +SKIP</span>
<span class="sd">            {&#39;id&#39;: 41}, {&#39;id&#39;: 21}, {&#39;id&#39;: 92}]</span>
<span class="sd">            &gt;&gt;&gt; ds.random_shuffle(seed=42).take(3)  # doctest: +SKIP</span>
<span class="sd">            {&#39;id&#39;: 77}, {&#39;id&#39;: 21}, {&#39;id&#39;: 63}]</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            seed: Fix the random seed to use, otherwise one is chosen</span>
<span class="sd">                based on system randomness.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The shuffled :class:`Dataset`.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">if</span> <span class="n">num_blocks</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">DeprecationWarning</span><span class="p">(</span>
                <span class="s2">&quot;`num_blocks` parameter is deprecated in Ray 2.9. random_shuffle() &quot;</span>
                <span class="s2">&quot;does not support to change the number of output blocks. Use &quot;</span>
                <span class="s2">&quot;repartition() instead.&quot;</span><span class="p">,</span>  <span class="c1"># noqa: E501</span>
            <span class="p">)</span>
        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">RandomShuffle</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.randomize_block_order">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.randomize_block_order.html#ray.data.Dataset.randomize_block_order">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">SSR_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">randomize_block_order</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Randomly shuffle the :ref:`blocks &lt;dataset_concept&gt;` of this :class:`Dataset`.</span>

<span class="sd">        This method is useful if you :meth:`~Dataset.split` your dataset into shards and</span>
<span class="sd">        want to randomize the data in each shard without performing a full</span>
<span class="sd">        :meth:`~Dataset.random_shuffle`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.take(5)</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 2}, {&#39;id&#39;: 3}, {&#39;id&#39;: 4}]</span>
<span class="sd">            &gt;&gt;&gt; ds.randomize_block_order().take(5)  # doctest: +SKIP</span>
<span class="sd">            {&#39;id&#39;: 15}, {&#39;id&#39;: 16}, {&#39;id&#39;: 17}, {&#39;id&#39;: 18}, {&#39;id&#39;: 19}]</span>

<span class="sd">        Args:</span>
<span class="sd">            seed: Fix the random seed to use, otherwise one is chosen</span>
<span class="sd">                based on system randomness.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The block-shuffled :class:`Dataset`.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">RandomizeBlocks</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.random_sample">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.random_sample.html#ray.data.Dataset.random_sample">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">BT_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">random_sample</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">fraction</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a new :class:`Dataset` containing a random fraction of the rows.</span>

<span class="sd">        .. note::</span>

<span class="sd">            This method returns roughly ``fraction * total_rows`` rows. An exact number</span>
<span class="sd">            of rows isn&#39;t guaranteed.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.random_sample(0.1).count()  # doctest: +SKIP</span>
<span class="sd">            10</span>

<span class="sd">        Args:</span>
<span class="sd">            fraction: The fraction of elements to sample.</span>
<span class="sd">            seed: Seeds the python random pRNG generator.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Returns a :class:`Dataset` containing the sampled rows.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">random</span>

        <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">initial_num_blocks</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot sample from an empty Dataset.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fraction</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">fraction</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Fraction must be between 0 and 1.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">random_sample</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">[</span><span class="n">row</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">batch</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">fraction</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Table</span><span class="p">):</span>
                <span class="c1"># Lets the item pass if weight generated for that item &lt;= fraction</span>
                <span class="k">return</span> <span class="n">batch</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span>
                    <span class="n">pa</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">fraction</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)))</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">batch</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="n">fraction</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">_create_possibly_ragged_ndarray</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">row</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">batch</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">fraction</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported batch type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_batches</span><span class="p">(</span><span class="n">random_sample</span><span class="p">,</span> <span class="n">batch_format</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.streaming_split">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.streaming_split.html#ray.data.Dataset.streaming_split">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">SMD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">streaming_split</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">equal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">locality_hints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;NodeIdStr&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">DataIterator</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns ``n`` :class:`DataIterators &lt;ray.data.DataIterator&gt;` that can</span>
<span class="sd">        be used to read disjoint subsets of the dataset in parallel.</span>

<span class="sd">        This method is the recommended way to consume :class:`Datasets &lt;Dataset&gt;` for</span>
<span class="sd">        distributed training.</span>

<span class="sd">        Streaming split works by delegating the execution of this :class:`Dataset` to a</span>
<span class="sd">        coordinator actor. The coordinator pulls block references from the executed</span>
<span class="sd">        stream, and divides those blocks among ``n`` output iterators. Iterators pull</span>
<span class="sd">        blocks from the coordinator actor to return to their caller on ``next``.</span>

<span class="sd">        The returned iterators are also repeatable; each iteration will trigger a</span>
<span class="sd">        new execution of the Dataset. There is an implicit barrier at the start of</span>
<span class="sd">        each iteration, which means that `next` must be called on all iterators before</span>
<span class="sd">        the iteration starts.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            Because iterators are pulling blocks from the same :class:`Dataset`</span>
<span class="sd">            execution, if one iterator falls behind, other iterators may be stalled.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.range(100)</span>
<span class="sd">                it1, it2 = ds.streaming_split(2, equal=True)</span>

<span class="sd">            Consume data from iterators in parallel.</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                @ray.remote</span>
<span class="sd">                def consume(it):</span>
<span class="sd">                    for batch in it.iter_batches():</span>
<span class="sd">                       pass</span>

<span class="sd">                ray.get([consume.remote(it1), consume.remote(it2)])</span>

<span class="sd">            You can loop over the iterators multiple times (multiple epochs).</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                @ray.remote</span>
<span class="sd">                def train(it):</span>
<span class="sd">                    NUM_EPOCHS = 2</span>
<span class="sd">                    for _ in range(NUM_EPOCHS):</span>
<span class="sd">                        for batch in it.iter_batches():</span>
<span class="sd">                            pass</span>

<span class="sd">                ray.get([train.remote(it1), train.remote(it2)])</span>

<span class="sd">            The following remote function call blocks waiting for a read on ``it2`` to</span>
<span class="sd">            start.</span>

<span class="sd">            .. testcode::</span>
<span class="sd">                :skipif: True</span>

<span class="sd">                ray.get(train.remote(it1))</span>

<span class="sd">        Args:</span>
<span class="sd">            n: Number of output iterators to return.</span>
<span class="sd">            equal: If ``True``, each output iterator sees an exactly equal number</span>
<span class="sd">                of rows, dropping data if necessary. If ``False``, some iterators may</span>
<span class="sd">                see slightly more or less rows than others, but no data is dropped.</span>
<span class="sd">            locality_hints: Specify the node ids corresponding to each iterator</span>
<span class="sd">                location. Dataset will try to minimize data movement based on the</span>
<span class="sd">                iterator output locations. This list must have length ``n``. You can</span>
<span class="sd">                get the current node id of a task or actor by calling</span>
<span class="sd">                ``ray.get_runtime_context().get_node_id()``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The output iterator splits. These iterators are Ray-serializable and can</span>
<span class="sd">            be freely passed to any Ray task or actor.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`Dataset.split`</span>
<span class="sd">                Unlike :meth:`~Dataset.streaming_split`, :meth:`~Dataset.split`</span>
<span class="sd">                materializes the dataset in memory.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">StreamSplitDataIterator</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">equal</span><span class="p">,</span> <span class="n">locality_hints</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.split">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.split.html#ray.data.Dataset.split">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">SMD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">equal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">locality_hints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Materialize and split the dataset into ``n`` disjoint pieces.</span>

<span class="sd">        This method returns a list of ``MaterializedDataset`` that can be passed to Ray</span>
<span class="sd">        Tasks and Actors and used to read the dataset rows in parallel.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                @ray.remote</span>
<span class="sd">                class Worker:</span>

<span class="sd">                    def train(self, data_iterator):</span>
<span class="sd">                        for batch in data_iterator.iter_batches(batch_size=8):</span>
<span class="sd">                            pass</span>

<span class="sd">                workers = [Worker.remote() for _ in range(4)]</span>
<span class="sd">                shards = ray.data.range(100).split(n=4, equal=True)</span>
<span class="sd">                ray.get([w.train.remote(s) for w, s in zip(workers, shards)])</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            n: Number of child datasets to return.</span>
<span class="sd">            equal: Whether to guarantee each split has an equal</span>
<span class="sd">                number of records. This might drop records if the rows can&#39;t be</span>
<span class="sd">                divided equally among the splits.</span>
<span class="sd">            locality_hints: [Experimental] A list of Ray actor handles of size ``n``.</span>
<span class="sd">                The system tries to co-locate the blocks of the i-th dataset</span>
<span class="sd">                with the i-th actor to maximize data locality.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of ``n`` disjoint dataset splits.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`Dataset.split_at_indices`</span>
<span class="sd">                Unlike :meth:`~Dataset.split`, which splits a dataset into approximately</span>
<span class="sd">                equal splits, :meth:`Dataset.split_proportionately` lets you split a</span>
<span class="sd">                dataset into different sizes.</span>

<span class="sd">            :meth:`Dataset.split_proportionately`</span>
<span class="sd">                This method is equivalent to :meth:`Dataset.split_at_indices` if</span>
<span class="sd">                you compute indices manually.</span>

<span class="sd">            :meth:`Dataset.streaming_split`.</span>
<span class="sd">                Unlike :meth:`~Dataset.split`, :meth:`~Dataset.streaming_split`</span>
<span class="sd">                doesn&#39;t materialize the dataset in memory.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The number of splits </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> is not positive.&quot;</span><span class="p">)</span>

        <span class="c1"># fallback to split_at_indices for equal split without locality hints.</span>
        <span class="c1"># simple benchmarks shows spilit_at_indices yields more stable performance.</span>
        <span class="c1"># https://github.com/ray-project/ray/pull/26641 for more context.</span>
        <span class="k">if</span> <span class="n">equal</span> <span class="ow">and</span> <span class="n">locality_hints</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
            <span class="n">split_index</span> <span class="o">=</span> <span class="n">count</span> <span class="o">//</span> <span class="n">n</span>
            <span class="c1"># we are creating n split_indices which will generate</span>
            <span class="c1"># n + 1 splits; the last split will at most contains (n - 1)</span>
            <span class="c1"># rows, which could be safely dropped.</span>
            <span class="n">split_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">split_index</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">shards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_at_indices</span><span class="p">(</span><span class="n">split_indices</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">shards</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">locality_hints</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">)</span> <span class="o">!=</span> <span class="n">n</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The length of locality_hints </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;doesn&#39;t equal the number of splits </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="n">bundle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
        <span class="n">owned_by_consumer</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">owns_blocks</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="n">block_refs</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">bundle</span><span class="o">.</span><span class="n">blocks</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">locality_hints</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">block_refs_splits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">block_refs</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="n">metadata_splits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

            <span class="n">split_datasets</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">block_refs_split</span><span class="p">,</span> <span class="n">metadata_split</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">block_refs_splits</span><span class="p">,</span> <span class="n">metadata_splits</span>
            <span class="p">):</span>
                <span class="n">ref_bundles</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">RefBundle</span><span class="p">([(</span><span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="p">)],</span> <span class="n">owns_blocks</span><span class="o">=</span><span class="n">owned_by_consumer</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">block_refs_split</span><span class="p">,</span> <span class="n">metadata_split</span><span class="p">)</span>
                <span class="p">]</span>
                <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">ref_bundles</span><span class="p">))</span>
                <span class="n">split_datasets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">MaterializedDataset</span><span class="p">(</span>
                        <span class="n">ExecutionPlan</span><span class="p">(</span><span class="n">stats</span><span class="p">),</span>
                        <span class="n">logical_plan</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">split_datasets</span>

        <span class="n">metadata_mapping</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">block_refs</span><span class="p">,</span> <span class="n">metadata</span><span class="p">))</span>

        <span class="c1"># If the locality_hints is set, we use a two-round greedy algorithm</span>
        <span class="c1"># to co-locate the blocks with the actors based on block</span>
        <span class="c1"># and actor&#39;s location (node_id).</span>
        <span class="c1">#</span>
        <span class="c1"># The split algorithm tries to allocate equally-sized blocks regardless</span>
        <span class="c1"># of locality. Thus we first calculate the expected number of blocks</span>
        <span class="c1"># for each split.</span>
        <span class="c1">#</span>
        <span class="c1"># In the first round, for each actor, we look for all blocks that</span>
        <span class="c1"># match the actor&#39;s node_id, then allocate those matched blocks to</span>
        <span class="c1"># this actor until we reach the limit(expected number).</span>
        <span class="c1">#</span>
        <span class="c1"># In the second round: fill each actor&#39;s allocation with</span>
        <span class="c1"># remaining unallocated blocks until we reach the limit.</span>

        <span class="k">def</span> <span class="nf">build_allocation_size_map</span><span class="p">(</span>
            <span class="n">num_blocks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">actors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Given the total number of blocks and a list of actors, calcuate</span>
<span class="sd">            the expected number of blocks to allocate for each actor.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">num_actors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actors</span><span class="p">)</span>
            <span class="n">num_blocks_per_actor</span> <span class="o">=</span> <span class="n">num_blocks</span> <span class="o">//</span> <span class="n">num_actors</span>
            <span class="n">num_blocks_left</span> <span class="o">=</span> <span class="n">num_blocks</span> <span class="o">-</span> <span class="n">num_blocks_per_actor</span> <span class="o">*</span> <span class="n">n</span>
            <span class="n">num_blocks_by_actor</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">actor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">actors</span><span class="p">):</span>
                <span class="n">num_blocks_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_blocks_per_actor</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_blocks_left</span><span class="p">:</span>
                    <span class="n">num_blocks_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="n">num_blocks_by_actor</span>

        <span class="k">def</span> <span class="nf">build_block_refs_by_node_id</span><span class="p">(</span>
            <span class="n">blocks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">]],</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">]]]:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Build the reverse index from node_id to block_refs. For</span>
<span class="sd">            simplicity, if the block is stored on multiple nodes we</span>
<span class="sd">            only pick the first one.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">block_ref_locations</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">get_object_locations</span><span class="p">(</span><span class="n">blocks</span><span class="p">)</span>
            <span class="n">block_refs_by_node_id</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">block_ref</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">:</span>
                <span class="n">node_ids</span> <span class="o">=</span> <span class="n">block_ref_locations</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">block_ref</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;node_ids&quot;</span><span class="p">,</span> <span class="p">[])</span>
                <span class="n">node_id</span> <span class="o">=</span> <span class="n">node_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">node_ids</span> <span class="k">else</span> <span class="kc">None</span>
                <span class="n">block_refs_by_node_id</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">block_ref</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">block_refs_by_node_id</span>

        <span class="k">def</span> <span class="nf">build_node_id_by_actor</span><span class="p">(</span><span class="n">actors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Build a map from a actor to its node_id.&quot;&quot;&quot;</span>
            <span class="n">actors_state</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">_private</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">actors</span><span class="p">()</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="n">actor</span><span class="p">:</span> <span class="n">actors_state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">actor</span><span class="o">.</span><span class="n">_actor_id</span><span class="o">.</span><span class="n">hex</span><span class="p">(),</span> <span class="p">{})</span>
                <span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;Address&quot;</span><span class="p">,</span> <span class="p">{})</span>
                <span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;NodeID&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">actors</span>
            <span class="p">}</span>

        <span class="c1"># expected number of blocks to be allocated for each actor</span>
        <span class="n">expected_block_count_by_actor</span> <span class="o">=</span> <span class="n">build_allocation_size_map</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">block_refs</span><span class="p">),</span> <span class="n">locality_hints</span>
        <span class="p">)</span>
        <span class="c1"># the reverse index from node_id to block_refs</span>
        <span class="n">block_refs_by_node_id</span> <span class="o">=</span> <span class="n">build_block_refs_by_node_id</span><span class="p">(</span><span class="n">block_refs</span><span class="p">)</span>
        <span class="c1"># the map from actor to its node_id</span>
        <span class="n">node_id_by_actor</span> <span class="o">=</span> <span class="n">build_node_id_by_actor</span><span class="p">(</span><span class="n">locality_hints</span><span class="p">)</span>

        <span class="n">allocation_per_actor</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

        <span class="c1"># In the first round, for each actor, we look for all blocks that</span>
        <span class="c1"># match the actor&#39;s node_id, then allocate those matched blocks to</span>
        <span class="c1"># this actor until we reach the limit(expected number)</span>
        <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">locality_hints</span><span class="p">:</span>
            <span class="n">node_id</span> <span class="o">=</span> <span class="n">node_id_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span>
            <span class="n">matching_blocks</span> <span class="o">=</span> <span class="n">block_refs_by_node_id</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span>
            <span class="n">expected_block_count</span> <span class="o">=</span> <span class="n">expected_block_count_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span>
            <span class="n">allocation</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">while</span> <span class="n">matching_blocks</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">allocation</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">expected_block_count</span><span class="p">:</span>
                <span class="n">allocation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">matching_blocks</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span>
            <span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span> <span class="o">=</span> <span class="n">allocation</span>

        <span class="c1"># In the second round: fill each actor&#39;s allocation with</span>
        <span class="c1"># remaining unallocated blocks until we reach the limit</span>
        <span class="n">remaining_block_refs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="n">block_refs_by_node_id</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">locality_hints</span><span class="p">:</span>
            <span class="k">while</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">expected_block_count_by_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span>
            <span class="p">):</span>
                <span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">remaining_block_refs</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">remaining_block_refs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">remaining_block_refs</span><span class="p">)</span>

        <span class="n">per_split_bundles</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">actor</span> <span class="ow">in</span> <span class="n">locality_hints</span><span class="p">:</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="n">allocation_per_actor</span><span class="p">[</span><span class="n">actor</span><span class="p">]</span>
            <span class="n">metadata</span> <span class="o">=</span> <span class="p">[</span><span class="n">metadata_mapping</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">]</span>
            <span class="n">bundle</span> <span class="o">=</span> <span class="n">RefBundle</span><span class="p">(</span>
                <span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">)),</span> <span class="n">owns_blocks</span><span class="o">=</span><span class="n">owned_by_consumer</span>
            <span class="p">)</span>
            <span class="n">per_split_bundles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bundle</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">equal</span><span class="p">:</span>
            <span class="c1"># equalize the splits</span>
            <span class="n">per_split_bundles</span> <span class="o">=</span> <span class="n">_equalize</span><span class="p">(</span><span class="n">per_split_bundles</span><span class="p">,</span> <span class="n">owned_by_consumer</span><span class="p">)</span>

        <span class="n">split_datasets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">bundle</span> <span class="ow">in</span> <span class="n">per_split_bundles</span><span class="p">:</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="p">[</span><span class="n">bundle</span><span class="p">]))</span>
            <span class="n">split_datasets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">MaterializedDataset</span><span class="p">(</span>
                    <span class="n">ExecutionPlan</span><span class="p">(</span><span class="n">stats</span><span class="p">),</span>
                    <span class="n">logical_plan</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">split_datasets</span></div>


<div class="viewcode-block" id="Dataset.split_at_indices">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.split_at_indices.html#ray.data.Dataset.split_at_indices">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">SMD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">split_at_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Materialize and split the dataset at the given indices (like ``np.split``).</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; d1, d2, d3 = ds.split_at_indices([2, 5])</span>
<span class="sd">            &gt;&gt;&gt; d1.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1])}</span>
<span class="sd">            &gt;&gt;&gt; d2.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([2, 3, 4])}</span>
<span class="sd">            &gt;&gt;&gt; d3.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([5, 6, 7, 8, 9])}</span>

<span class="sd">        Time complexity: O(num splits)</span>

<span class="sd">        Args:</span>
<span class="sd">            indices: List of sorted integers which indicate where the dataset</span>
<span class="sd">                are split. If an index exceeds the length of the dataset,</span>
<span class="sd">                an empty dataset is returned.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The dataset splits.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`Dataset.split`</span>
<span class="sd">                Unlike :meth:`~Dataset.split_at_indices`, which lets you split a</span>
<span class="sd">                dataset into different sizes, :meth:`Dataset.split` splits a dataset</span>
<span class="sd">                into approximately equal splits.</span>

<span class="sd">            :meth:`Dataset.split_proportionately`</span>
<span class="sd">                This method is equivalent to :meth:`Dataset.split_at_indices` if</span>
<span class="sd">                you compute indices manually.</span>

<span class="sd">            :meth:`Dataset.streaming_split`.</span>
<span class="sd">                Unlike :meth:`~Dataset.split`, :meth:`~Dataset.streaming_split`</span>
<span class="sd">                doesn&#39;t materialize the dataset in memory.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;indices must be at least of length 1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">!=</span> <span class="n">indices</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;indices must be sorted&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;indices must be positive&quot;</span><span class="p">)</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="n">bundle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
        <span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="n">_split_at_indices</span><span class="p">(</span>
            <span class="n">bundle</span><span class="o">.</span><span class="n">blocks</span><span class="p">,</span>
            <span class="n">indices</span><span class="p">,</span>
            <span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">split_duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
        <span class="n">parent_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">bs</span><span class="p">,</span> <span class="n">ms</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">blocks</span><span class="p">,</span> <span class="n">metadata</span><span class="p">):</span>
            <span class="n">stats</span> <span class="o">=</span> <span class="n">DatasetStats</span><span class="p">(</span><span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Split&quot;</span><span class="p">:</span> <span class="n">ms</span><span class="p">},</span> <span class="n">parent</span><span class="o">=</span><span class="n">parent_stats</span><span class="p">)</span>
            <span class="n">stats</span><span class="o">.</span><span class="n">time_total_s</span> <span class="o">=</span> <span class="n">split_duration</span>
            <span class="n">ref_bundles</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">RefBundle</span><span class="p">([(</span><span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="p">)],</span> <span class="n">owns_blocks</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">ms</span><span class="p">)</span>
            <span class="p">]</span>
            <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">ref_bundles</span><span class="p">))</span>

            <span class="n">splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">MaterializedDataset</span><span class="p">(</span>
                    <span class="n">ExecutionPlan</span><span class="p">(</span><span class="n">stats</span><span class="p">),</span>
                    <span class="n">logical_plan</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">splits</span></div>


<div class="viewcode-block" id="Dataset.split_proportionately">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.split_proportionately.html#ray.data.Dataset.split_proportionately">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">SMD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">split_proportionately</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">proportions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Materialize and split the dataset using proportions.</span>

<span class="sd">        A common use case for this is splitting the dataset into train</span>
<span class="sd">        and test sets (equivalent to eg. scikit-learn&#39;s ``train_test_split``).</span>
<span class="sd">        For a higher level abstraction, see :meth:`Dataset.train_test_split`.</span>

<span class="sd">        This method splits datasets so that all splits</span>
<span class="sd">        always contains at least one row. If that isn&#39;t possible,</span>
<span class="sd">        an exception is raised.</span>

<span class="sd">        This is equivalent to caulculating the indices manually and calling</span>
<span class="sd">        :meth:`Dataset.split_at_indices`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; d1, d2, d3 = ds.split_proportionately([0.2, 0.5])</span>
<span class="sd">            &gt;&gt;&gt; d1.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1])}</span>
<span class="sd">            &gt;&gt;&gt; d2.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([2, 3, 4, 5, 6])}</span>
<span class="sd">            &gt;&gt;&gt; d3.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([7, 8, 9])}</span>

<span class="sd">        Time complexity: O(num splits)</span>

<span class="sd">        Args:</span>
<span class="sd">            proportions: List of proportions to split the dataset according to.</span>
<span class="sd">                Must sum up to less than 1, and each proportion must be bigger</span>
<span class="sd">                than 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The dataset splits.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`Dataset.split`</span>
<span class="sd">                Unlike :meth:`~Dataset.split_proportionately`, which lets you split a</span>
<span class="sd">                dataset into different sizes, :meth:`Dataset.split` splits a dataset</span>
<span class="sd">                into approximately equal splits.</span>

<span class="sd">            :meth:`Dataset.split_at_indices`</span>
<span class="sd">                :meth:`Dataset.split_proportionately` uses this method under the hood.</span>

<span class="sd">            :meth:`Dataset.streaming_split`.</span>
<span class="sd">                Unlike :meth:`~Dataset.split`, :meth:`~Dataset.streaming_split`</span>
<span class="sd">                doesn&#39;t materialize the dataset in memory.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">proportions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;proportions must be at least of length 1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">proportions</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;proportions must sum to less than 1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">proportions</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;proportions must be bigger than 0&quot;</span><span class="p">)</span>

        <span class="n">dataset_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
        <span class="n">cumulative_proportions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">proportions</span><span class="p">)</span>
        <span class="n">split_indices</span> <span class="o">=</span> <span class="p">[</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">dataset_length</span> <span class="o">*</span> <span class="n">proportion</span><span class="p">)</span> <span class="k">for</span> <span class="n">proportion</span> <span class="ow">in</span> <span class="n">cumulative_proportions</span>
        <span class="p">]</span>

        <span class="c1"># Ensure each split has at least one element</span>
        <span class="n">subtract</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">split_indices</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">subtract</span>
            <span class="k">if</span> <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]:</span>
                <span class="n">subtract</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">split_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">split_indices</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Couldn&#39;t create non-empty splits with the given proportions.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_at_indices</span><span class="p">(</span><span class="n">split_indices</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.train_test_split">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.train_test_split.html#ray.data.Dataset.train_test_split">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">SMD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">train_test_split</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">test_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">,</span> <span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Materialize and split the dataset into train and test subsets.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(8)</span>
<span class="sd">            &gt;&gt;&gt; train, test = ds.train_test_split(test_size=0.25)</span>
<span class="sd">            &gt;&gt;&gt; train.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1, 2, 3, 4, 5])}</span>
<span class="sd">            &gt;&gt;&gt; test.take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([6, 7])}</span>

<span class="sd">        Args:</span>
<span class="sd">            test_size: If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">                proportion of the dataset to include in the test split. If int,</span>
<span class="sd">                represents the absolute number of test samples. The train split</span>
<span class="sd">                always complements the test split.</span>
<span class="sd">            shuffle: Whether or not to globally shuffle the dataset before splitting.</span>
<span class="sd">                Defaults to ``False``. This may be a very expensive operation with a</span>
<span class="sd">                large dataset.</span>
<span class="sd">            seed: Fix the random seed to use for shuffle, otherwise one is chosen</span>
<span class="sd">                based on system randomness. Ignored if ``shuffle=False``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Train and test subsets as two ``MaterializedDatasets``.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`Dataset.split_proportionately`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="bp">self</span>

        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">random_shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`test_size` must be int or float got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If `test_size` is a float, it must be bigger than 0 and smaller &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;than 1. Got </span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">ds</span><span class="o">.</span><span class="n">split_proportionately</span><span class="p">([</span><span class="mi">1</span> <span class="o">-</span> <span class="n">test_size</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ds_length</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&gt;=</span> <span class="n">ds_length</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If `test_size` is an int, it must be bigger than 0 and smaller &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;than the size of the dataset (</span><span class="si">{</span><span class="n">ds_length</span><span class="si">}</span><span class="s2">). &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">ds</span><span class="o">.</span><span class="n">split_at_indices</span><span class="p">([</span><span class="n">ds_length</span> <span class="o">-</span> <span class="n">test_size</span><span class="p">])</span></div>


<div class="viewcode-block" id="Dataset.union">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.union.html#ray.data.Dataset.union">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">SMD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">union</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">other</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;Dataset&quot;</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Concatenate :class:`Datasets &lt;ray.data.Dataset&gt;` across rows.</span>

<span class="sd">        The order of the blocks in the datasets is preserved, as is the</span>
<span class="sd">        relative ordering between the datasets passed in the argument list.</span>

<span class="sd">        .. caution::</span>
<span class="sd">            Unioned datasets aren&#39;t lineage-serializable. As a result, they can&#39;t be</span>
<span class="sd">            used as a tunable hyperparameter in Ray Tune.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds1 = ray.data.range(2)</span>
<span class="sd">            &gt;&gt;&gt; ds2 = ray.data.range(3)</span>
<span class="sd">            &gt;&gt;&gt; ds1.union(ds2).take_all()</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 2}]</span>

<span class="sd">        Args:</span>
<span class="sd">            other: List of datasets to combine with this one. The datasets</span>
<span class="sd">                must have the same schema as this dataset, otherwise the</span>
<span class="sd">                behavior is undefined.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new dataset holding the rows of the input datasets.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>

        <span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>
        <span class="n">logical_plans</span> <span class="o">=</span> <span class="p">[</span><span class="n">union_ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_logical_plan</span> <span class="k">for</span> <span class="n">union_ds</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">UnionLogicalOperator</span><span class="p">(</span>
            <span class="o">*</span><span class="p">[</span><span class="n">plan</span><span class="o">.</span><span class="n">dag</span> <span class="k">for</span> <span class="n">plan</span> <span class="ow">in</span> <span class="n">logical_plans</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

        <span class="n">stats</span> <span class="o">=</span> <span class="n">DatasetStats</span><span class="p">(</span>
            <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Union&quot;</span><span class="p">:</span> <span class="p">[]},</span>
            <span class="n">parent</span><span class="o">=</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">time_total_s</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span><span class="n">stats</span><span class="p">),</span>
            <span class="n">logical_plan</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.groupby">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.groupby.html#ray.data.Dataset.groupby">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">GGA_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">groupby</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;GroupedData&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Group rows of a :class:`Dataset` according to a column.</span>

<span class="sd">        Use this method to transform data based on a</span>
<span class="sd">        categorical variable.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import pandas as pd</span>
<span class="sd">                import ray</span>

<span class="sd">                def normalize_variety(group: pd.DataFrame) -&gt; pd.DataFrame:</span>
<span class="sd">                    for feature in group.drop(&quot;variety&quot;).columns:</span>
<span class="sd">                        group[feature] = group[feature] / group[feature].abs().max()</span>
<span class="sd">                    return group</span>

<span class="sd">                ds = (</span>
<span class="sd">                    ray.data.read_parquet(&quot;s3://anonymous@ray-example-data/iris.parquet&quot;)</span>
<span class="sd">                    .groupby(&quot;variety&quot;)</span>
<span class="sd">                    .map_groups(normalize_variety, batch_format=&quot;pandas&quot;)</span>
<span class="sd">                )</span>

<span class="sd">        Time complexity: O(dataset size * log(dataset size / parallelism))</span>

<span class="sd">        Args:</span>
<span class="sd">            key: A column name or list of column names.</span>
<span class="sd">            If this is ``None``, place all rows in a single group.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A lazy :class:`~ray.data.grouped_data.GroupedData`.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~ray.data.grouped_data.GroupedData.map_groups`</span>
<span class="sd">                Call this method to transform groups of data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">ray.data.grouped_data</span> <span class="kn">import</span> <span class="n">GroupedData</span>

        <span class="c1"># Always allow None since groupby interprets that as grouping all</span>
        <span class="c1"># records into a single global group.</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Fetching the schema can trigger execution, so don&#39;t fetch it for</span>
            <span class="c1"># input validation.</span>
            <span class="n">SortKey</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">validate_schema</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">GroupedData</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.unique">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.unique.html#ray.data.Dataset.unique">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">GGA_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">unique</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;List the unique elements in a given column.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_items([1, 2, 3, 2, 3])</span>
<span class="sd">            &gt;&gt;&gt; ds.unique(&quot;item&quot;)</span>
<span class="sd">            [1, 2, 3]</span>

<span class="sd">            This function is very useful for computing labels</span>
<span class="sd">            in a machine learning dataset:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris.csv&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.unique(&quot;target&quot;)</span>
<span class="sd">            [0, 1, 2]</span>

<span class="sd">            One common use case is to convert the class labels</span>
<span class="sd">            into integers for training and inference:</span>

<span class="sd">            &gt;&gt;&gt; classes = {0: &#39;Setosa&#39;, 1: &#39;Versicolor&#39;, 2: &#39;Virginica&#39;}</span>
<span class="sd">            &gt;&gt;&gt; def preprocessor(df, classes):</span>
<span class="sd">            ...     df[&quot;variety&quot;] = df[&quot;target&quot;].map(classes)</span>
<span class="sd">            ...     return df</span>
<span class="sd">            &gt;&gt;&gt; train_ds = ds.map_batches(</span>
<span class="sd">            ...     preprocessor, fn_kwargs={&quot;classes&quot;: classes}, batch_format=&quot;pandas&quot;)</span>
<span class="sd">            &gt;&gt;&gt; train_ds.sort(&quot;sepal length (cm)&quot;).take(1)  # Sort to make it deterministic</span>
<span class="sd">            [{&#39;sepal length (cm)&#39;: 4.3, ..., &#39;variety&#39;: &#39;Setosa&#39;}]</span>

<span class="sd">        Time complexity: O(dataset size * log(dataset size / parallelism))</span>

<span class="sd">        Args:</span>
<span class="sd">            column: The column to collect unique elements over.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list with unique elements in the given column.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_columns</span><span class="p">([</span><span class="n">column</span><span class="p">])</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">column</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">ds</span><span class="o">.</span><span class="n">take_all</span><span class="p">()]</span></div>


<div class="viewcode-block" id="Dataset.aggregate">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.aggregate.html#ray.data.Dataset.aggregate">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">GGA_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">aggregate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">aggs</span><span class="p">:</span> <span class="n">AggregateFn</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Aggregate values using one or more functions.</span>

<span class="sd">        Use this method to compute metrics like the product of a column.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>
<span class="sd">                from ray.data.aggregate import AggregateFn</span>

<span class="sd">                ds = ray.data.from_items([{&quot;number&quot;: i} for i in range(1, 10)])</span>
<span class="sd">                aggregation = AggregateFn(</span>
<span class="sd">                    init=lambda column: 1,</span>
<span class="sd">                    # Apply this to each row to produce a partial aggregate result</span>
<span class="sd">                    accumulate_row=lambda a, row: a * row[&quot;number&quot;],</span>
<span class="sd">                    # Apply this to merge partial aggregate results into a final result</span>
<span class="sd">                    merge=lambda a1, a2: a1 * a2,</span>
<span class="sd">                    name=&quot;prod&quot;</span>
<span class="sd">                )</span>
<span class="sd">                print(ds.aggregate(aggregation))</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                {&#39;prod&#39;: 362880}</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            *aggs: :class:`Aggregations &lt;ray.data.aggregate.AggregateFn&gt;` to perform.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A ``dict`` where each each value is an aggregation for a given column.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="o">*</span><span class="n">aggs</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="Dataset.sum">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.sum.html#ray.data.Dataset.sum">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">GGA_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">sum</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the sum of one or more columns.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).sum(&quot;id&quot;)</span>
<span class="sd">            4950</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)</span>
<span class="sd">            ... ]).sum([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;sum(A)&#39;: 4950, &#39;sum(B)&#39;: 328350}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values are ignored when computing the sum. If ``False``,</span>
<span class="sd">                when a null value is encountered, the output is ``None``.</span>
<span class="sd">                Ray Data considers ``np.nan``, ``None``, and ``pd.NaT`` to be null</span>
<span class="sd">                values. Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The sum result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: a dict containing the column-wise sum of all</span>
<span class="sd">              columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the sum of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column ``dict``</span>
<span class="sd">              containing the column-wise sum of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null. If ``ignore_nulls`` is</span>
<span class="sd">            ``False`` and any value is null, then the output is ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Sum</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.min">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.min.html#ray.data.Dataset.min">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">GGA_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">min</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the minimum of one or more columns.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).min(&quot;id&quot;)</span>
<span class="sd">            0</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)</span>
<span class="sd">            ... ]).min([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;min(A)&#39;: 0, &#39;min(B)&#39;: 0}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values are ignored when computing the min; if ``False``,</span>
<span class="sd">                when a null value is encountered, the output is ``None``.</span>
<span class="sd">                This method considers ``np.nan``, ``None``, and ``pd.NaT`` to be null</span>
<span class="sd">                values. Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The min result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise min of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the min of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise min of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null. If ``ignore_nulls`` is</span>
<span class="sd">            ``False`` and any value is null, then the output is ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Min</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.max">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.max.html#ray.data.Dataset.max">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">GGA_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">max</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the maximum of one or more columns.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).max(&quot;id&quot;)</span>
<span class="sd">            99</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)</span>
<span class="sd">            ... ]).max([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;max(A)&#39;: 99, &#39;max(B)&#39;: 9801}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values are ignored when computing the max; if ``False``,</span>
<span class="sd">                when a null value is encountered, the output is ``None``.</span>
<span class="sd">                This method considers ``np.nan``, ``None``, and ``pd.NaT`` to be null</span>
<span class="sd">                values. Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The max result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise max of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the max of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise max of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null. If ``ignore_nulls`` is</span>
<span class="sd">            ``False`` and any value is null, then the output is ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Max</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.mean">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.mean.html#ray.data.Dataset.mean">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">GGA_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the mean of one or more columns.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.range(100).mean(&quot;id&quot;)</span>
<span class="sd">            49.5</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)</span>
<span class="sd">            ... ]).mean([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;mean(A)&#39;: 49.5, &#39;mean(B)&#39;: 3283.5}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values are ignored when computing the mean; if ``False``,</span>
<span class="sd">                when a null value is encountered, the output is ``None``.</span>
<span class="sd">                This method considers ``np.nan``, ``None``, and ``pd.NaT`` to be null</span>
<span class="sd">                values. Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The mean result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise mean of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the mean of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise mean of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null. If ``ignore_nulls`` is</span>
<span class="sd">            ``False`` and any value is null, then the output is ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Mean</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.std">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.std.html#ray.data.Dataset.std">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">GGA_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">std</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ddof</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the standard deviation of one or more columns.</span>

<span class="sd">        .. note::</span>
<span class="sd">            This method uses Welford&#39;s online method for an accumulator-style</span>
<span class="sd">            computation of the standard deviation. This method has</span>
<span class="sd">            numerical stability, and is computable in a single pass. This may give</span>
<span class="sd">            different (but more accurate) results than NumPy, Pandas, and sklearn, which</span>
<span class="sd">            use a less numerically stable two-pass algorithm.</span>
<span class="sd">            To learn more, see</span>
<span class="sd">            `the Wikapedia article &lt;https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford&#39;s_online_algorithm&gt;`_.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; round(ray.data.range(100).std(&quot;id&quot;, ddof=0), 5)</span>
<span class="sd">            28.86607</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items([</span>
<span class="sd">            ...     {&quot;A&quot;: i, &quot;B&quot;: i**2}</span>
<span class="sd">            ...     for i in range(100)</span>
<span class="sd">            ... ]).std([&quot;A&quot;, &quot;B&quot;])</span>
<span class="sd">            {&#39;std(A)&#39;: 29.011491975882016, &#39;std(B)&#39;: 2968.1748039269296}</span>

<span class="sd">        Args:</span>
<span class="sd">            on: a column name or a list of column names to aggregate.</span>
<span class="sd">            ddof: Delta Degrees of Freedom. The divisor used in calculations</span>
<span class="sd">                is ``N - ddof``, where ``N`` represents the number of elements.</span>
<span class="sd">            ignore_nulls: Whether to ignore null values. If ``True``, null</span>
<span class="sd">                values are ignored when computing the std; if ``False``,</span>
<span class="sd">                when a null value is encountered, the output is ``None``.</span>
<span class="sd">                This method considers ``np.nan``, ``None``, and ``pd.NaT`` to be null</span>
<span class="sd">                values. Default is ``True``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The standard deviation result.</span>

<span class="sd">            For different values of ``on``, the return varies:</span>

<span class="sd">            - ``on=None``: an dict containing the column-wise std of</span>
<span class="sd">              all columns,</span>
<span class="sd">            - ``on=&quot;col&quot;``: a scalar representing the std of all items in</span>
<span class="sd">              column ``&quot;col&quot;``,</span>
<span class="sd">            - ``on=[&quot;col_1&quot;, ..., &quot;col_n&quot;]``: an n-column dict</span>
<span class="sd">              containing the column-wise std of the provided columns.</span>

<span class="sd">            If the dataset is empty, all values are null. If ``ignore_nulls`` is</span>
<span class="sd">            ``False`` and any value is null, then the output is ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_on</span><span class="p">(</span><span class="n">Std</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_result</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.sort">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.sort.html#ray.data.Dataset.sort">[docs]</a>
    <span class="nd">@AllToAllAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">SSR_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">sort</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">descending</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">boundaries</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sort the dataset by the specified key column or key function.</span>

<span class="sd">        .. note::</span>
<span class="sd">            The `descending` parameter must be a boolean, or a list of booleans.</span>
<span class="sd">            If it is a list, all items in the list must share the same direction.</span>
<span class="sd">            Multi-directional sort is not supported yet.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(15)</span>
<span class="sd">            &gt;&gt;&gt; ds = ds.sort(&quot;id&quot;, descending=False, boundaries=[5, 10])</span>
<span class="sd">            &gt;&gt;&gt; for df in ray.get(ds.to_pandas_refs()):</span>
<span class="sd">            ...     print(df)</span>
<span class="sd">               id</span>
<span class="sd">            0   0</span>
<span class="sd">            1   1</span>
<span class="sd">            2   2</span>
<span class="sd">            3   3</span>
<span class="sd">            4   4</span>
<span class="sd">               id</span>
<span class="sd">            0   5</span>
<span class="sd">            1   6</span>
<span class="sd">            2   7</span>
<span class="sd">            3   8</span>
<span class="sd">            4   9</span>
<span class="sd">               id</span>
<span class="sd">            0  10</span>
<span class="sd">            1  11</span>
<span class="sd">            2  12</span>
<span class="sd">            3  13</span>
<span class="sd">            4  14</span>

<span class="sd">        Time complexity: O(dataset size * log(dataset size / parallelism))</span>

<span class="sd">        Args:</span>
<span class="sd">            key: The column or a list of columns to sort by.</span>
<span class="sd">            descending: Whether to sort in descending order. Must be a boolean or a list</span>
<span class="sd">                of booleans matching the number of the columns.</span>
<span class="sd">            boundaries: The list of values based on which to repartition the dataset.</span>
<span class="sd">                For example, if the input boundary is [10,20], rows with values less</span>
<span class="sd">                than 10 will be divided into the first block, rows with values greater</span>
<span class="sd">                than or equal to 10 and less than 20 will be divided into the</span>
<span class="sd">                second block, and rows with values greater than or equal to 20</span>
<span class="sd">                will be divided into the third block. If not provided, the</span>
<span class="sd">                boundaries will be sampled from the input blocks. This feature</span>
<span class="sd">                only supports numeric columns right now.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new, sorted :class:`Dataset`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sort_key</span> <span class="o">=</span> <span class="n">SortKey</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">descending</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">)</span>
        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">Sort</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
            <span class="n">sort_key</span><span class="o">=</span><span class="n">sort_key</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.zip">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.zip.html#ray.data.Dataset.zip">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">SMD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">zip</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Zip the columns of this dataset with the columns of another.</span>

<span class="sd">        The datasets must have the same number of rows. Their column sets are</span>
<span class="sd">        merged, and any duplicate column names are disambiguated with suffixes like</span>
<span class="sd">        ``&quot;_1&quot;``.</span>

<span class="sd">        .. note::</span>
<span class="sd">            The smaller of the two datasets is repartitioned to align the number</span>
<span class="sd">            of rows per block with the larger dataset.</span>

<span class="sd">        .. note::</span>
<span class="sd">            Zipped datasets aren&#39;t lineage-serializable. As a result, they can&#39;t be used</span>
<span class="sd">            as a tunable hyperparameter in Ray Tune.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds1 = ray.data.range(5)</span>
<span class="sd">            &gt;&gt;&gt; ds2 = ray.data.range(5)</span>
<span class="sd">            &gt;&gt;&gt; ds1.zip(ds2).take_batch()</span>
<span class="sd">            {&#39;id&#39;: array([0, 1, 2, 3, 4]), &#39;id_1&#39;: array([0, 1, 2, 3, 4])}</span>

<span class="sd">        Args:</span>
<span class="sd">            other: The dataset to zip with on the right hand side.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A :class:`Dataset` containing the columns of the second dataset</span>
<span class="sd">            concatenated horizontally with the columns of the first dataset,</span>
<span class="sd">            with duplicate column names disambiguated with suffixes like ``&quot;_1&quot;``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">Zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.limit">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.limit.html#ray.data.Dataset.limit">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">BT_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">limit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Truncate the dataset to the first ``limit`` rows.</span>

<span class="sd">        Unlike :meth:`~Dataset.take`, this method doesn&#39;t move data to the caller&#39;s</span>
<span class="sd">        machine. Instead, it returns a new :class:`Dataset` pointing to the truncated</span>
<span class="sd">        distributed data.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">            &gt;&gt;&gt; ds.limit(5).count()</span>
<span class="sd">            5</span>

<span class="sd">        Time complexity: O(limit specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The size of the dataset to truncate to.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The truncated dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">Limit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="n">limit</span><span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.take_batch">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.take_batch.html#ray.data.Dataset.take_batch">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">CD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">take_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">batch_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataBatch</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return up to ``batch_size`` rows from the :class:`Dataset` in a batch.</span>

<span class="sd">        Ray Data represents batches as NumPy arrays or pandas DataFrames. You can</span>
<span class="sd">        configure the batch type by specifying ``batch_format``.</span>

<span class="sd">        This method is useful for inspecting inputs to :meth:`~Dataset.map_batches`.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            :meth:`~Dataset.take_batch` moves up to ``batch_size`` rows to the caller&#39;s</span>
<span class="sd">            machine. If ``batch_size`` is large, this method can cause an `</span>
<span class="sd">            ``OutOfMemory`` error on the caller.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.take_batch(5)</span>
<span class="sd">            {&#39;id&#39;: array([0, 1, 2, 3, 4])}</span>

<span class="sd">        Time complexity: O(batch_size specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_size: The maximum number of rows to return.</span>
<span class="sd">            batch_format: If ``&quot;default&quot;`` or ``&quot;numpy&quot;``, batches are</span>
<span class="sd">                ``Dict[str, numpy.ndarray]``. If ``&quot;pandas&quot;``, batches are</span>
<span class="sd">                ``pandas.DataFrame``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A batch of up to ``batch_size`` rows from the dataset.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ``ValueError``: if the dataset is empty.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_format</span> <span class="o">=</span> <span class="n">_apply_batch_format</span><span class="p">(</span><span class="n">batch_format</span><span class="p">)</span>
        <span class="n">limited_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
                <span class="nb">iter</span><span class="p">(</span>
                    <span class="n">limited_ds</span><span class="o">.</span><span class="n">iter_batches</span><span class="p">(</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">prefetch_batches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The dataset is empty.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>

        <span class="c1"># Save the computed stats to the original dataset.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_snapshot_stats</span> <span class="o">=</span> <span class="n">limited_ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="Dataset.take">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.take.html#ray.data.Dataset.take">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">CD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">take</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return up to ``limit`` rows from the :class:`Dataset`.</span>

<span class="sd">        This method is useful for inspecting data.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            :meth:`~Dataset.take` moves up to ``limit`` rows to the caller&#39;s machine. If</span>
<span class="sd">            ``limit`` is large, this method can cause an ``OutOfMemory`` error on the</span>
<span class="sd">            caller.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.take(3)</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 2}]</span>

<span class="sd">        Time complexity: O(limit specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The maximum number of rows to return.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of up to ``limit`` rows from the dataset.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.take_all`</span>
<span class="sd">                Call this method to return all rows.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">log_once</span><span class="p">(</span><span class="s2">&quot;dataset_take&quot;</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Tip: Use `take_batch()` instead of `take() / show()` to return &quot;</span>
                <span class="s2">&quot;records in pandas or numpy batch format.&quot;</span>
            <span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">limited_ds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="n">limit</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">limited_ds</span><span class="o">.</span><span class="n">iter_rows</span><span class="p">():</span>
            <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">limit</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>

        <span class="c1"># Save the computed stats to the original dataset.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_snapshot_stats</span> <span class="o">=</span> <span class="n">limited_ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="Dataset.take_all">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.take_all.html#ray.data.Dataset.take_all">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">CD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">take_all</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return all of the rows in this :class:`Dataset`.</span>

<span class="sd">        This method is useful for inspecting small datasets.</span>

<span class="sd">        .. warning::</span>

<span class="sd">            :meth:`~Dataset.take_all` moves the entire dataset to the caller&#39;s</span>
<span class="sd">            machine. If the dataset is large, this method can cause an</span>
<span class="sd">            ``OutOfMemory`` error on the caller.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(5)</span>
<span class="sd">            &gt;&gt;&gt; ds.take_all()</span>
<span class="sd">            [{&#39;id&#39;: 0}, {&#39;id&#39;: 1}, {&#39;id&#39;: 2}, {&#39;id&#39;: 3}, {&#39;id&#39;: 4}]</span>

<span class="sd">        Time complexity: O(dataset size)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: Raise an error if the size exceeds the specified limit.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of all the rows in the dataset.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.take`</span>
<span class="sd">                Call this method to return a specific number of rows.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_rows</span><span class="p">():</span>
            <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">limit</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">limit</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The dataset has more than the given limit of </span><span class="si">{</span><span class="n">limit</span><span class="si">}</span><span class="s2"> records.&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="Dataset.show">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.show.html#ray.data.Dataset.show">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">CD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Print up to the given number of rows from the :class:`Dataset`.</span>

<span class="sd">        This method is useful for inspecting data.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.show(3)</span>
<span class="sd">            {&#39;id&#39;: 0}</span>
<span class="sd">            {&#39;id&#39;: 1}</span>
<span class="sd">            {&#39;id&#39;: 2}</span>

<span class="sd">        Time complexity: O(limit specified)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The maximum number of row to print.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~Dataset.take`</span>
<span class="sd">                Call this method to get (not print) a given number of rows.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">limit</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">row</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.count">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.count.html#ray.data.Dataset.count">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">datasource_metadata</span><span class="o">=</span><span class="s2">&quot;row count&quot;</span><span class="p">,</span>
        <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Examples:&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IM_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Count the number of rows in the dataset.</span>

<span class="sd">        For Datasets which only read Parquet files (created with</span>
<span class="sd">        :meth:`~ray.data.read_parquet`), this method reads the file metadata to</span>
<span class="sd">        efficiently count the number of rows without reading in the entire data.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; ds.count()</span>
<span class="sd">            10</span>

<span class="sd">        Returns:</span>
<span class="sd">            The number of records in the dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle empty dataset.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">initial_num_blocks</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>

        <span class="c1"># For parquet, we can return the count directly from metadata.</span>
        <span class="n">meta_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_meta_count</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">meta_count</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">meta_count</span>

        <span class="c1"># Directly loop over the iterator of `RefBundle`s instead of</span>
        <span class="c1"># retrieving a full list of `BlockRef`s.</span>
        <span class="n">total_rows</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">ref_bundle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_internal_ref_bundles</span><span class="p">():</span>
            <span class="n">num_rows</span> <span class="o">=</span> <span class="n">ref_bundle</span><span class="o">.</span><span class="n">num_rows</span><span class="p">()</span>
            <span class="c1"># Executing the dataset always returns blocks with valid `num_rows`.</span>
            <span class="k">assert</span> <span class="n">num_rows</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="n">total_rows</span> <span class="o">+=</span> <span class="n">num_rows</span>
        <span class="k">return</span> <span class="n">total_rows</span></div>


<div class="viewcode-block" id="Dataset.schema">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.schema.html#ray.data.Dataset.schema">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">datasource_metadata</span><span class="o">=</span><span class="s2">&quot;schema&quot;</span><span class="p">,</span>
        <span class="n">extra_condition</span><span class="o">=</span><span class="s2">&quot;or if ``fetch_if_missing=True`` (the default)&quot;</span><span class="p">,</span>
        <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IM_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">schema</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetch_if_missing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Schema&quot;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the schema of the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; ds.schema()</span>
<span class="sd">            Column  Type</span>
<span class="sd">            ------  ----</span>
<span class="sd">            id      int64</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            fetch_if_missing: If True, synchronously fetch the schema if it&#39;s</span>
<span class="sd">                not known. If False, None is returned if the schema is not known.</span>
<span class="sd">                Default is True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The :class:`ray.data.Schema` class of the records, or None if the</span>
<span class="sd">            schema is not known and fetch_if_missing is False.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_context</span>

        <span class="c1"># First check if the schema is already known from materialized blocks.</span>
        <span class="n">base_schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">base_schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Schema</span><span class="p">(</span><span class="n">base_schema</span><span class="p">,</span> <span class="n">data_context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>

        <span class="c1"># Lazily execute only the first block to minimize computation. We achieve this</span>
        <span class="c1"># by appending a Limit[1] operation to a copy of this Dataset, which we then</span>
        <span class="c1"># execute to get its schema.</span>
        <span class="n">base_schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="n">fetch_if_missing</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">base_schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">cache_schema</span><span class="p">(</span><span class="n">base_schema</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">Schema</span><span class="p">(</span><span class="n">base_schema</span><span class="p">,</span> <span class="n">data_context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="Dataset.columns">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.columns.html#ray.data.Dataset.columns">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">if_more_than_read</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">datasource_metadata</span><span class="o">=</span><span class="s2">&quot;schema&quot;</span><span class="p">,</span>
        <span class="n">extra_condition</span><span class="o">=</span><span class="s2">&quot;or if ``fetch_if_missing=True`` (the default)&quot;</span><span class="p">,</span>
        <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IM_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetch_if_missing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the columns of this Dataset.</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; # Create dataset from synthetic data.</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1000)</span>
<span class="sd">            &gt;&gt;&gt; ds.columns()</span>
<span class="sd">            [&#39;id&#39;]</span>

<span class="sd">        Args:</span>
<span class="sd">            fetch_if_missing: If True, synchronously fetch the column names from the</span>
<span class="sd">                schema if it&#39;s not known. If False, None is returned if the schema is</span>
<span class="sd">                not known. Default is True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of the column names for this Dataset or None if schema is not known</span>
<span class="sd">            and `fetch_if_missing` is False.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="n">fetch_if_missing</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">schema</span><span class="o">.</span><span class="n">names</span>
        <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="Dataset.num_blocks">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.num_blocks.html#ray.data.Dataset.num_blocks">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IM_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">num_blocks</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the number of blocks of this :class:`Dataset`.</span>

<span class="sd">        This method is only implemented for :class:`~ray.data.MaterializedDataset`,</span>
<span class="sd">        since the number of blocks may dynamically change during execution.</span>
<span class="sd">        For instance, during read and transform operations, Ray Data may dynamically</span>
<span class="sd">        adjust the number of blocks to respect memory limits, increasing the</span>
<span class="sd">        number of blocks at runtime.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The number of blocks of this :class:`Dataset`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;Number of blocks is only available for `MaterializedDataset`,&quot;</span>
            <span class="s2">&quot;because the number of blocks may dynamically change during execution.&quot;</span>
            <span class="s2">&quot;Call `ds.materialize()` to get a `MaterializedDataset`.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.size_bytes">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.size_bytes.html#ray.data.Dataset.size_bytes">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IM_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">size_bytes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the in-memory size of the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; ds.size_bytes()</span>
<span class="sd">            80</span>

<span class="sd">        Returns:</span>
<span class="sd">            The in-memory size of the dataset in bytes, or None if the</span>
<span class="sd">            in-memory size is not known.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If the size is known from metadata, return it.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="o">.</span><span class="n">aggregate_output_metadata</span><span class="p">()</span><span class="o">.</span><span class="n">size_bytes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="o">.</span><span class="n">aggregate_output_metadata</span><span class="p">()</span><span class="o">.</span><span class="n">size_bytes</span>

        <span class="n">metadata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">metadata</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">metadata</span> <span class="ow">or</span> <span class="n">metadata</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size_bytes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">size_bytes</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metadata</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.input_files">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.input_files.html#ray.data.Dataset.input_files">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IM_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">input_files</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the list of input files for the dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris.csv&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.input_files()</span>
<span class="sd">            [&#39;ray-example-data/iris.csv&#39;]</span>

<span class="sd">        Returns:</span>
<span class="sd">            The list of input files used to create the dataset, or an empty</span>
<span class="sd">            list if the input files is not known.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">input_files</span><span class="p">()))</span></div>


<div class="viewcode-block" id="Dataset.write_parquet">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_parquet.html#ray.data.Dataset.write_parquet">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">write_parquet</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filename_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FilenameProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">arrow_parquet_args_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_rows_per_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes the :class:`~ray.data.Dataset` to parquet files under the provided ``path``.</span>

<span class="sd">        The number of files is determined by the number of blocks in the dataset.</span>
<span class="sd">        To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>

<span class="sd">        If pyarrow can&#39;t represent your data, this method errors.</span>

<span class="sd">        By default, the format of the output files is ``{uuid}_{block_idx}.parquet``,</span>
<span class="sd">        where ``uuid`` is a unique id for the dataset. To modify this behavior,</span>
<span class="sd">        implement a custom :class:`~ray.data.datasource.FilenameProvider` and pass it in</span>
<span class="sd">        as the ``filename_provider`` argument.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_parquet(&quot;local:///tmp/data/&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where</span>
<span class="sd">                parquet files are written to.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in the</span>
<span class="sd">                destination path. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            filename_provider: A :class:`~ray.data.datasource.FilenameProvider`</span>
<span class="sd">                implementation. Use this parameter to customize what your filenames</span>
<span class="sd">                look like.</span>
<span class="sd">            arrow_parquet_args_fn: Callable that returns a dictionary of write</span>
<span class="sd">                arguments that are provided to `pyarrow.parquet.write_table() &lt;https:/\</span>
<span class="sd">                    /arrow.apache.org/docs/python/generated/\</span>
<span class="sd">                        pyarrow.parquet.write_table.html#pyarrow.parquet.write_table&gt;`_</span>
<span class="sd">                when writing each block to a file. Overrides</span>
<span class="sd">                any duplicate keys from ``arrow_parquet_args``. Use this argument</span>
<span class="sd">                instead of ``arrow_parquet_args`` if any of your write arguments</span>
<span class="sd">                can&#39;t pickled, or if you&#39;d like to lazily resolve the write</span>
<span class="sd">                arguments for each dataset block.</span>
<span class="sd">            num_rows_per_file: The target number of rows to write to each file. If</span>
<span class="sd">                ``None``, Ray Data writes a system-chosen number of rows to each file.</span>
<span class="sd">                The specified value is a hint, not a strict limit. Ray Data might write</span>
<span class="sd">                more or fewer rows to each file.</span>
<span class="sd">            ray_remote_args: Kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">            concurrency: The maximum number of Ray tasks to run concurrently. Set this</span>
<span class="sd">                to control number of tasks to run concurrently. This doesn&#39;t change the</span>
<span class="sd">                total number of tasks run. By default, concurrency is dynamically</span>
<span class="sd">                decided based on the available resources.</span>
<span class="sd">            arrow_parquet_args: Options to pass to</span>
<span class="sd">                `pyarrow.parquet.write_table() &lt;https://arrow.apache.org/docs/python\</span>
<span class="sd">                    /generated/pyarrow.parquet.write_table.html\</span>
<span class="sd">                        #pyarrow.parquet.write_table&gt;`_, which is used to write out each</span>
<span class="sd">                block to a file.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">if</span> <span class="n">arrow_parquet_args_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">arrow_parquet_args_fn</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{}</span>  <span class="c1"># noqa: E731</span>

        <span class="n">datasink</span> <span class="o">=</span> <span class="n">ParquetDatasink</span><span class="p">(</span>
            <span class="n">path</span><span class="p">,</span>
            <span class="n">arrow_parquet_args_fn</span><span class="o">=</span><span class="n">arrow_parquet_args_fn</span><span class="p">,</span>
            <span class="n">arrow_parquet_args</span><span class="o">=</span><span class="n">arrow_parquet_args</span><span class="p">,</span>
            <span class="n">num_rows_per_file</span><span class="o">=</span><span class="n">num_rows_per_file</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">filename_provider</span><span class="o">=</span><span class="n">filename_provider</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasink</span><span class="p">(</span>
            <span class="n">datasink</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.write_json">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_json.html#ray.data.Dataset.write_json">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">write_json</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filename_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FilenameProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pandas_json_args_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_rows_per_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">pandas_json_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes the :class:`~ray.data.Dataset` to JSON and JSONL files.</span>

<span class="sd">        The number of files is determined by the number of blocks in the dataset.</span>
<span class="sd">        To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>

<span class="sd">        This method is only supported for datasets with records that are convertible to</span>
<span class="sd">        pandas dataframes.</span>

<span class="sd">        By default, the format of the output files is ``{uuid}_{block_idx}.json``,</span>
<span class="sd">        where ``uuid`` is a unique id for the dataset. To modify this behavior,</span>
<span class="sd">        implement a custom :class:`~ray.data.datasource.FilenameProvider` and pass it in</span>
<span class="sd">        as the ``filename_provider`` argument.</span>

<span class="sd">        Examples:</span>
<span class="sd">            Write the dataset as JSON file to a local directory.</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_pandas([pd.DataFrame({&quot;one&quot;: [1], &quot;two&quot;: [&quot;a&quot;]})])</span>
<span class="sd">            &gt;&gt;&gt; ds.write_json(&quot;local:///tmp/data&quot;)</span>

<span class="sd">            Write the dataset as JSONL files to a local directory.</span>

<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_json(&quot;s3://anonymous@ray-example-data/train.jsonl&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_json(&quot;local:///tmp/data&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where</span>
<span class="sd">                the JSON files are written to.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in the</span>
<span class="sd">                destination path. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            filename_provider: A :class:`~ray.data.datasource.FilenameProvider`</span>
<span class="sd">                implementation. Use this parameter to customize what your filenames</span>
<span class="sd">                look like.</span>
<span class="sd">            pandas_json_args_fn: Callable that returns a dictionary of write</span>
<span class="sd">                arguments that are provided to</span>
<span class="sd">                `pandas.DataFrame.to_json() &lt;https://pandas.pydata.org/docs/reference/\</span>
<span class="sd">                    api/pandas.DataFrame.to_json.html&gt;`_</span>
<span class="sd">                when writing each block to a file. Overrides</span>
<span class="sd">                any duplicate keys from ``pandas_json_args``. Use this parameter</span>
<span class="sd">                instead of ``pandas_json_args`` if any of your write arguments</span>
<span class="sd">                can&#39;t be pickled, or if you&#39;d like to lazily resolve the write</span>
<span class="sd">                arguments for each dataset block.</span>
<span class="sd">            num_rows_per_file: The target number of rows to write to each file. If</span>
<span class="sd">                ``None``, Ray Data writes a system-chosen number of rows to each file.</span>
<span class="sd">                The specified value is a hint, not a strict limit. Ray Data might write</span>
<span class="sd">                more or fewer rows to each file.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">            concurrency: The maximum number of Ray tasks to run concurrently. Set this</span>
<span class="sd">                to control number of tasks to run concurrently. This doesn&#39;t change the</span>
<span class="sd">                total number of tasks run. By default, concurrency is dynamically</span>
<span class="sd">                decided based on the available resources.</span>
<span class="sd">            pandas_json_args: These args are passed to</span>
<span class="sd">                `pandas.DataFrame.to_json() &lt;https://pandas.pydata.org/docs/reference/\</span>
<span class="sd">                    api/pandas.DataFrame.to_json.html&gt;`_,</span>
<span class="sd">                which is used under the hood to write out each</span>
<span class="sd">                :class:`~ray.data.Dataset` block. These</span>
<span class="sd">                are dict(orient=&quot;records&quot;, lines=True) by default.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">pandas_json_args_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pandas_json_args_fn</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{}</span>  <span class="c1"># noqa: E731</span>

        <span class="n">datasink</span> <span class="o">=</span> <span class="n">JSONDatasink</span><span class="p">(</span>
            <span class="n">path</span><span class="p">,</span>
            <span class="n">pandas_json_args_fn</span><span class="o">=</span><span class="n">pandas_json_args_fn</span><span class="p">,</span>
            <span class="n">pandas_json_args</span><span class="o">=</span><span class="n">pandas_json_args</span><span class="p">,</span>
            <span class="n">num_rows_per_file</span><span class="o">=</span><span class="n">num_rows_per_file</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">filename_provider</span><span class="o">=</span><span class="n">filename_provider</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasink</span><span class="p">(</span>
            <span class="n">datasink</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.write_images">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_images.html#ray.data.Dataset.write_images">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_images</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">file_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;png&quot;</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filename_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FilenameProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes the :class:`~ray.data.Dataset` to images.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_images(&quot;s3://anonymous@ray-example-data/image-datasets/simple&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_images(&quot;local:///tmp/images&quot;, column=&quot;image&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where</span>
<span class="sd">                the images are written to.</span>
<span class="sd">            column: The column containing the data you want to write to images.</span>
<span class="sd">            file_format: The image file format to write with. For available options,</span>
<span class="sd">                see `Image file formats &lt;https://pillow.readthedocs.io/en/latest\</span>
<span class="sd">                /handbook/image-file-formats.html&gt;`_.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in the</span>
<span class="sd">                destination path. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            filename_provider: A :class:`~ray.data.datasource.FilenameProvider`</span>
<span class="sd">                implementation. Use this parameter to customize what your filenames</span>
<span class="sd">                look like.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">            concurrency: The maximum number of Ray tasks to run concurrently. Set this</span>
<span class="sd">                to control number of tasks to run concurrently. This doesn&#39;t change the</span>
<span class="sd">                total number of tasks run. By default, concurrency is dynamically</span>
<span class="sd">                decided based on the available resources.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="n">datasink</span> <span class="o">=</span> <span class="n">ImageDatasink</span><span class="p">(</span>
            <span class="n">path</span><span class="p">,</span>
            <span class="n">column</span><span class="p">,</span>
            <span class="n">file_format</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">filename_provider</span><span class="o">=</span><span class="n">filename_provider</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasink</span><span class="p">(</span>
            <span class="n">datasink</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.write_csv">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_csv.html#ray.data.Dataset.write_csv">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">write_csv</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filename_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FilenameProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">arrow_csv_args_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_rows_per_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">arrow_csv_args</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes the :class:`~ray.data.Dataset` to CSV files.</span>

<span class="sd">        The number of files is determined by the number of blocks in the dataset.</span>
<span class="sd">        To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>

<span class="sd">        This method is only supported for datasets with records that are convertible to</span>
<span class="sd">        pyarrow tables.</span>

<span class="sd">        By default, the format of the output files is ``{uuid}_{block_idx}.csv``,</span>
<span class="sd">        where ``uuid`` is a unique id for the dataset. To modify this behavior,</span>
<span class="sd">        implement a custom :class:`~ray.data.datasource.FilenameProvider`</span>
<span class="sd">        and pass it in as the ``filename_provider`` argument.</span>


<span class="sd">        Examples:</span>
<span class="sd">            Write the dataset as CSV files to a local directory.</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_csv(&quot;local:///tmp/data&quot;)</span>

<span class="sd">            Write the dataset as CSV files to S3.</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_csv(&quot;s3://bucket/folder/)  # doctest: +SKIP</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where</span>
<span class="sd">                the CSV files are written to.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in the</span>
<span class="sd">                destination path if ``True``. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            filename_provider: A :class:`~ray.data.datasource.FilenameProvider`</span>
<span class="sd">                implementation. Use this parameter to customize what your filenames</span>
<span class="sd">                look like.</span>
<span class="sd">            arrow_csv_args_fn: Callable that returns a dictionary of write</span>
<span class="sd">                arguments that are provided to `pyarrow.write.write_csv &lt;https://\</span>
<span class="sd">                arrow.apache.org/docs/python/generated/\</span>
<span class="sd">                pyarrow.csv.write_csv.html#pyarrow.csv.write_csv&gt;`_ when writing each</span>
<span class="sd">                block to a file. Overrides any duplicate keys from ``arrow_csv_args``.</span>
<span class="sd">                Use this argument instead of ``arrow_csv_args`` if any of your write</span>
<span class="sd">                arguments cannot be pickled, or if you&#39;d like to lazily resolve the</span>
<span class="sd">                write arguments for each dataset block.</span>
<span class="sd">            num_rows_per_file: The target number of rows to write to each file. If</span>
<span class="sd">                ``None``, Ray Data writes a system-chosen number of rows to each file.</span>
<span class="sd">                The specified value is a hint, not a strict limit. Ray Data might write</span>
<span class="sd">                more or fewer rows to each file.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">            concurrency: The maximum number of Ray tasks to run concurrently. Set this</span>
<span class="sd">                to control number of tasks to run concurrently. This doesn&#39;t change the</span>
<span class="sd">                total number of tasks run. By default, concurrency is dynamically</span>
<span class="sd">                decided based on the available resources.</span>
<span class="sd">            arrow_csv_args: Options to pass to `pyarrow.write.write_csv &lt;https://\</span>
<span class="sd">                arrow.apache.org/docs/python/generated/pyarrow.csv.write_csv.html\</span>
<span class="sd">                    #pyarrow.csv.write_csv&gt;`_</span>
<span class="sd">                when writing each block to a file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">arrow_csv_args_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">arrow_csv_args_fn</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{}</span>  <span class="c1"># noqa: E731</span>

        <span class="n">datasink</span> <span class="o">=</span> <span class="n">CSVDatasink</span><span class="p">(</span>
            <span class="n">path</span><span class="p">,</span>
            <span class="n">arrow_csv_args_fn</span><span class="o">=</span><span class="n">arrow_csv_args_fn</span><span class="p">,</span>
            <span class="n">arrow_csv_args</span><span class="o">=</span><span class="n">arrow_csv_args</span><span class="p">,</span>
            <span class="n">num_rows_per_file</span><span class="o">=</span><span class="n">num_rows_per_file</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">filename_provider</span><span class="o">=</span><span class="n">filename_provider</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasink</span><span class="p">(</span>
            <span class="n">datasink</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.write_tfrecords">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_tfrecords.html#ray.data.Dataset.write_tfrecords">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">write_tfrecords</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tf_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;schema_pb2.Schema&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filename_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FilenameProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_rows_per_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write the :class:`~ray.data.Dataset` to TFRecord files.</span>

<span class="sd">        The `TFRecord &lt;https://www.tensorflow.org/tutorials/load_data/tfrecord&gt;`_</span>
<span class="sd">        files contain</span>
<span class="sd">        `tf.train.Example &lt;https://www.tensorflow.org/api_docs/python/tf/train/\</span>
<span class="sd">            Example&gt;`_</span>
<span class="sd">        records, with one Example record for each row in the dataset.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            tf.train.Feature only natively stores ints, floats, and bytes,</span>
<span class="sd">            so this function only supports datasets with these data types,</span>
<span class="sd">            and will error if the dataset contains unsupported types.</span>

<span class="sd">        The number of files is determined by the number of blocks in the dataset.</span>
<span class="sd">        To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>

<span class="sd">        This method is only supported for datasets with records that are convertible to</span>
<span class="sd">        pyarrow tables.</span>

<span class="sd">        By default, the format of the output files is ``{uuid}_{block_idx}.tfrecords``,</span>
<span class="sd">        where ``uuid`` is a unique id for the dataset. To modify this behavior,</span>
<span class="sd">        implement a custom :class:`~ray.data.datasource.FilenameProvider`</span>
<span class="sd">        and pass it in as the ``filename_provider`` argument.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_tfrecords(&quot;local:///tmp/data/&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where tfrecords</span>
<span class="sd">                files are written to.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in the</span>
<span class="sd">                destination path. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            filename_provider: A :class:`~ray.data.datasource.FilenameProvider`</span>
<span class="sd">                implementation. Use this parameter to customize what your filenames</span>
<span class="sd">                look like.</span>
<span class="sd">            num_rows_per_file: The target number of rows to write to each file. If</span>
<span class="sd">                ``None``, Ray Data writes a system-chosen number of rows to each file.</span>
<span class="sd">                The specified value is a hint, not a strict limit. Ray Data might write</span>
<span class="sd">                more or fewer rows to each file.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">            concurrency: The maximum number of Ray tasks to run concurrently. Set this</span>
<span class="sd">                to control number of tasks to run concurrently. This doesn&#39;t change the</span>
<span class="sd">                total number of tasks run. By default, concurrency is dynamically</span>
<span class="sd">                decided based on the available resources.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">datasink</span> <span class="o">=</span> <span class="n">TFRecordDatasink</span><span class="p">(</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">tf_schema</span><span class="o">=</span><span class="n">tf_schema</span><span class="p">,</span>
            <span class="n">num_rows_per_file</span><span class="o">=</span><span class="n">num_rows_per_file</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">filename_provider</span><span class="o">=</span><span class="n">filename_provider</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasink</span><span class="p">(</span>
            <span class="n">datasink</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.write_webdataset">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_webdataset.html#ray.data.Dataset.write_webdataset">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">write_webdataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filename_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FilenameProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_rows_per_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">callable</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes the dataset to `WebDataset &lt;https://webdataset.github.io/webdataset/&gt;`_ files.</span>

<span class="sd">        The `TFRecord &lt;https://www.tensorflow.org/tutorials/load_data/tfrecord&gt;`_</span>
<span class="sd">        files will contain</span>
<span class="sd">        `tf.train.Example &lt;https://www.tensorflow.org/api_docs/python/tf/train/Example&gt;`_ # noqa: E501</span>
<span class="sd">        records, with one Example record for each row in the dataset.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            tf.train.Feature only natively stores ints, floats, and bytes,</span>
<span class="sd">            so this function only supports datasets with these data types,</span>
<span class="sd">            and will error if the dataset contains unsupported types.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        To control the number of files, use :meth:`Dataset.repartition`.</span>

<span class="sd">        Unless a custom filename provider is given, the format of the output</span>
<span class="sd">        files is ``{uuid}_{block_idx}.tfrecords``, where ``uuid`` is a unique id</span>
<span class="sd">        for the dataset.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>
<span class="sd">                :skipif: True</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.range(100)</span>
<span class="sd">                ds.write_webdataset(&quot;s3://bucket/folder/&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where tfrecords</span>
<span class="sd">                files are written to.</span>
<span class="sd">            filesystem: The filesystem implementation to write to.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all</span>
<span class="sd">                directories in the destination path. Does nothing if all directories</span>
<span class="sd">                already exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                ``pyarrow.fs.FileSystem.open_output_stream``</span>
<span class="sd">            filename_provider: A :class:`~ray.data.datasource.FilenameProvider`</span>
<span class="sd">                implementation. Use this parameter to customize what your filenames</span>
<span class="sd">                look like.</span>
<span class="sd">            num_rows_per_file: The target number of rows to write to each file. If</span>
<span class="sd">                ``None``, Ray Data writes a system-chosen number of rows to each file.</span>
<span class="sd">                The specified value is a hint, not a strict limit. Ray Data might write</span>
<span class="sd">                more or fewer rows to each file.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ``ray.remote`` in the write tasks.</span>
<span class="sd">            concurrency: The maximum number of Ray tasks to run concurrently. Set this</span>
<span class="sd">                to control number of tasks to run concurrently. This doesn&#39;t change the</span>
<span class="sd">                total number of tasks run. By default, concurrency is dynamically</span>
<span class="sd">                decided based on the available resources.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">datasink</span> <span class="o">=</span> <span class="n">WebDatasetDatasink</span><span class="p">(</span>
            <span class="n">path</span><span class="p">,</span>
            <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
            <span class="n">num_rows_per_file</span><span class="o">=</span><span class="n">num_rows_per_file</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">filename_provider</span><span class="o">=</span><span class="n">filename_provider</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasink</span><span class="p">(</span>
            <span class="n">datasink</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.write_numpy">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_numpy.html#ray.data.Dataset.write_numpy">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">write_numpy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">column</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">filesystem</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;pyarrow.fs.FileSystem&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">try_create_dir</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">arrow_open_stream_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">filename_provider</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">FilenameProvider</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_rows_per_file</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes a column of the :class:`~ray.data.Dataset` to .npy files.</span>

<span class="sd">        This is only supported for columns in the datasets that can be converted to</span>
<span class="sd">        NumPy arrays.</span>

<span class="sd">        The number of files is determined by the number of blocks in the dataset.</span>
<span class="sd">        To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>


<span class="sd">        By default, the format of the output files is ``{uuid}_{block_idx}.npy``,</span>
<span class="sd">        where ``uuid`` is a unique id for the dataset. To modify this behavior,</span>
<span class="sd">        implement a custom :class:`~ray.data.datasource.FilenameProvider`</span>
<span class="sd">        and pass it in as the ``filename_provider`` argument.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100)</span>
<span class="sd">            &gt;&gt;&gt; ds.write_numpy(&quot;local:///tmp/data/&quot;, column=&quot;id&quot;)</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            path: The path to the destination root directory, where</span>
<span class="sd">                the npy files are written to.</span>
<span class="sd">            column: The name of the column that contains the data to</span>
<span class="sd">                be written.</span>
<span class="sd">            filesystem: The pyarrow filesystem implementation to write to.</span>
<span class="sd">                These filesystems are specified in the</span>
<span class="sd">                `pyarrow docs &lt;https://arrow.apache.org/docs\</span>
<span class="sd">                /python/api/filesystems.html#filesystem-implementations&gt;`_.</span>
<span class="sd">                Specify this if you need to provide specific configurations to the</span>
<span class="sd">                filesystem. By default, the filesystem is automatically selected based</span>
<span class="sd">                on the scheme of the paths. For example, if the path begins with</span>
<span class="sd">                ``s3://``, the ``S3FileSystem`` is used.</span>
<span class="sd">            try_create_dir: If ``True``, attempts to create all directories in</span>
<span class="sd">                destination path. Does nothing if all directories already</span>
<span class="sd">                exist. Defaults to ``True``.</span>
<span class="sd">            arrow_open_stream_args: kwargs passed to</span>
<span class="sd">                `pyarrow.fs.FileSystem.open_output_stream &lt;https://arrow.apache.org\</span>
<span class="sd">                /docs/python/generated/pyarrow.fs.FileSystem.html\</span>
<span class="sd">                #pyarrow.fs.FileSystem.open_output_stream&gt;`_, which is used when</span>
<span class="sd">                opening the file to write to.</span>
<span class="sd">            filename_provider: A :class:`~ray.data.datasource.FilenameProvider`</span>
<span class="sd">                implementation. Use this parameter to customize what your filenames</span>
<span class="sd">                look like.</span>
<span class="sd">            num_rows_per_file: The target number of rows to write to each file. If</span>
<span class="sd">                ``None``, Ray Data writes a system-chosen number of rows to each file.</span>
<span class="sd">                The specified value is a hint, not a strict limit. Ray Data might write</span>
<span class="sd">                more or fewer rows to each file.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">            concurrency: The maximum number of Ray tasks to run concurrently. Set this</span>
<span class="sd">                to control number of tasks to run concurrently. This doesn&#39;t change the</span>
<span class="sd">                total number of tasks run. By default, concurrency is dynamically</span>
<span class="sd">                decided based on the available resources.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">datasink</span> <span class="o">=</span> <span class="n">NumpyDatasink</span><span class="p">(</span>
            <span class="n">path</span><span class="p">,</span>
            <span class="n">column</span><span class="p">,</span>
            <span class="n">num_rows_per_file</span><span class="o">=</span><span class="n">num_rows_per_file</span><span class="p">,</span>
            <span class="n">filesystem</span><span class="o">=</span><span class="n">filesystem</span><span class="p">,</span>
            <span class="n">try_create_dir</span><span class="o">=</span><span class="n">try_create_dir</span><span class="p">,</span>
            <span class="n">open_stream_args</span><span class="o">=</span><span class="n">arrow_open_stream_args</span><span class="p">,</span>
            <span class="n">filename_provider</span><span class="o">=</span><span class="n">filename_provider</span><span class="p">,</span>
            <span class="n">dataset_uuid</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasink</span><span class="p">(</span>
            <span class="n">datasink</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.write_sql">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_sql.html#ray.data.Dataset.write_sql">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_sql</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sql</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">connection_factory</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Connection</span><span class="p">],</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write to a database that provides a</span>
<span class="sd">        `Python DB API2-compliant &lt;https://peps.python.org/pep-0249/&gt;`_ connector.</span>

<span class="sd">        .. note::</span>

<span class="sd">            This method writes data in parallel using the DB API2 ``executemany``</span>
<span class="sd">            method. To learn more about this method, see</span>
<span class="sd">            `PEP 249 &lt;https://peps.python.org/pep-0249/#executemany&gt;`_.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import sqlite3</span>
<span class="sd">                import ray</span>

<span class="sd">                connection = sqlite3.connect(&quot;example.db&quot;)</span>
<span class="sd">                connection.cursor().execute(&quot;CREATE TABLE movie(title, year, score)&quot;)</span>
<span class="sd">                dataset = ray.data.from_items([</span>
<span class="sd">                    {&quot;title&quot;: &quot;Monty Python and the Holy Grail&quot;, &quot;year&quot;: 1975, &quot;score&quot;: 8.2},</span>
<span class="sd">                    {&quot;title&quot;: &quot;And Now for Something Completely Different&quot;, &quot;year&quot;: 1971, &quot;score&quot;: 7.5}</span>
<span class="sd">                ])</span>

<span class="sd">                dataset.write_sql(</span>
<span class="sd">                    &quot;INSERT INTO movie VALUES(?, ?, ?)&quot;, lambda: sqlite3.connect(&quot;example.db&quot;)</span>
<span class="sd">                )</span>

<span class="sd">                result = connection.cursor().execute(&quot;SELECT * FROM movie ORDER BY year&quot;)</span>
<span class="sd">                print(result.fetchall())</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                [(&#39;And Now for Something Completely Different&#39;, 1971, 7.5), (&#39;Monty Python and the Holy Grail&#39;, 1975, 8.2)]</span>

<span class="sd">            .. testcode::</span>
<span class="sd">                :hide:</span>

<span class="sd">                import os</span>
<span class="sd">                os.remove(&quot;example.db&quot;)</span>

<span class="sd">        Arguments:</span>
<span class="sd">            sql: An ``INSERT INTO`` statement that specifies the table to write to. The</span>
<span class="sd">                number of parameters must match the number of columns in the table.</span>
<span class="sd">            connection_factory: A function that takes no arguments and returns a</span>
<span class="sd">                Python DB API2</span>
<span class="sd">                `Connection object &lt;https://peps.python.org/pep-0249/#connection-objects&gt;`_.</span>
<span class="sd">            ray_remote_args: Keyword arguments passed to :meth:`~ray.remote` in the</span>
<span class="sd">                write tasks.</span>
<span class="sd">            concurrency: The maximum number of Ray tasks to run concurrently. Set this</span>
<span class="sd">                to control number of tasks to run concurrently. This doesn&#39;t change the</span>
<span class="sd">                total number of tasks run. By default, concurrency is dynamically</span>
<span class="sd">                decided based on the available resources.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="n">datasink</span> <span class="o">=</span> <span class="n">SQLDatasink</span><span class="p">(</span><span class="n">sql</span><span class="o">=</span><span class="n">sql</span><span class="p">,</span> <span class="n">connection_factory</span><span class="o">=</span><span class="n">connection_factory</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasink</span><span class="p">(</span>
            <span class="n">datasink</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.write_mongo">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_mongo.html#ray.data.Dataset.write_mongo">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_mongo</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">database</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">collection</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes the :class:`~ray.data.Dataset` to a MongoDB database.</span>

<span class="sd">        This method is only supported for datasets convertible to pyarrow tables.</span>

<span class="sd">        The number of parallel writes is determined by the number of blocks in the</span>
<span class="sd">        dataset. To control the number of number of blocks, call</span>
<span class="sd">        :meth:`~ray.data.Dataset.repartition`.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            This method supports only a subset of the PyArrow&#39;s types, due to the</span>
<span class="sd">            limitation of pymongoarrow which is used underneath. Writing unsupported</span>
<span class="sd">            types fails on type checking. See all the supported types at:</span>
<span class="sd">            https://mongo-arrow.readthedocs.io/en/latest/data_types.html.</span>

<span class="sd">        .. note::</span>
<span class="sd">            The records are inserted into MongoDB as new documents. If a record has</span>
<span class="sd">            the _id field, this _id must be non-existent in MongoDB, otherwise the write</span>
<span class="sd">            is rejected and fail (hence preexisting documents are protected from</span>
<span class="sd">            being mutated). It&#39;s fine to not have _id field in record and MongoDB will</span>
<span class="sd">            auto generate one at insertion.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>
<span class="sd">                :skipif: True</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.range(100)</span>
<span class="sd">                ds.write_mongo(</span>
<span class="sd">                    uri=&quot;mongodb://username:<a href="https://docs.ray.io/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="96e6f7e5e5e1f9e4f2d6fbf9f8f1f9f2f4a6b8f3eef7fbe6faf3b8f5f9fb">[email&#160;protected]</a>:27017/?authSource=admin&quot;,</span>
<span class="sd">                    database=&quot;my_db&quot;,</span>
<span class="sd">                    collection=&quot;my_collection&quot;</span>
<span class="sd">                )</span>

<span class="sd">        Args:</span>
<span class="sd">            uri: The URI to the destination MongoDB where the dataset is</span>
<span class="sd">                written to. For the URI format, see details in the</span>
<span class="sd">                `MongoDB docs &lt;https://www.mongodb.com/docs/manual/reference\</span>
<span class="sd">                    /connection-string/&gt;`_.</span>
<span class="sd">            database: The name of the database. This database must exist otherwise</span>
<span class="sd">                a ValueError is raised.</span>
<span class="sd">            collection: The name of the collection in the database. This collection</span>
<span class="sd">                must exist otherwise a ValueError is raised.</span>
<span class="sd">            ray_remote_args: kwargs passed to :meth:`~ray.remote` in the write tasks.</span>
<span class="sd">            concurrency: The maximum number of Ray tasks to run concurrently. Set this</span>
<span class="sd">                to control number of tasks to run concurrently. This doesn&#39;t change the</span>
<span class="sd">                total number of tasks run. By default, concurrency is dynamically</span>
<span class="sd">                decided based on the available resources.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if ``database`` doesn&#39;t exist.</span>
<span class="sd">            ValueError: if ``collection`` doesn&#39;t exist.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">datasink</span> <span class="o">=</span> <span class="n">MongoDatasink</span><span class="p">(</span>
            <span class="n">uri</span><span class="o">=</span><span class="n">uri</span><span class="p">,</span>
            <span class="n">database</span><span class="o">=</span><span class="n">database</span><span class="p">,</span>
            <span class="n">collection</span><span class="o">=</span><span class="n">collection</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasink</span><span class="p">(</span>
            <span class="n">datasink</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.write_bigquery">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_bigquery.html#ray.data.Dataset.write_bigquery">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="k">def</span> <span class="nf">write_bigquery</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">project_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">max_retry_cnt</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">overwrite_table</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write the dataset to a BigQuery dataset table.</span>

<span class="sd">        To control the number of parallel write tasks, use ``.repartition()``</span>
<span class="sd">        before calling this method.</span>

<span class="sd">        Examples:</span>
<span class="sd">             .. testcode::</span>
<span class="sd">                :skipif: True</span>

<span class="sd">                import ray</span>
<span class="sd">                import pandas as pd</span>

<span class="sd">                docs = [{&quot;title&quot;: &quot;BigQuery Datasource test&quot;} for key in range(4)]</span>
<span class="sd">                ds = ray.data.from_pandas(pd.DataFrame(docs))</span>
<span class="sd">                ds.write_bigquery(</span>
<span class="sd">                    project_id=&quot;my_project_id&quot;,</span>
<span class="sd">                    dataset=&quot;my_dataset_table&quot;,</span>
<span class="sd">                    overwrite_table=True</span>
<span class="sd">                )</span>

<span class="sd">        Args:</span>
<span class="sd">            project_id: The name of the associated Google Cloud Project that hosts</span>
<span class="sd">                the dataset to read. For more information, see details in</span>
<span class="sd">                `Creating and managing projects &lt;https://cloud.google.com/resource-manager/docs/creating-managing-projects&gt;`_.</span>
<span class="sd">            dataset: The name of the dataset in the format of ``dataset_id.table_id``.</span>
<span class="sd">                The dataset is created if it doesn&#39;t already exist.</span>
<span class="sd">            max_retry_cnt: The maximum number of retries that an individual block write</span>
<span class="sd">                is retried due to BigQuery rate limiting errors. This isn&#39;t</span>
<span class="sd">                related to Ray fault tolerance retries. The default number of retries</span>
<span class="sd">                is 10.</span>
<span class="sd">            overwrite_table: Whether the write will overwrite the table if it already</span>
<span class="sd">                exists. The default behavior is to overwrite the table.</span>
<span class="sd">                ``overwrite_table=False`` will append to the table if it exists.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ray.remote in the write tasks.</span>
<span class="sd">            concurrency: The maximum number of Ray tasks to run concurrently. Set this</span>
<span class="sd">                to control number of tasks to run concurrently. This doesn&#39;t change the</span>
<span class="sd">                total number of tasks run. By default, concurrency is dynamically</span>
<span class="sd">                decided based on the available resources.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">if</span> <span class="n">ray_remote_args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Each write task will launch individual remote tasks to write each block</span>
        <span class="c1"># To avoid duplicate block writes, the write task should not be retried</span>
        <span class="k">if</span> <span class="n">ray_remote_args</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;max_retries&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The max_retries of a BigQuery Write Task should be set to 0&quot;</span>
                <span class="s2">&quot; to avoid duplicate writes.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;max_retries&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">datasink</span> <span class="o">=</span> <span class="n">BigQueryDatasink</span><span class="p">(</span>
            <span class="n">project_id</span><span class="o">=</span><span class="n">project_id</span><span class="p">,</span>
            <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
            <span class="n">max_retry_cnt</span><span class="o">=</span><span class="n">max_retry_cnt</span><span class="p">,</span>
            <span class="n">overwrite_table</span><span class="o">=</span><span class="n">overwrite_table</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write_datasink</span><span class="p">(</span>
            <span class="n">datasink</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.write_datasink">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.write_datasink.html#ray.data.Dataset.write_datasink">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">write_datasink</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">datasink</span><span class="p">:</span> <span class="n">Datasink</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">ray_remote_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">concurrency</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Writes the dataset to a custom :class:`~ray.data.Datasink`.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            datasink: The :class:`~ray.data.Datasink` to write to.</span>
<span class="sd">            ray_remote_args: Kwargs passed to ``ray.remote`` in the write tasks.</span>
<span class="sd">            concurrency: The maximum number of Ray tasks to run concurrently. Set this</span>
<span class="sd">                to control number of tasks to run concurrently. This doesn&#39;t change the</span>
<span class="sd">                total number of tasks run. By default, concurrency is dynamically</span>
<span class="sd">                decided based on the available resources.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">if</span> <span class="n">ray_remote_args</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ray_remote_args</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">datasink</span><span class="o">.</span><span class="n">supports_distributed_writes</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">ray</span><span class="o">.</span><span class="n">is_connected</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;If you&#39;re using Ray Client, Ray Data won&#39;t schedule write tasks &quot;</span>
                    <span class="s2">&quot;on the driver&#39;s node.&quot;</span>
                <span class="p">)</span>
            <span class="n">ray_remote_args</span><span class="p">[</span><span class="s2">&quot;scheduling_strategy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">NodeAffinitySchedulingStrategy</span><span class="p">(</span>
                <span class="n">ray</span><span class="o">.</span><span class="n">get_runtime_context</span><span class="p">()</span><span class="o">.</span><span class="n">get_node_id</span><span class="p">(),</span>
                <span class="n">soft</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">plan</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">write_op</span> <span class="o">=</span> <span class="n">Write</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="p">,</span>
            <span class="n">datasink</span><span class="p">,</span>
            <span class="n">ray_remote_args</span><span class="o">=</span><span class="n">ray_remote_args</span><span class="p">,</span>
            <span class="n">concurrency</span><span class="o">=</span><span class="n">concurrency</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">write_op</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

            <span class="n">datasink</span><span class="o">.</span><span class="n">on_write_start</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_write_ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">logical_plan</span><span class="p">)</span><span class="o">.</span><span class="n">materialize</span><span class="p">()</span>
            <span class="n">blocks</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_write_ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">block_refs</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">blocks</span>
            <span class="p">)</span>
            <span class="n">write_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">block</span><span class="p">[</span><span class="s2">&quot;write_result&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">blocks</span><span class="p">]</span>

            <span class="n">datasink</span><span class="o">.</span><span class="n">on_write_complete</span><span class="p">(</span><span class="n">write_results</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">datasink</span><span class="o">.</span><span class="n">on_write_failed</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="k">raise</span></div>


<div class="viewcode-block" id="Dataset.iterator">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iterator.html#ray.data.Dataset.iterator">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span>
        <span class="n">delegate</span><span class="o">=</span><span class="p">(</span>
            <span class="s2">&quot;Calling any of the consumption methods on the returned ``DataIterator``&quot;</span>
        <span class="p">),</span>
        <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Returns:&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">CD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">iterator</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataIterator</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a :class:`~ray.data.DataIterator` over this dataset.</span>

<span class="sd">        Don&#39;t call this method directly. Use it internally.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A :class:`~ray.data.DataIterator` over this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">DataIteratorImpl</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.iter_rows">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_rows.html#ray.data.Dataset.iter_rows">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">CD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">iter_rows</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">prefetch_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return an iterable over the rows in this dataset.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; for row in ray.data.range(3).iter_rows():</span>
<span class="sd">            ...     print(row)</span>
<span class="sd">            {&#39;id&#39;: 0}</span>
<span class="sd">            {&#39;id&#39;: 1}</span>
<span class="sd">            {&#39;id&#39;: 2}</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_batches: The number of batches to prefetch ahead of the current</span>
<span class="sd">                batch during the scan.</span>
<span class="sd">            prefetch_blocks: This argument is deprecated. Use ``prefetch_batches``</span>
<span class="sd">                instead.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterable over the rows in this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_rows</span><span class="p">(</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span> <span class="n">prefetch_blocks</span><span class="o">=</span><span class="n">prefetch_blocks</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.iter_batches">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_batches.html#ray.data.Dataset.iter_batches">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">CD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">iter_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">batch_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;default&quot;</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">_collate_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">DataBatch</span><span class="p">],</span> <span class="n">CollatedData</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">DataBatch</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return an iterable over batches of data.</span>

<span class="sd">        This method is useful for model training.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.read_images(&quot;example://image-datasets/simple&quot;)</span>

<span class="sd">                for batch in ds.iter_batches(batch_size=2, batch_format=&quot;numpy&quot;):</span>
<span class="sd">                    print(batch)</span>

<span class="sd">            .. testoutput::</span>
<span class="sd">                :options: +MOCK</span>

<span class="sd">                {&#39;image&#39;: array([[[[...]]]], dtype=uint8)}</span>
<span class="sd">                ...</span>
<span class="sd">                {&#39;image&#39;: array([[[[...]]]], dtype=uint8)}</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool is used</span>
<span class="sd">                to fetch the objects to the local node and format the batches. Defaults</span>
<span class="sd">                to 1.</span>
<span class="sd">            batch_size: The number of rows in each batch, or ``None`` to use entire</span>
<span class="sd">                blocks as batches (blocks may contain different numbers of rows).</span>
<span class="sd">                The final batch may include fewer than ``batch_size`` rows if</span>
<span class="sd">                ``drop_last`` is ``False``. Defaults to 256.</span>
<span class="sd">            batch_format: If ``&quot;default&quot;`` or ``&quot;numpy&quot;``, batches are</span>
<span class="sd">                ``Dict[str, numpy.ndarray]``. If ``&quot;pandas&quot;``, batches are</span>
<span class="sd">                ``pandas.DataFrame``.</span>
<span class="sd">            drop_last: Whether to drop the last batch if it&#39;s incomplete.</span>
<span class="sd">            local_shuffle_buffer_size: If not ``None``, the data is randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value serves as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer are drained.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterable over batches of data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_format</span> <span class="o">=</span> <span class="n">_apply_batch_format</span><span class="p">(</span><span class="n">batch_format</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_batches</span><span class="p">(</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">batch_format</span><span class="o">=</span><span class="n">batch_format</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
            <span class="n">_collate_fn</span><span class="o">=</span><span class="n">_collate_fn</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.iter_torch_batches">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_torch_batches.html#ray.data.Dataset.iter_torch_batches">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">CD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">iter_torch_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">dtypes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;torch.dtype&quot;</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]],</span> <span class="n">CollatedData</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">TorchBatchType</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return an iterable over batches of data represented as Torch tensors.</span>

<span class="sd">        This iterable yields batches of type ``Dict[str, torch.Tensor]``.</span>
<span class="sd">        For more flexibility, call :meth:`~Dataset.iter_batches` and manually convert</span>
<span class="sd">        your data to Torch tensors.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; for batch in ray.data.range(</span>
<span class="sd">            ...     12,</span>
<span class="sd">            ... ).iter_torch_batches(batch_size=4):</span>
<span class="sd">            ...     print(batch)</span>
<span class="sd">            {&#39;id&#39;: tensor([0, 1, 2, 3])}</span>
<span class="sd">            {&#39;id&#39;: tensor([4, 5, 6, 7])}</span>
<span class="sd">            {&#39;id&#39;: tensor([ 8,  9, 10, 11])}</span>

<span class="sd">            Use the ``collate_fn`` to customize how the tensor batch is created.</span>

<span class="sd">            &gt;&gt;&gt; from typing import Any, Dict</span>
<span class="sd">            &gt;&gt;&gt; import torch</span>
<span class="sd">            &gt;&gt;&gt; import numpy as np</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; def collate_fn(batch: Dict[str, np.ndarray]) -&gt; Any:</span>
<span class="sd">            ...     return torch.stack(</span>
<span class="sd">            ...         [torch.as_tensor(array) for array in batch.values()],</span>
<span class="sd">            ...         axis=1</span>
<span class="sd">            ...     )</span>
<span class="sd">            &gt;&gt;&gt; dataset = ray.data.from_items([</span>
<span class="sd">            ...     {&quot;col_1&quot;: 1, &quot;col_2&quot;: 2},</span>
<span class="sd">            ...     {&quot;col_1&quot;: 3, &quot;col_2&quot;: 4}])</span>
<span class="sd">            &gt;&gt;&gt; for batch in dataset.iter_torch_batches(collate_fn=collate_fn):</span>
<span class="sd">            ...     print(batch)</span>
<span class="sd">            tensor([[1, 2],</span>
<span class="sd">                    [3, 4]])</span>


<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool is used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the ``collate_fn``. Defaults to 1.</span>
<span class="sd">            batch_size: The number of rows in each batch, or ``None`` to use entire</span>
<span class="sd">                blocks as batches (blocks may contain different number of rows).</span>
<span class="sd">                The final batch may include fewer than ``batch_size`` rows if</span>
<span class="sd">                ``drop_last`` is ``False``. Defaults to 256.</span>
<span class="sd">            dtypes: The Torch dtype(s) for the created tensor(s); if ``None``, the dtype</span>
<span class="sd">                is inferred from the tensor data. You can&#39;t use this parameter with</span>
<span class="sd">                ``collate_fn``.</span>
<span class="sd">            device: The device on which the tensor should be placed. Defaults to</span>
<span class="sd">                &quot;auto&quot; which moves the tensors to the appropriate device when the</span>
<span class="sd">                Dataset is passed to Ray Train and ``collate_fn`` is not provided.</span>
<span class="sd">                Otherwise, defaults to CPU. You can&#39;t use this parameter with</span>
<span class="sd">                ``collate_fn``.</span>
<span class="sd">            collate_fn: A function to convert a Numpy batch to a PyTorch tensor batch.</span>
<span class="sd">                When this parameter is specified, the user should manually handle the</span>
<span class="sd">                host to device data transfer outside of collate_fn.</span>
<span class="sd">                This is useful for further processing the data after it has been</span>
<span class="sd">                batched. Potential use cases include collating along a dimension other</span>
<span class="sd">                than the first, padding sequences of various lengths, or generally</span>
<span class="sd">                handling batches of different length tensors. If not provided, the</span>
<span class="sd">                default collate function is used which simply converts the batch of</span>
<span class="sd">                numpy arrays to a batch of PyTorch tensors. This API is still</span>
<span class="sd">                experimental and is subject to change. You can&#39;t use this parameter in</span>
<span class="sd">                conjunction with ``dtypes`` or ``device``.</span>
<span class="sd">            drop_last: Whether to drop the last batch if it&#39;s incomplete.</span>
<span class="sd">            local_shuffle_buffer_size: If not ``None``, the data is randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value serves as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer are drained.</span>
<span class="sd">                ``batch_size`` must also be specified when using local shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterable over Torch Tensor batches.</span>

<span class="sd">        .. seealso::</span>
<span class="sd">            :meth:`Dataset.iter_batches`</span>
<span class="sd">                Call this method to manually convert your data to Torch tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_torch_batches</span><span class="p">(</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">dtypes</span><span class="o">=</span><span class="n">dtypes</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.iter_tf_batches">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_tf_batches.html#ray.data.Dataset.iter_tf_batches">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">CD_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">iter_tf_batches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">dtypes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="s2">&quot;tf.dtypes.DType&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.dtypes.DType&quot;</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">TensorFlowTensorBatchType</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return an iterable over batches of data represented as TensorFlow tensors.</span>

<span class="sd">        This iterable yields batches of type ``Dict[str, tf.Tensor]``.</span>
<span class="sd">        For more flexibility, call :meth:`~Dataset.iter_batches` and manually convert</span>
<span class="sd">        your data to TensorFlow tensors.</span>

<span class="sd">        .. tip::</span>
<span class="sd">            If you don&#39;t need the additional flexibility provided by this method,</span>
<span class="sd">            consider using :meth:`~ray.data.Dataset.to_tf` instead. It&#39;s easier</span>
<span class="sd">            to use.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.read_csv(&quot;s3://anonymous@air-example-data/iris.csv&quot;)</span>

<span class="sd">                tf_dataset = ds.to_tf(</span>
<span class="sd">                    feature_columns=&quot;sepal length (cm)&quot;,</span>
<span class="sd">                    label_columns=&quot;target&quot;,</span>
<span class="sd">                    batch_size=2</span>
<span class="sd">                )</span>
<span class="sd">                for features, labels in tf_dataset:</span>
<span class="sd">                    print(features, labels)</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                tf.Tensor([5.1 4.9], shape=(2,), dtype=float64) tf.Tensor([0 0], shape=(2,), dtype=int64)</span>
<span class="sd">                ...</span>
<span class="sd">                tf.Tensor([6.2 5.9], shape=(2,), dtype=float64) tf.Tensor([2 2], shape=(2,), dtype=int64)</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool is used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the ``collate_fn``. Defaults to 1.</span>
<span class="sd">            batch_size: The number of rows in each batch, or ``None`` to use entire</span>
<span class="sd">                blocks as batches (blocks may contain different numbers of rows).</span>
<span class="sd">                The final batch may include fewer than ``batch_size`` rows if</span>
<span class="sd">                ``drop_last`` is ``False``. Defaults to 256.</span>
<span class="sd">            dtypes: The TensorFlow dtype(s) for the created tensor(s); if ``None``, the</span>
<span class="sd">                dtype is inferred from the tensor data.</span>
<span class="sd">            drop_last: Whether to drop the last batch if it&#39;s incomplete.</span>
<span class="sd">            local_shuffle_buffer_size: If not ``None``, the data is randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value serves as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer are drained.</span>
<span class="sd">                ``batch_size`` must also be specified when using local shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterable over TensorFlow Tensor batches.</span>

<span class="sd">        .. seealso::</span>
<span class="sd">            :meth:`Dataset.iter_batches`</span>
<span class="sd">                Call this method to manually convert your data to TensorFlow tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">iter_tf_batches</span><span class="p">(</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">dtypes</span><span class="o">=</span><span class="n">dtypes</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.to_torch">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_torch.html#ray.data.Dataset.to_torch">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_torch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">label_column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">label_column_dtype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_column_dtypes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;torch.dtype&quot;</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;torch.dtype&quot;</span><span class="p">]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">unsqueeze_label_tensor</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">unsqueeze_feature_tensors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;torch.utils.data.IterableDataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a</span>
<span class="sd">        `Torch IterableDataset &lt;https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset&gt;`_</span>
<span class="sd">        over this :class:`~ray.data.Dataset`.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>

<span class="sd">        It is recommended to use the returned ``IterableDataset`` directly</span>
<span class="sd">        instead of passing it into a torch ``DataLoader``.</span>

<span class="sd">        Each element in ``IterableDataset`` is a tuple consisting of 2</span>
<span class="sd">        elements. The first item contains the feature tensor(s), and the</span>
<span class="sd">        second item is the label tensor. Those can take on different</span>
<span class="sd">        forms, depending on the specified arguments.</span>

<span class="sd">        For the features tensor (N is the ``batch_size`` and n, m, k</span>
<span class="sd">        are the number of features per tensor):</span>

<span class="sd">        * If ``feature_columns`` is a ``List[str]``, the features is</span>
<span class="sd">          a tensor of shape (N, n), with columns corresponding to</span>
<span class="sd">          ``feature_columns``</span>

<span class="sd">        * If ``feature_columns`` is a ``List[List[str]]``, the features is</span>
<span class="sd">          a list of tensors of shape [(N, m),...,(N, k)], with columns of each</span>
<span class="sd">          tensor corresponding to the elements of ``feature_columns``</span>

<span class="sd">        * If ``feature_columns`` is a ``Dict[str, List[str]]``, the features</span>
<span class="sd">          is a dict of key-tensor pairs of shape</span>
<span class="sd">          {key1: (N, m),..., keyN: (N, k)}, with columns of each</span>
<span class="sd">          tensor corresponding to the value of ``feature_columns`` under the</span>
<span class="sd">          key.</span>

<span class="sd">        If ``unsqueeze_label_tensor=True`` (default), the label tensor is</span>
<span class="sd">        of shape (N, 1). Otherwise, it is of shape (N,).</span>
<span class="sd">        If ``label_column`` is specified as ``None``, then no column from the</span>
<span class="sd">        ``Dataset`` is treated as the label, and the output label tensor</span>
<span class="sd">        is ``None``.</span>

<span class="sd">        Note that you probably want to call :meth:`Dataset.split` on this dataset if</span>
<span class="sd">        there are to be multiple Torch workers consuming the data.</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Args:</span>
<span class="sd">            label_column: The name of the column used as the</span>
<span class="sd">                label (second element of the output list). Can be None for</span>
<span class="sd">                prediction, in which case the second element of returned</span>
<span class="sd">                tuple will also be None.</span>
<span class="sd">            feature_columns: The names of the columns</span>
<span class="sd">                to use as the features. Can be a list of lists or</span>
<span class="sd">                a dict of string-list pairs for multi-tensor output.</span>
<span class="sd">                If ``None``, then use all columns except the label column as</span>
<span class="sd">                the features.</span>
<span class="sd">            label_column_dtype: The torch dtype to</span>
<span class="sd">                use for the label column. If ``None``, then automatically infer</span>
<span class="sd">                the dtype.</span>
<span class="sd">            feature_column_dtypes: The dtypes to use for the feature</span>
<span class="sd">                tensors. This should match the format of ``feature_columns``,</span>
<span class="sd">                or be a single dtype, in which case it is applied to</span>
<span class="sd">                all tensors. If ``None``, then automatically infer the dtype.</span>
<span class="sd">            batch_size: How many samples per batch to yield at a time.</span>
<span class="sd">                Defaults to 1.</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool is used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the collate_fn. Defaults to 1.</span>
<span class="sd">            drop_last: Set to True to drop the last incomplete batch,</span>
<span class="sd">                if the dataset size is not divisible by the batch size. If</span>
<span class="sd">                False and the size of the stream is not divisible by the batch</span>
<span class="sd">                size, then the last batch is smaller. Defaults to False.</span>
<span class="sd">            local_shuffle_buffer_size: If non-None, the data is randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value will serve as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer is drained. This</span>
<span class="sd">                buffer size must be greater than or equal to ``batch_size``, and</span>
<span class="sd">                therefore ``batch_size`` must also be specified when using local</span>
<span class="sd">                shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>
<span class="sd">            unsqueeze_label_tensor: If set to True, the label tensor</span>
<span class="sd">                is unsqueezed (reshaped to (N, 1)). Otherwise, it will</span>
<span class="sd">                be left as is, that is (N, ). In general, regression loss</span>
<span class="sd">                functions expect an unsqueezed tensor, while classification</span>
<span class="sd">                loss functions expect a squeezed one. Defaults to True.</span>
<span class="sd">            unsqueeze_feature_tensors: If set to True, the features tensors</span>
<span class="sd">                are unsqueezed (reshaped to (N, 1)) before being concatenated into</span>
<span class="sd">                the final features tensor. Otherwise, they are left as is, that is</span>
<span class="sd">                (N, ). Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Torch IterableDataset`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span>
            <span class="n">label_column</span><span class="o">=</span><span class="n">label_column</span><span class="p">,</span>
            <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>
            <span class="n">label_column_dtype</span><span class="o">=</span><span class="n">label_column_dtype</span><span class="p">,</span>
            <span class="n">feature_column_dtypes</span><span class="o">=</span><span class="n">feature_column_dtypes</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
            <span class="n">unsqueeze_label_tensor</span><span class="o">=</span><span class="n">unsqueeze_label_tensor</span><span class="p">,</span>
            <span class="n">unsqueeze_feature_tensors</span><span class="o">=</span><span class="n">unsqueeze_feature_tensors</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.to_tf">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_tf.html#ray.data.Dataset.to_tf">[docs]</a>
    <span class="nd">@ConsumptionAPI</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_tf</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">feature_columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">label_columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">additional_columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prefetch_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">local_shuffle_buffer_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">local_shuffle_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_type_spec</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">label_type_spec</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">additional_type_spec</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf.TypeSpec&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;tf.data.Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a `TensorFlow Dataset &lt;https://www.tensorflow.org/api_docs/python/tf/data/Dataset/&gt;`_</span>
<span class="sd">        over this :class:`~ray.data.Dataset`.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            If your :class:`~ray.data.Dataset` contains ragged tensors, this method errors.</span>
<span class="sd">            To prevent errors, :ref:`resize your tensors &lt;transforming_tensors&gt;`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.read_csv(&quot;s3://anonymous@air-example-data/iris.csv&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds</span>
<span class="sd">            Dataset(</span>
<span class="sd">               num_rows=?,</span>
<span class="sd">               schema={</span>
<span class="sd">                  sepal length (cm): double,</span>
<span class="sd">                  sepal width (cm): double,</span>
<span class="sd">                  petal length (cm): double,</span>
<span class="sd">                  petal width (cm): double,</span>
<span class="sd">                  target: int64</span>
<span class="sd">               }</span>
<span class="sd">            )</span>

<span class="sd">            If your model accepts a single tensor as input, specify a single feature column.</span>

<span class="sd">            &gt;&gt;&gt; ds.to_tf(feature_columns=&quot;sepal length (cm)&quot;, label_columns=&quot;target&quot;)</span>
<span class="sd">            &lt;_OptionsDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.float64, name=&#39;sepal length (cm)&#39;), TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;target&#39;))&gt;</span>

<span class="sd">            If your model accepts a dictionary as input, specify a list of feature columns.</span>

<span class="sd">            &gt;&gt;&gt; ds.to_tf([&quot;sepal length (cm)&quot;, &quot;sepal width (cm)&quot;], &quot;target&quot;)</span>
<span class="sd">            &lt;_OptionsDataset element_spec=({&#39;sepal length (cm)&#39;: TensorSpec(shape=(None,), dtype=tf.float64, name=&#39;sepal length (cm)&#39;), &#39;sepal width (cm)&#39;: TensorSpec(shape=(None,), dtype=tf.float64, name=&#39;sepal width (cm)&#39;)}, TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;target&#39;))&gt;</span>

<span class="sd">            If your dataset contains multiple features but your model accepts a single</span>
<span class="sd">            tensor as input, combine features with</span>
<span class="sd">            :class:`~ray.data.preprocessors.Concatenator`.</span>

<span class="sd">            &gt;&gt;&gt; from ray.data.preprocessors import Concatenator</span>
<span class="sd">            &gt;&gt;&gt; preprocessor = Concatenator(output_column_name=&quot;features&quot;, exclude=&quot;target&quot;)</span>
<span class="sd">            &gt;&gt;&gt; ds = preprocessor.transform(ds)</span>
<span class="sd">            &gt;&gt;&gt; ds</span>
<span class="sd">            Concatenator</span>
<span class="sd">            +- Dataset(</span>
<span class="sd">                  num_rows=?,</span>
<span class="sd">                  schema={</span>
<span class="sd">                     sepal length (cm): double,</span>
<span class="sd">                     sepal width (cm): double,</span>
<span class="sd">                     petal length (cm): double,</span>
<span class="sd">                     petal width (cm): double,</span>
<span class="sd">                     target: int64</span>
<span class="sd">                  }</span>
<span class="sd">               )</span>
<span class="sd">            &gt;&gt;&gt; ds.to_tf(&quot;features&quot;, &quot;target&quot;)</span>
<span class="sd">            &lt;_OptionsDataset element_spec=(TensorSpec(shape=(None, 4), dtype=tf.float64, name=&#39;features&#39;), TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;target&#39;))&gt;</span>

<span class="sd">            If your model accepts different types, shapes, or names of tensors as input, specify the type spec.</span>
<span class="sd">            If type specs are not specified, they are automatically inferred from the schema of the dataset.</span>

<span class="sd">            &gt;&gt;&gt; import tensorflow as tf</span>
<span class="sd">            &gt;&gt;&gt; ds.to_tf(</span>
<span class="sd">            ...     feature_columns=&quot;features&quot;,</span>
<span class="sd">            ...     label_columns=&quot;target&quot;,</span>
<span class="sd">            ...     feature_type_spec=tf.TensorSpec(shape=(None, 4), dtype=tf.float32, name=&quot;features&quot;),</span>
<span class="sd">            ...     label_type_spec=tf.TensorSpec(shape=(None,), dtype=tf.float32, name=&quot;label&quot;)</span>
<span class="sd">            ... )</span>
<span class="sd">            &lt;_OptionsDataset element_spec=(TensorSpec(shape=(None, 4), dtype=tf.float32, name=&#39;features&#39;), TensorSpec(shape=(None,), dtype=tf.float32, name=&#39;label&#39;))&gt;</span>

<span class="sd">            If your model accepts additional metadata aside from features and label, specify a single additional column or a list of additional columns.</span>
<span class="sd">            A common use case is to include sample weights in the data samples and train a ``tf.keras.Model`` with ``tf.keras.Model.fit``.</span>

<span class="sd">            &gt;&gt;&gt; ds = ds.add_column(&quot;sample weights&quot;, lambda df: 1)</span>
<span class="sd">            &gt;&gt;&gt; ds.to_tf(feature_columns=&quot;features&quot;, label_columns=&quot;target&quot;, additional_columns=&quot;sample weights&quot;)</span>
<span class="sd">            &lt;_OptionsDataset element_spec=(TensorSpec(shape=(None, 4), dtype=tf.float64, name=&#39;features&#39;), TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;target&#39;), TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;sample weights&#39;))&gt;</span>

<span class="sd">            If your model accepts different types, shapes, or names for the additional metadata, specify the type spec of the additional column.</span>

<span class="sd">            &gt;&gt;&gt; ds.to_tf(</span>
<span class="sd">            ...     feature_columns=&quot;features&quot;,</span>
<span class="sd">            ...     label_columns=&quot;target&quot;,</span>
<span class="sd">            ...     additional_columns=&quot;sample weights&quot;,</span>
<span class="sd">            ...     additional_type_spec=tf.TensorSpec(shape=(None,), dtype=tf.float32, name=&quot;weight&quot;)</span>
<span class="sd">            ... )</span>
<span class="sd">            &lt;_OptionsDataset element_spec=(TensorSpec(shape=(None, 4), dtype=tf.float64, name=&#39;features&#39;), TensorSpec(shape=(None,), dtype=tf.int64, name=&#39;target&#39;), TensorSpec(shape=(None,), dtype=tf.float32, name=&#39;weight&#39;))&gt;</span>

<span class="sd">        Args:</span>
<span class="sd">            feature_columns: Columns that correspond to model inputs. If this is a</span>
<span class="sd">                string, the input data is a tensor. If this is a list, the input data</span>
<span class="sd">                is a ``dict`` that maps column names to their tensor representation.</span>
<span class="sd">            label_columns: Columns that correspond to model targets. If this is a</span>
<span class="sd">                string, the target data is a tensor. If this is a list, the target data</span>
<span class="sd">                is a ``dict`` that maps column names to their tensor representation.</span>
<span class="sd">            additional_columns: Columns that correspond to sample weights or other metadata.</span>
<span class="sd">                If this is a string, the weight data is a tensor. If this is a list, the</span>
<span class="sd">                weight data is a ``dict`` that maps column names to their tensor representation.</span>
<span class="sd">            prefetch_batches: The number of batches to fetch ahead of the current batch</span>
<span class="sd">                to fetch. If set to greater than 0, a separate threadpool is used</span>
<span class="sd">                to fetch the objects to the local node, format the batches, and apply</span>
<span class="sd">                the collate_fn. Defaults to 1.</span>
<span class="sd">            batch_size: Record batch size. Defaults to 1.</span>
<span class="sd">            drop_last: Set to True to drop the last incomplete batch,</span>
<span class="sd">                if the dataset size is not divisible by the batch size. If</span>
<span class="sd">                False and the size of the stream is not divisible by the batch</span>
<span class="sd">                size, then the last batch is smaller. Defaults to False.</span>
<span class="sd">            local_shuffle_buffer_size: If non-None, the data is randomly shuffled</span>
<span class="sd">                using a local in-memory shuffle buffer, and this value will serve as the</span>
<span class="sd">                minimum number of rows that must be in the local in-memory shuffle</span>
<span class="sd">                buffer in order to yield a batch. When there are no more rows to add to</span>
<span class="sd">                the buffer, the remaining rows in the buffer is drained. This</span>
<span class="sd">                buffer size must be greater than or equal to ``batch_size``, and</span>
<span class="sd">                therefore ``batch_size`` must also be specified when using local</span>
<span class="sd">                shuffling.</span>
<span class="sd">            local_shuffle_seed: The seed to use for the local random shuffle.</span>
<span class="sd">            feature_type_spec: The `tf.TypeSpec` of `feature_columns`. If there is</span>
<span class="sd">                only one column, specify a `tf.TypeSpec`. If there are multiple columns,</span>
<span class="sd">                specify a ``dict`` that maps column names to their `tf.TypeSpec`.</span>
<span class="sd">                Default is `None` to automatically infer the type of each column.</span>
<span class="sd">            label_type_spec: The `tf.TypeSpec` of `label_columns`. If there is</span>
<span class="sd">                only one column, specify a `tf.TypeSpec`. If there are multiple columns,</span>
<span class="sd">                specify a ``dict`` that maps column names to their `tf.TypeSpec`.</span>
<span class="sd">                Default is `None` to automatically infer the type of each column.</span>
<span class="sd">            additional_type_spec: The `tf.TypeSpec` of `additional_columns`. If there</span>
<span class="sd">                is only one column, specify a `tf.TypeSpec`. If there are multiple</span>
<span class="sd">                columns, specify a ``dict`` that maps column names to their `tf.TypeSpec`.</span>
<span class="sd">                Default is `None` to automatically infer the type of each column.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `TensorFlow Dataset`_ that yields inputs and targets.</span>

<span class="sd">        .. seealso::</span>

<span class="sd">            :meth:`~ray.data.Dataset.iter_tf_batches`</span>
<span class="sd">                Call this method if you need more flexibility.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterator</span><span class="p">()</span><span class="o">.</span><span class="n">to_tf</span><span class="p">(</span>
            <span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>
            <span class="n">label_columns</span><span class="o">=</span><span class="n">label_columns</span><span class="p">,</span>
            <span class="n">additional_columns</span><span class="o">=</span><span class="n">additional_columns</span><span class="p">,</span>
            <span class="n">prefetch_batches</span><span class="o">=</span><span class="n">prefetch_batches</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">local_shuffle_buffer_size</span><span class="o">=</span><span class="n">local_shuffle_buffer_size</span><span class="p">,</span>
            <span class="n">local_shuffle_seed</span><span class="o">=</span><span class="n">local_shuffle_seed</span><span class="p">,</span>
            <span class="n">feature_type_spec</span><span class="o">=</span><span class="n">feature_type_spec</span><span class="p">,</span>
            <span class="n">label_type_spec</span><span class="o">=</span><span class="n">label_type_spec</span><span class="p">,</span>
            <span class="n">additional_type_spec</span><span class="o">=</span><span class="n">additional_type_spec</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.to_dask">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_dask.html#ray.data.Dataset.to_dask">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_dask</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">meta</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
            <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pandas.Series&quot;</span><span class="p">,</span>
            <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
            <span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
            <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">verify_meta</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;dask.dataframe.DataFrame&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` into a</span>
<span class="sd">        `Dask DataFrame &lt;https://docs.dask.org/en/stable/generated/dask.dataframe.DataFrame.html#dask.dataframe.DataFrame&gt;`_.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>

<span class="sd">        Note that this function will set the Dask scheduler to Dask-on-Ray</span>
<span class="sd">        globally, via the config.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            meta: An empty `pandas DataFrame`_ or `Series`_ that matches the dtypes and column</span>
<span class="sd">                names of the stream. This metadata is necessary for many algorithms in</span>
<span class="sd">                dask dataframe to work. For ease of use, some alternative inputs are</span>
<span class="sd">                also available. Instead of a DataFrame, a dict of ``{name: dtype}`` or</span>
<span class="sd">                iterable of ``(name, dtype)`` can be provided (note that the order of</span>
<span class="sd">                the names should match the order of the columns). Instead of a series, a</span>
<span class="sd">                tuple of ``(name, dtype)`` can be used.</span>
<span class="sd">                By default, this is inferred from the underlying Dataset schema,</span>
<span class="sd">                with this argument supplying an optional override.</span>
<span class="sd">            verify_meta: If True, Dask will check that the partitions have consistent</span>
<span class="sd">                metadata. Defaults to True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Dask DataFrame`_ created from this dataset.</span>

<span class="sd">        .. _pandas DataFrame: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html</span>
<span class="sd">        .. _Series: https://pandas.pydata.org/docs/reference/api/pandas.Series.html</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="kn">import</span> <span class="nn">dask</span>
        <span class="kn">import</span> <span class="nn">dask.dataframe</span> <span class="k">as</span> <span class="nn">dd</span>
        <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">pa</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="kn">from</span> <span class="nn">ray.data._internal.pandas_block</span> <span class="kn">import</span> <span class="n">PandasBlockSchema</span>
        <span class="kn">from</span> <span class="nn">ray.util.client.common</span> <span class="kn">import</span> <span class="n">ClientObjectRef</span>
        <span class="kn">from</span> <span class="nn">ray.util.dask</span> <span class="kn">import</span> <span class="n">ray_dask_get</span>

        <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="n">ray_dask_get</span><span class="p">)</span>

        <span class="nd">@dask</span><span class="o">.</span><span class="n">delayed</span>
        <span class="k">def</span> <span class="nf">block_to_df</span><span class="p">(</span><span class="n">block_ref</span><span class="p">:</span> <span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">block_ref</span><span class="p">,</span> <span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">ObjectRef</span><span class="p">,</span> <span class="n">ClientObjectRef</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Dataset.to_dask() must be used with Dask-on-Ray, please &quot;</span>
                    <span class="s2">&quot;set the Dask scheduler to ray_dask_get (located in &quot;</span>
                    <span class="s2">&quot;ray.util.dask).&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">_block_to_df</span><span class="p">(</span><span class="n">block_ref</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">meta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">TensorDtype</span>

            <span class="c1"># Infer Dask metadata from Dataset schema.</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">PandasBlockSchema</span><span class="p">):</span>
                <span class="n">meta</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="n">col</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
                            <span class="n">dtype</span><span class="o">=</span><span class="p">(</span>
                                <span class="n">dtype</span>
                                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">TensorDtype</span><span class="p">)</span>
                                <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">object_</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                        <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>
                    <span class="p">}</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">pa</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
                <span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">ArrowTensorType</span>

                <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">type_</span><span class="p">,</span> <span class="n">ArrowTensorType</span><span class="p">)</span> <span class="k">for</span> <span class="n">type_</span> <span class="ow">in</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">):</span>
                    <span class="n">meta</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="n">col</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
                                <span class="n">dtype</span><span class="o">=</span><span class="p">(</span>
                                    <span class="n">dtype</span><span class="o">.</span><span class="n">to_pandas_dtype</span><span class="p">()</span>
                                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ArrowTensorType</span><span class="p">)</span>
                                    <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">object_</span>
                                <span class="p">)</span>
                            <span class="p">)</span>
                            <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">meta</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">empty_table</span><span class="p">()</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>

        <span class="n">dfs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ref_bundle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_internal_ref_bundles</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">block_ref</span> <span class="ow">in</span> <span class="n">ref_bundle</span><span class="o">.</span><span class="n">block_refs</span><span class="p">:</span>
                <span class="n">dfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">block_to_df</span><span class="p">(</span><span class="n">block_ref</span><span class="p">))</span>

        <span class="n">ddf</span> <span class="o">=</span> <span class="n">dd</span><span class="o">.</span><span class="n">from_delayed</span><span class="p">(</span>
            <span class="n">dfs</span><span class="p">,</span>
            <span class="n">meta</span><span class="o">=</span><span class="n">meta</span><span class="p">,</span>
            <span class="n">verify_meta</span><span class="o">=</span><span class="n">verify_meta</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">ddf</span></div>


<div class="viewcode-block" id="Dataset.to_mars">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_mars.html#ray.data.Dataset.to_mars">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_mars</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;mars.dataframe.DataFrame&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` into a</span>
<span class="sd">        `Mars DataFrame &lt;https://mars-project.readthedocs.io/en/latest/reference/dataframe/index.html&gt;`_.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Mars DataFrame`_ created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
        <span class="kn">from</span> <span class="nn">mars.dataframe.datasource.read_raydataset</span> <span class="kn">import</span> <span class="n">DataFrameReadRayDataset</span>
        <span class="kn">from</span> <span class="nn">mars.dataframe.utils</span> <span class="kn">import</span> <span class="n">parse_index</span>

        <span class="kn">from</span> <span class="nn">ray.data._internal.pandas_block</span> <span class="kn">import</span> <span class="n">PandasBlockSchema</span>

        <span class="n">refs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_pandas_refs</span><span class="p">()</span>
        <span class="c1"># remove this when https://github.com/mars-project/mars/issues/2945 got fixed</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">Schema</span><span class="p">):</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">base_schema</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">PandasBlockSchema</span><span class="p">):</span>
            <span class="n">dtypes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
            <span class="n">dtypes</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">empty_table</span><span class="p">()</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span><span class="o">.</span><span class="n">dtypes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported format of schema </span><span class="si">{</span><span class="n">schema</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">index_value</span> <span class="o">=</span> <span class="n">parse_index</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">RangeIndex</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">columns_value</span> <span class="o">=</span> <span class="n">parse_index</span><span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">store_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">DataFrameReadRayDataset</span><span class="p">(</span><span class="n">refs</span><span class="o">=</span><span class="n">refs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">op</span><span class="p">(</span><span class="n">index_value</span><span class="o">=</span><span class="n">index_value</span><span class="p">,</span> <span class="n">columns_value</span><span class="o">=</span><span class="n">columns_value</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">=</span><span class="n">dtypes</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.to_modin">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_modin.html#ray.data.Dataset.to_modin">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_modin</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;modin.pandas.dataframe.DataFrame&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` into a</span>
<span class="sd">        `Modin DataFrame &lt;https://modin.readthedocs.io/en/stable/flow/modin/pandas/dataframe.html&gt;`_.</span>

<span class="sd">        This works by first converting this dataset into a distributed set of</span>
<span class="sd">        Pandas DataFrames (using :meth:`Dataset.to_pandas_refs`).</span>
<span class="sd">        See caveats there. Then the individual DataFrames are used to</span>
<span class="sd">        create the Modin DataFrame using</span>
<span class="sd">        ``modin.distributed.dataframe.pandas.partitions.from_partitions()``.</span>

<span class="sd">        This is only supported for datasets convertible to Arrow records.</span>
<span class="sd">        This function induces a copy of the data. For zero-copy access to the</span>
<span class="sd">        underlying data, consider using :meth:`.to_arrow_refs` or</span>
<span class="sd">        :meth:`.iter_internal_ref_bundles`.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Modin DataFrame`_ created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="kn">from</span> <span class="nn">modin.distributed.dataframe.pandas.partitions</span> <span class="kn">import</span> <span class="n">from_partitions</span>

        <span class="n">pd_objs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_pandas_refs</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">from_partitions</span><span class="p">(</span><span class="n">pd_objs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.to_spark">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_spark.html#ray.data.Dataset.to_spark">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_spark</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spark</span><span class="p">:</span> <span class="s2">&quot;pyspark.sql.SparkSession&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pyspark.sql.DataFrame&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` into a</span>
<span class="sd">        `Spark DataFrame &lt;https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.html&gt;`_.</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            spark: A `SparkSession`_, which must be created by RayDP (Spark-on-Ray).</span>

<span class="sd">        Returns:</span>
<span class="sd">            A `Spark DataFrame`_ created from this dataset.</span>

<span class="sd">        .. _SparkSession: https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.SparkSession.html</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="kn">import</span> <span class="nn">raydp</span>

        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">Schema</span><span class="p">):</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">base_schema</span>

        <span class="n">ref_bundles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_internal_ref_bundles</span><span class="p">()</span>
        <span class="n">block_refs</span> <span class="o">=</span> <span class="n">_ref_bundles_iterator_to_block_refs_list</span><span class="p">(</span><span class="n">ref_bundles</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">raydp</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">ray_dataset_to_spark_dataframe</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="n">schema</span><span class="p">,</span> <span class="n">block_refs</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.to_pandas">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_pandas.html#ray.data.Dataset.to_pandas">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IOC_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_pandas</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">limit</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` to a single pandas DataFrame.</span>

<span class="sd">        This method errors if the number of rows exceeds the provided ``limit``.</span>
<span class="sd">        To truncate the dataset beforehand, call :meth:`.limit`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.from_items([{&quot;a&quot;: i} for i in range(3)])</span>
<span class="sd">            &gt;&gt;&gt; ds.to_pandas()</span>
<span class="sd">               a</span>
<span class="sd">            0  0</span>
<span class="sd">            1  1</span>
<span class="sd">            2  2</span>

<span class="sd">        Time complexity: O(dataset size)</span>

<span class="sd">        Args:</span>
<span class="sd">            limit: The maximum number of rows to return. An error is</span>
<span class="sd">                raised if the dataset has more rows than this limit. Defaults to</span>
<span class="sd">                ``None``, which means no limit.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A pandas DataFrame created from this dataset, containing a limited</span>
<span class="sd">            number of rows.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if the number of rows in the :class:`~ray.data.Dataset` exceeds</span>
<span class="sd">                ``limit``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">limit</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="n">limit</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;the dataset has more than the given limit of </span><span class="si">{</span><span class="n">limit</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;rows: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2">. If you are sure that a DataFrame with &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> rows will fit in local memory, set &quot;</span>
                    <span class="s2">&quot;ds.to_pandas(limit=None) to disable limits.&quot;</span>
                <span class="p">)</span>
        <span class="n">bundles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_internal_ref_bundles</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">DelegatingBlockBuilder</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">bundle</span> <span class="ow">in</span> <span class="n">bundles</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">block_ref</span> <span class="ow">in</span> <span class="n">bundle</span><span class="o">.</span><span class="n">block_refs</span><span class="p">:</span>
                <span class="n">output</span><span class="o">.</span><span class="n">add_block</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">block_ref</span><span class="p">))</span>
        <span class="n">block</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">)</span></div>


<div class="viewcode-block" id="Dataset.to_pandas_refs">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_pandas_refs.html#ray.data.Dataset.to_pandas_refs">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">to_pandas_refs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts this :class:`~ray.data.Dataset` into a distributed set of Pandas</span>
<span class="sd">        dataframes.</span>

<span class="sd">        One DataFrame is created for each block in this Dataset.</span>

<span class="sd">        This function induces a copy of the data. For zero-copy access to the</span>
<span class="sd">        underlying data, consider using :meth:`Dataset.to_arrow_refs` or</span>
<span class="sd">        :meth:`Dataset.iter_internal_ref_bundles`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10, override_num_blocks=2)</span>
<span class="sd">            &gt;&gt;&gt; refs = ds.to_pandas_refs()</span>
<span class="sd">            &gt;&gt;&gt; len(refs)</span>
<span class="sd">            2</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of remote pandas DataFrames created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">block_to_df</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_block_to_df</span><span class="p">)</span>
        <span class="n">pandas_refs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">bundle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_internal_ref_bundles</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">block_ref</span> <span class="ow">in</span> <span class="n">bundle</span><span class="o">.</span><span class="n">block_refs</span><span class="p">:</span>
                <span class="n">pandas_refs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">block_to_df</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block_ref</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">pandas_refs</span></div>


<div class="viewcode-block" id="Dataset.to_numpy_refs">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_numpy_refs.html#ray.data.Dataset.to_numpy_refs">[docs]</a>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">to_numpy_refs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts this :class:`~ray.data.Dataset` into a distributed set of NumPy</span>
<span class="sd">        ndarrays or dictionary of NumPy ndarrays.</span>

<span class="sd">        This is only supported for datasets convertible to NumPy ndarrays.</span>
<span class="sd">        This function induces a copy of the data. For zero-copy access to the</span>
<span class="sd">        underlying data, consider using :meth:`Dataset.to_arrow_refs` or</span>
<span class="sd">        :meth:`Dataset.iter_internal_ref_bundles`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10, override_num_blocks=2)</span>
<span class="sd">            &gt;&gt;&gt; refs = ds.to_numpy_refs()</span>
<span class="sd">            &gt;&gt;&gt; len(refs)</span>
<span class="sd">            2</span>

<span class="sd">        Time complexity: O(dataset size / parallelism)</span>

<span class="sd">        Args:</span>
<span class="sd">            column: The name of the column to convert to numpy. If ``None``, all columns</span>
<span class="sd">                are used. If multiple columns are specified, each returned</span>
<span class="sd">            future represents a dict of ndarrays. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of remote NumPy ndarrays created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">block_to_ndarray</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_block_to_ndarray</span><span class="p">)</span>
        <span class="n">numpy_refs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">bundle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_internal_ref_bundles</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">block_ref</span> <span class="ow">in</span> <span class="n">bundle</span><span class="o">.</span><span class="n">block_refs</span><span class="p">:</span>
                <span class="n">numpy_refs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">block_to_ndarray</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block_ref</span><span class="p">,</span> <span class="n">column</span><span class="o">=</span><span class="n">column</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">numpy_refs</span></div>


<div class="viewcode-block" id="Dataset.to_arrow_refs">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.to_arrow_refs.html#ray.data.Dataset.to_arrow_refs">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Time complexity:&quot;</span><span class="p">)</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">to_arrow_refs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert this :class:`~ray.data.Dataset` into a distributed set of PyArrow</span>
<span class="sd">        tables.</span>

<span class="sd">        One PyArrow table is created for each block in this Dataset.</span>

<span class="sd">        This method is only supported for datasets convertible to PyArrow tables.</span>
<span class="sd">        This function is zero-copy if the existing data is already in PyArrow</span>
<span class="sd">        format. Otherwise, the data is converted to PyArrow format.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10, override_num_blocks=2)</span>
<span class="sd">            &gt;&gt;&gt; refs = ds.to_arrow_refs()</span>
<span class="sd">            &gt;&gt;&gt; len(refs)</span>
<span class="sd">            2</span>

<span class="sd">        Time complexity: O(1) unless conversion is required.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of remote PyArrow tables created from this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

        <span class="n">ref_bundles</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">RefBundle</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_internal_ref_bundles</span><span class="p">()</span>
        <span class="n">block_refs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span>
            <span class="n">ObjectRef</span><span class="p">[</span><span class="s2">&quot;pyarrow.Table&quot;</span><span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="n">_ref_bundles_iterator_to_block_refs_list</span><span class="p">(</span><span class="n">ref_bundles</span><span class="p">)</span>
        <span class="c1"># Schema is safe to call since we have already triggered execution with</span>
        <span class="c1"># iter_internal_ref_bundles.</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">Schema</span><span class="p">):</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">base_schema</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
            <span class="c1"># Zero-copy path.</span>
            <span class="k">return</span> <span class="n">block_refs</span>

        <span class="n">block_to_arrow</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_block_to_arrow</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">block_to_arrow</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">block_refs</span><span class="p">]</span></div>


    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Args:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">to_random_access_dataset</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RandomAccessDataset</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert this dataset into a distributed RandomAccessDataset (EXPERIMENTAL).</span>

<span class="sd">        RandomAccessDataset partitions the dataset across the cluster by the given</span>
<span class="sd">        sort key, providing efficient random access to records via binary search. A</span>
<span class="sd">        number of worker actors are created, each of which has zero-copy access to the</span>
<span class="sd">        underlying sorted data blocks of the dataset.</span>

<span class="sd">        Note that the key must be unique in the dataset. If there are duplicate keys,</span>
<span class="sd">        an arbitrary value is returned.</span>

<span class="sd">        This is only supported for Arrow-format datasets.</span>

<span class="sd">        Args:</span>
<span class="sd">            key: The key column over which records can be queried.</span>
<span class="sd">            num_workers: The number of actors to use to serve random access queries.</span>
<span class="sd">                By default, this is determined by multiplying the number of Ray nodes</span>
<span class="sd">                in the cluster by four. As a rule of thumb, you can expect each worker</span>
<span class="sd">                to provide ~3000 records / second via ``get_async()``, and</span>
<span class="sd">                ~10000 records / second via ``multiget()``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">num_workers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">RandomAccessDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">)</span>

<div class="viewcode-block" id="Dataset.materialize">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.materialize.html#ray.data.Dataset.materialize">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;store memory.&quot;</span><span class="p">,</span> <span class="n">insert_after</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">E_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">materialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;MaterializedDataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute and materialize this dataset into object store memory.</span>

<span class="sd">        This can be used to read all blocks into memory. By default, Dataset</span>
<span class="sd">        doesn&#39;t read blocks from the datasource until the first transform.</span>

<span class="sd">        Note that this does not mutate the original Dataset. Only the blocks of the</span>
<span class="sd">        returned MaterializedDataset class are pinned in memory.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(10)</span>
<span class="sd">            &gt;&gt;&gt; materialized_ds = ds.materialize()</span>
<span class="sd">            &gt;&gt;&gt; materialized_ds</span>
<span class="sd">            MaterializedDataset(num_blocks=..., num_rows=10, schema={id: int64})</span>

<span class="sd">        Returns:</span>
<span class="sd">            A MaterializedDataset holding the materialized data blocks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">copy</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_deep_copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">_as</span><span class="o">=</span><span class="n">MaterializedDataset</span><span class="p">)</span>
        <span class="n">copy</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>

        <span class="n">bundle</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_snapshot_bundle</span>
        <span class="n">blocks_with_metadata</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">blocks</span>
        <span class="c1"># TODO(hchen): Here we generate the same number of blocks as</span>
        <span class="c1"># the original Dataset. Because the old code path does this, and</span>
        <span class="c1"># some unit tests implicily depend on this behavior.</span>
        <span class="c1"># After we remove the old code path, we should consider merging</span>
        <span class="c1"># some blocks for better perf.</span>
        <span class="n">ref_bundles</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">RefBundle</span><span class="p">(</span>
                <span class="n">blocks</span><span class="o">=</span><span class="p">[</span><span class="n">block_with_metadata</span><span class="p">],</span>
                <span class="n">owns_blocks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">block_with_metadata</span> <span class="ow">in</span> <span class="n">blocks_with_metadata</span>
        <span class="p">]</span>
        <span class="n">logical_plan</span> <span class="o">=</span> <span class="n">LogicalPlan</span><span class="p">(</span><span class="n">InputData</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">ref_bundles</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">MaterializedDataset</span><span class="p">(</span>
            <span class="n">ExecutionPlan</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()),</span>
            <span class="n">logical_plan</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Metrics are tagged with `copy`s uuid, update the output uuid with</span>
        <span class="c1"># this so the user can access the metrics label.</span>
        <span class="n">output</span><span class="o">.</span><span class="n">_set_name</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span>
        <span class="n">output</span><span class="o">.</span><span class="n">_set_uuid</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">_get_uuid</span><span class="p">())</span>
        <span class="n">output</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>  <span class="c1"># No-op that marks the plan as fully executed.</span>
        <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="Dataset.stats">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.stats.html#ray.data.Dataset.stats">[docs]</a>
    <span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">api_group</span><span class="o">=</span><span class="n">IM_API_GROUP</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">stats</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a string containing execution timing information.</span>

<span class="sd">        Note that this does not trigger execution, so if the dataset has not yet</span>
<span class="sd">        executed, an empty string is returned.</span>

<span class="sd">        Examples:</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            import ray</span>

<span class="sd">            ds = ray.data.range(10)</span>
<span class="sd">            assert ds.stats() == &quot;&quot;</span>

<span class="sd">            ds = ds.materialize()</span>
<span class="sd">            print(ds.stats())</span>

<span class="sd">        .. testoutput::</span>
<span class="sd">            :options: +MOCK</span>

<span class="sd">            Operator 0 Read: 1 tasks executed, 5 blocks produced in 0s</span>
<span class="sd">            * Remote wall time: 16.29us min, 7.29ms max, 1.21ms mean, 24.17ms total</span>
<span class="sd">            * Remote cpu time: 16.0us min, 2.54ms max, 810.45us mean, 16.21ms total</span>
<span class="sd">            * Peak heap memory usage (MiB): 137968.75 min, 142734.38 max, 139846 mean</span>
<span class="sd">            * Output num rows: 0 min, 1 max, 0 mean, 10 total</span>
<span class="sd">            * Output size bytes: 0 min, 8 max, 4 mean, 80 total</span>
<span class="sd">            * Tasks per node: 20 min, 20 max, 20 mean; 1 nodes used</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="o">.</span><span class="n">get_stats</span><span class="p">()</span><span class="o">.</span><span class="n">to_summary</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_write_ds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_write_ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">has_computed_output</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_write_ds</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_stats_summary</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span></div>


    <span class="k">def</span> <span class="nf">_get_stats_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DatasetStatsSummary</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">stats</span><span class="p">()</span><span class="o">.</span><span class="n">to_summary</span><span class="p">()</span>

<div class="viewcode-block" id="Dataset.iter_internal_ref_bundles">
<a class="viewcode-back" href="../../../data/api/doc/ray.data.Dataset.iter_internal_ref_bundles.html#ray.data.Dataset.iter_internal_ref_bundles">[docs]</a>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Examples:&quot;</span><span class="p">)</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">iter_internal_ref_bundles</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">RefBundle</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get an iterator over ``RefBundles``</span>
<span class="sd">        belonging to this Dataset. Calling this function doesn&#39;t keep</span>
<span class="sd">        the data materialized in-memory.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1)</span>
<span class="sd">            &gt;&gt;&gt; for ref_bundle in ds.iter_internal_ref_bundles():</span>
<span class="sd">            ...     for block_ref, block_md in ref_bundle.blocks:</span>
<span class="sd">            ...         block = ray.get(block_ref)</span>

<span class="sd">        Returns:</span>
<span class="sd">            An iterator over this Dataset&#39;s ``RefBundles``.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">iter_ref_bundles</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute_to_iterator</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">iter_ref_bundles</span></div>


    <span class="nd">@Deprecated</span>
    <span class="nd">@ConsumptionAPI</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;Examples:&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">get_internal_block_refs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ObjectRef</span><span class="p">[</span><span class="n">Block</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get a list of references to the underlying blocks of this dataset.</span>

<span class="sd">        This function can be used for zero-copy access to the data. It blocks</span>
<span class="sd">        until the underlying blocks are computed.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(1)</span>
<span class="sd">            &gt;&gt;&gt; ds.get_internal_block_refs()</span>
<span class="sd">            [ObjectRef(...)]</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of references to this dataset&#39;s blocks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;`Dataset.get_internal_block_refs()` is deprecated. Use &quot;</span>
            <span class="s2">&quot;`Dataset.iter_internal_ref_bundles()` instead.&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">block_refs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span><span class="o">.</span><span class="n">block_refs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_synchronize_progress_bar</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">block_refs</span>

    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">has_serializable_lineage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Whether this dataset&#39;s lineage is able to be serialized for storage and</span>
<span class="sd">        later deserialized, possibly on a different cluster.</span>

<span class="sd">        Only datasets that are created from data that we know will still exist at</span>
<span class="sd">        deserialization time, e.g. data external to this Ray cluster such as persistent</span>
<span class="sd">        cloud object stores, support lineage-based serialization. All of the</span>
<span class="sd">        ray.data.read_*() APIs support lineage-based serialization.</span>

<span class="sd">        Examples:</span>

<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ray.data.from_items(list(range(10))).has_serializable_lineage()</span>
<span class="sd">            False</span>
<span class="sd">            &gt;&gt;&gt; ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris.csv&quot;).has_serializable_lineage()</span>
<span class="sd">            True</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">op</span><span class="o">.</span><span class="n">is_lineage_serializable</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="o">.</span><span class="n">dag</span><span class="o">.</span><span class="n">post_order_iter</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">serialize_lineage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bytes</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Serialize this dataset&#39;s lineage, not the actual data or the existing data</span>
<span class="sd">        futures, to bytes that can be stored and later deserialized, possibly on a</span>
<span class="sd">        different cluster.</span>

<span class="sd">        Note that this uses pickle and will drop all computed data, and that everything</span>
<span class="sd">        is recomputed from scratch after deserialization.</span>

<span class="sd">        Use :py:meth:`Dataset.deserialize_lineage` to deserialize the serialized</span>
<span class="sd">        bytes returned from this method into a Dataset.</span>

<span class="sd">        .. note::</span>
<span class="sd">            Unioned and zipped datasets, produced by :py:meth`Dataset.union` and</span>
<span class="sd">            :py:meth:`Dataset.zip`, are not lineage-serializable.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris.csv&quot;)</span>
<span class="sd">                serialized_ds = ds.serialize_lineage()</span>
<span class="sd">                ds = ray.data.Dataset.deserialize_lineage(serialized_ds)</span>
<span class="sd">                print(ds)</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                Dataset(</span>
<span class="sd">                   num_rows=?,</span>
<span class="sd">                   schema={</span>
<span class="sd">                      sepal length (cm): double,</span>
<span class="sd">                      sepal width (cm): double,</span>
<span class="sd">                      petal length (cm): double,</span>
<span class="sd">                      petal width (cm): double,</span>
<span class="sd">                      target: int64</span>
<span class="sd">                   }</span>
<span class="sd">                )</span>


<span class="sd">        Returns:</span>
<span class="sd">            Serialized bytes containing the lineage of this dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_serializable_lineage</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Lineage-based serialization is not supported for this stream, which &quot;</span>
                <span class="s2">&quot;means that it cannot be used as a tunable hyperparameter. &quot;</span>
                <span class="s2">&quot;Lineage-based serialization is explicitly NOT supported for unioned &quot;</span>
                <span class="s2">&quot;or zipped datasets (see docstrings for those methods), and is only &quot;</span>
                <span class="s2">&quot;supported for datasets created from data that we know will still &quot;</span>
                <span class="s2">&quot;exist at deserialization time, e.g. external data in persistent cloud &quot;</span>
                <span class="s2">&quot;object stores or in-memory data from long-lived clusters. Concretely, &quot;</span>
                <span class="s2">&quot;all ray.data.read_*() APIs should support lineage-based &quot;</span>
                <span class="s2">&quot;serialization, while all of the ray.data.from_*() APIs do not. To &quot;</span>
                <span class="s2">&quot;allow this stream to be serialized to storage, write the data to an &quot;</span>
                <span class="s2">&quot;external store (such as AWS S3, GCS, or Azure Blob Storage) using the &quot;</span>
                <span class="s2">&quot;Dataset.write_*() APIs, and serialize a new dataset reading &quot;</span>
                <span class="s2">&quot;from the external store using the ray.data.read_*() APIs.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Copy Dataset and clear the blocks from the execution plan so only the</span>
        <span class="c1"># Dataset&#39;s lineage is serialized.</span>
        <span class="n">plan_copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">deep_copy</span><span class="p">()</span>
        <span class="n">logical_plan_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_logical_plan</span><span class="p">)</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">plan_copy</span><span class="p">,</span> <span class="n">logical_plan_copy</span><span class="p">)</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">clear_snapshot</span><span class="p">()</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">_set_uuid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_uuid</span><span class="p">())</span>

        <span class="k">def</span> <span class="nf">_reduce_remote_fn</span><span class="p">(</span><span class="n">rf</span><span class="p">:</span> <span class="n">ray</span><span class="o">.</span><span class="n">remote_function</span><span class="o">.</span><span class="n">RemoteFunction</span><span class="p">):</span>
            <span class="c1"># Custom reducer for Ray remote function handles that allows for</span>
            <span class="c1"># cross-cluster serialization.</span>
            <span class="c1"># This manually unsets the last export session and job to force re-exporting</span>
            <span class="c1"># of the function when the handle is deserialized on a new cluster.</span>
            <span class="c1"># TODO(Clark): Fix this in core Ray, see issue:</span>
            <span class="c1"># https://github.com/ray-project/ray/issues/24152.</span>
            <span class="n">reconstructor</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">__reduce__</span><span class="p">()</span>
            <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_last_export_session_and_job&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">return</span> <span class="n">reconstructor</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">state</span>

        <span class="n">context</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">_private</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">global_worker</span><span class="o">.</span><span class="n">get_serialization_context</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">context</span><span class="o">.</span><span class="n">_register_cloudpickle_reducer</span><span class="p">(</span>
                <span class="n">ray</span><span class="o">.</span><span class="n">remote_function</span><span class="o">.</span><span class="n">RemoteFunction</span><span class="p">,</span> <span class="n">_reduce_remote_fn</span>
            <span class="p">)</span>
            <span class="n">serialized</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">context</span><span class="o">.</span><span class="n">_unregister_cloudpickle_reducer</span><span class="p">(</span><span class="n">ray</span><span class="o">.</span><span class="n">remote_function</span><span class="o">.</span><span class="n">RemoteFunction</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">serialized</span>

    <span class="nd">@staticmethod</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">deserialize_lineage</span><span class="p">(</span><span class="n">serialized_ds</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;Dataset&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Deserialize the provided lineage-serialized Dataset.</span>

<span class="sd">        This uses pickle, and assumes that the provided serialized bytes were</span>
<span class="sd">        serialized using :py:meth:`Dataset.serialize_lineage`.</span>

<span class="sd">        Examples:</span>

<span class="sd">            .. testcode::</span>

<span class="sd">                import ray</span>

<span class="sd">                ds = ray.data.read_csv(&quot;s3://anonymous@ray-example-data/iris.csv&quot;)</span>
<span class="sd">                serialized_ds = ds.serialize_lineage()</span>
<span class="sd">                ds = ray.data.Dataset.deserialize_lineage(serialized_ds)</span>
<span class="sd">                print(ds)</span>

<span class="sd">            .. testoutput::</span>

<span class="sd">                Dataset(</span>
<span class="sd">                   num_rows=?,</span>
<span class="sd">                   schema={</span>
<span class="sd">                      sepal length (cm): double,</span>
<span class="sd">                      sepal width (cm): double,</span>
<span class="sd">                      petal length (cm): double,</span>
<span class="sd">                      petal width (cm): double,</span>
<span class="sd">                      target: int64</span>
<span class="sd">                   }</span>
<span class="sd">                )</span>

<span class="sd">        Args:</span>
<span class="sd">            serialized_ds: The serialized Dataset that we wish to deserialize.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A deserialized ``Dataset`` instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">serialized_ds</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="nd">@DeveloperAPI</span>
    <span class="k">def</span> <span class="nf">context</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataContext</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the DataContext used to create this Dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_context</span>

    <span class="k">def</span> <span class="nf">_aggregate_on</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">agg_cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">,</span> <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]],</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper for aggregating on a particular subset of the dataset.</span>

<span class="sd">        This validates the `on` argument, and converts a list of column names</span>
<span class="sd">        or lambdas to a multi-aggregation. A null `on` results in a</span>
<span class="sd">        multi-aggregation on all columns for an Arrow Dataset, and a single</span>
<span class="sd">        aggregation on the entire row for a simple Dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">aggs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_multicolumn_aggs</span><span class="p">(</span><span class="n">agg_cls</span><span class="p">,</span> <span class="n">on</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="o">*</span><span class="n">aggs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_build_multicolumn_aggs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">agg_cls</span><span class="p">:</span> <span class="nb">type</span><span class="p">,</span>
        <span class="n">on</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]],</span>
        <span class="n">ignore_nulls</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">skip_cols</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Build set of aggregations for applying a single aggregation to</span>
<span class="sd">        multiple columns.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Expand None into an aggregation for each column.</span>
        <span class="k">if</span> <span class="n">on</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">skip_cols</span><span class="p">:</span>
                    <span class="n">skip_cols</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">on</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">schema</span><span class="o">.</span><span class="n">names</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">skip_cols</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">on</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">on</span> <span class="o">=</span> <span class="p">[</span><span class="n">on</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">agg_cls</span><span class="p">(</span><span class="n">on_</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">ignore_nulls</span><span class="o">=</span><span class="n">ignore_nulls</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">on_</span> <span class="ow">in</span> <span class="n">on</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_aggregate_result</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">U</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># NOTE (kfstorm): We cannot call `result[0]` directly on</span>
                <span class="c1"># `PandasRow` because indexing a column with position is not</span>
                <span class="c1"># supported by pandas.</span>
                <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span>

    <span class="nd">@repr_with_fallback</span><span class="p">([</span><span class="s2">&quot;ipywidgets&quot;</span><span class="p">,</span> <span class="s2">&quot;8&quot;</span><span class="p">])</span>
    <span class="k">def</span> <span class="nf">_repr_mimebundle_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a mimebundle with an ipywidget repr and a simple text repr.</span>

<span class="sd">        Depending on the frontend where the data is being displayed,</span>
<span class="sd">        different mimetypes are used from this bundle.</span>
<span class="sd">        See https://ipython.readthedocs.io/en/stable/config/integrating.html</span>
<span class="sd">        for information about this method, and</span>
<span class="sd">        https://ipywidgets.readthedocs.io/en/latest/embedding.html</span>
<span class="sd">        for more information about the jupyter widget mimetype.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A mimebundle containing an ipywidget repr and a simple text repr.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">ipywidgets</span>

        <span class="n">title</span> <span class="o">=</span> <span class="n">ipywidgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&lt;h2&gt;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&lt;/h2&gt;&quot;</span><span class="p">)</span>
        <span class="n">tab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tab_repr_</span><span class="p">()</span>
        <span class="n">widget</span> <span class="o">=</span> <span class="n">ipywidgets</span><span class="o">.</span><span class="n">VBox</span><span class="p">([</span><span class="n">title</span><span class="p">,</span> <span class="n">tab</span><span class="p">],</span> <span class="n">layout</span><span class="o">=</span><span class="n">ipywidgets</span><span class="o">.</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s2">&quot;100%&quot;</span><span class="p">))</span>

        <span class="c1"># Get the widget mime bundle, but replace the plaintext</span>
        <span class="c1"># with the Datastream repr</span>
        <span class="n">bundle</span> <span class="o">=</span> <span class="n">widget</span><span class="o">.</span><span class="n">_repr_mimebundle_</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">bundle</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;text/plain&quot;</span><span class="p">:</span> <span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">bundle</span>

    <span class="k">def</span> <span class="nf">_tab_repr_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">Tab</span>

        <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;num_blocks&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">initial_num_blocks</span><span class="p">(),</span>
            <span class="s2">&quot;num_rows&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_meta_count</span><span class="p">(),</span>
        <span class="p">}</span>
        <span class="c1"># Show metadata if available, but don&#39;t trigger execution.</span>
        <span class="n">schema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">fetch_if_missing</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">schema</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">schema_repr</span> <span class="o">=</span> <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;rendered_html_common.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="s2">&quot;&lt;h5&gt;Unknown schema&lt;/h5&gt;&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
            <span class="n">schema_repr</span> <span class="o">=</span> <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;rendered_html_common.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;&lt;h5&gt;Data type: &lt;code&gt;</span><span class="si">{</span><span class="n">html</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">schema</span><span class="p">))</span><span class="si">}</span><span class="s2">&lt;/code&gt;&lt;/h5&gt;&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">schema_data</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">sname</span><span class="p">,</span> <span class="n">stype</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="n">schema</span><span class="o">.</span><span class="n">types</span><span class="p">):</span>
                <span class="n">schema_data</span><span class="p">[</span><span class="n">sname</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">stype</span><span class="p">,</span> <span class="s2">&quot;__name__&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">stype</span><span class="p">))</span>

            <span class="n">schema_repr</span> <span class="o">=</span> <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;scrollableTable.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                <span class="n">table</span><span class="o">=</span><span class="n">tabulate</span><span class="p">(</span>
                    <span class="n">tabular_data</span><span class="o">=</span><span class="n">schema_data</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span>
                    <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;html&quot;</span><span class="p">,</span>
                    <span class="n">showindex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">headers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Name&quot;</span><span class="p">,</span> <span class="s2">&quot;Type&quot;</span><span class="p">],</span>
                <span class="p">),</span>
                <span class="n">max_height</span><span class="o">=</span><span class="s2">&quot;300px&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">children</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">HTML</span><span class="p">(</span>
                <span class="n">Template</span><span class="p">(</span><span class="s2">&quot;scrollableTable.html.j2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">(</span>
                    <span class="n">table</span><span class="o">=</span><span class="n">tabulate</span><span class="p">(</span>
                        <span class="n">tabular_data</span><span class="o">=</span><span class="n">metadata</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span>
                        <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;html&quot;</span><span class="p">,</span>
                        <span class="n">showindex</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">headers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Field&quot;</span><span class="p">,</span> <span class="s2">&quot;Value&quot;</span><span class="p">],</span>
                    <span class="p">),</span>
                    <span class="n">max_height</span><span class="o">=</span><span class="s2">&quot;300px&quot;</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">schema_repr</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Tab</span><span class="p">(</span><span class="n">children</span><span class="p">,</span> <span class="n">titles</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Metadata&quot;</span><span class="p">,</span> <span class="s2">&quot;Schema&quot;</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">get_plan_as_string</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__bool__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="c1"># Prevents `__len__` from being called to check if it is None</span>
        <span class="c1"># see: issue #25152</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
            <span class="s2">&quot;Use `ds.count()` to compute the length of a distributed Dataset. &quot;</span>
            <span class="s2">&quot;This may be an expensive operation.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="s2">&quot;`Dataset` objects aren&#39;t iterable. To iterate records, call &quot;</span>
            <span class="s2">&quot;`ds.iter_rows()` or `ds.iter_batches()`. For more information, read &quot;</span>
            <span class="s2">&quot;https://docs.ray.io/en/latest/data/iterating-over-data.html.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_block_num_rows</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">get_num_rows</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_get_num_rows</span><span class="p">)</span>
        <span class="n">num_rows</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ref_bundle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_internal_ref_bundles</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">block_ref</span> <span class="ow">in</span> <span class="n">ref_bundle</span><span class="o">.</span><span class="n">block_refs</span><span class="p">:</span>
                <span class="n">num_rows</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">get_num_rows</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block_ref</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">num_rows</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_block_size_bytes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="n">get_size_bytes</span> <span class="o">=</span> <span class="n">cached_remote_fn</span><span class="p">(</span><span class="n">_get_size_bytes</span><span class="p">)</span>
        <span class="n">size_bytes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ref_bundle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">iter_internal_ref_bundles</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">block_ref</span> <span class="ow">in</span> <span class="n">ref_bundle</span><span class="o">.</span><span class="n">block_refs</span><span class="p">:</span>
                <span class="n">size_bytes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">get_size_bytes</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">block_ref</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">size_bytes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_meta_count</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">meta_count</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_uuid</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span>

    <span class="k">def</span> <span class="nf">_set_uuid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">uuid</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span> <span class="o">=</span> <span class="n">uuid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_dataset_uuid</span> <span class="o">=</span> <span class="n">uuid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">_in_stats</span><span class="o">.</span><span class="n">dataset_uuid</span> <span class="o">=</span> <span class="n">uuid</span>

    <span class="k">def</span> <span class="nf">_synchronize_progress_bar</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Flush progress bar output by shutting down the current executor.</span>

<span class="sd">        This should be called at the end of all blocking APIs (e.g., `take`), but not</span>
<span class="sd">        async APIs (e.g., `iter_batches`).</span>

<span class="sd">        The streaming executor runs in a separate generator / thread, so it is</span>
<span class="sd">        possible the shutdown logic runs even after a call to retrieve rows from the</span>
<span class="sd">        stream has finished. Explicit shutdown avoids this, which can clobber console</span>
<span class="sd">        output (https://github.com/ray-project/ray/issues/32414).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Note: excludes _current_executor which is not serializable.</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;plan&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="p">,</span>
            <span class="s2">&quot;uuid&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span><span class="p">,</span>
            <span class="s2">&quot;logical_plan&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;plan&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;uuid&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logical_plan</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;logical_plan&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># When Python shuts down, `ray` might evaluate to `&lt;module None from None&gt;`.</span>
        <span class="c1"># This value is truthy and not `None`, so we use a try-catch in addition to</span>
        <span class="c1"># `if ray is not None`. For more information, see #42382.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ray</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ray</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_current_executor</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="k">pass</span></div>



<span class="nd">@PublicAPI</span>
<span class="k">class</span> <span class="nc">MaterializedDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Generic</span><span class="p">[</span><span class="n">T</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A Dataset materialized in Ray memory, e.g., via `.materialize()`.</span>

<span class="sd">    The blocks of a MaterializedDataset object are materialized into Ray object store</span>
<span class="sd">    memory, which means that this class can be shared or iterated over by multiple Ray</span>
<span class="sd">    tasks without re-executing the underlying computations for producing the stream.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">num_blocks</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the number of blocks of this :class:`MaterializedDataset`.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; import ray</span>
<span class="sd">            &gt;&gt;&gt; ds = ray.data.range(100).repartition(10).materialize()</span>
<span class="sd">            &gt;&gt;&gt; ds.num_blocks()</span>
<span class="sd">            10</span>

<span class="sd">        Time complexity: O(1)</span>

<span class="sd">        Returns:</span>
<span class="sd">            The number of blocks of this :class:`Dataset`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_plan</span><span class="o">.</span><span class="n">initial_num_blocks</span><span class="p">()</span>


<div class="viewcode-block" id="Schema">
<a class="viewcode-back" href="../../../data/api/dataset.html#ray.data.Schema">[docs]</a>
<span class="nd">@PublicAPI</span><span class="p">(</span><span class="n">stability</span><span class="o">=</span><span class="s2">&quot;beta&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Schema</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Dataset schema.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        base_schema: The underlying Arrow or Pandas schema.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">base_schema</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;pyarrow.lib.Schema&quot;</span><span class="p">,</span> <span class="s2">&quot;PandasBlockSchema&quot;</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">data_context</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataContext</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span> <span class="o">=</span> <span class="n">base_schema</span>

        <span class="c1"># Snapshot the current context, so that the config of Datasets is always</span>
        <span class="c1"># determined by the config at the time it was created.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_context</span> <span class="o">=</span> <span class="n">data_context</span> <span class="ow">or</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">DataContext</span><span class="o">.</span><span class="n">get_current</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Lists the columns of this Dataset.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="o">.</span><span class="n">names</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">types</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">type</span><span class="p">[</span><span class="nb">object</span><span class="p">],</span> <span class="s2">&quot;pyarrow.lib.DataType&quot;</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Lists the types of this Dataset in Arrow format</span>

<span class="sd">        For non-Arrow compatible types, we return &quot;object&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>

        <span class="kn">from</span> <span class="nn">ray.data.extensions</span> <span class="kn">import</span> <span class="n">ArrowTensorType</span><span class="p">,</span> <span class="n">TensorDtype</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">lib</span><span class="o">.</span><span class="n">Schema</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>

        <span class="n">arrow_types</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span><span class="o">.</span><span class="n">types</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">TensorDtype</span><span class="p">):</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">use_arrow_tensor_v2</span><span class="p">:</span>
                    <span class="n">pa_tensor_type_class</span> <span class="o">=</span> <span class="n">ArrowTensorTypeV2</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">pa_tensor_type_class</span> <span class="o">=</span> <span class="n">ArrowTensorType</span>

                <span class="c1"># Manually convert our Pandas tensor extension type to Arrow.</span>
                <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">pa_tensor_type_class</span><span class="p">(</span>
                        <span class="n">shape</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pa</span><span class="o">.</span><span class="n">from_numpy_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pa</span><span class="o">.</span><span class="n">from_numpy_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">))</span>
                <span class="k">except</span> <span class="n">pa</span><span class="o">.</span><span class="n">ArrowNotImplementedError</span><span class="p">:</span>
                    <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error converting dtype </span><span class="si">{</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> to Arrow.&quot;</span><span class="p">)</span>
                    <span class="n">arrow_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">arrow_types</span>

    <span class="k">def</span> <span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">other</span><span class="p">,</span> <span class="n">Schema</span><span class="p">)</span> <span class="ow">and</span> <span class="n">other</span><span class="o">.</span><span class="n">base_schema</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_schema</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">column_width</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">)])</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="mi">2</span>

        <span class="n">output</span> <span class="o">=</span> <span class="s2">&quot;Column&quot;</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">((</span><span class="n">column_width</span> <span class="o">+</span> <span class="n">padding</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot;Type</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">((</span><span class="n">column_width</span> <span class="o">+</span> <span class="n">padding</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Column&quot;</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Type&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="nb">type</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">types</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="n">name</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">((</span><span class="n">column_width</span> <span class="o">+</span> <span class="n">padding</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
            <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span></div>



<span class="k">def</span> <span class="nf">_get_size_bytes</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">size_bytes</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_block_to_df</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;pandas.DataFrame&quot;</span><span class="p">:</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_block_to_ndarray</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">,</span> <span class="n">column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_block_to_arrow</span><span class="p">(</span><span class="n">block</span><span class="p">:</span> <span class="n">Block</span><span class="p">):</span>
    <span class="n">block</span> <span class="o">=</span> <span class="n">BlockAccessor</span><span class="o">.</span><span class="n">for_block</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">block</span><span class="o">.</span><span class="n">to_arrow</span><span class="p">()</span>
</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="footer-content-items footer-content__inner">
  
    <div class="footer-content-item"><div id="csat">
  <div id="csat-feedback-received" class="csat-hidden">
    <span>Thanks for the feedback!</span>
  </div>
  <div id="csat-inputs">
    <span>Was this helpful?</span>
    <div id="csat-yes" class="csat-button">
      <svg id="csat-yes-icon" class="csat-hidden csat-icon" width="18" height="13" viewBox="0 0 18 13" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 10.172L16.1922 0.979004L17.6072 2.393L7.00023 13L0.63623 6.636L2.05023 5.222L7.00023 10.172Z" />
      </svg>
      <span>Yes<span>
    </div>
    <div id="csat-no" class="csat-button">
      <svg id="csat-no-icon" class="csat-hidden csat-icon" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M7.00023 5.58599L11.9502 0.635986L13.3642 2.04999L8.41423 6.99999L13.3642 11.95L11.9502 13.364L7.00023 8.41399L2.05023 13.364L0.63623 11.95L5.58623 6.99999L0.63623 2.04999L2.05023 0.635986L7.00023 5.58599Z" />
      </svg>
      <span>No<span>
    </div>
  </div>
  <div id="csat-textarea-group" class="csat-hidden">
    <span id="csat-feedback-label">Feedback</span>
    <textarea id="csat-textarea"></textarea>
    <div id="csat-submit">Submit</div>
  </div>
</div></div>
  
</div>

          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script data-cfasync="false" src="https://docs.ray.io/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script src="https://docs.ray.io/en/master/_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="https://docs.ray.io/en/master/_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
      © Copyright 2024, The Ray Team.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.3.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.14.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>